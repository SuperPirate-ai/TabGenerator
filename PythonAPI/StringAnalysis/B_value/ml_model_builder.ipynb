{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (708, 4)\n",
      "Training labels shape: (708, 6)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"b_values.json\") as f:\n",
    "#     b_values = json.load(f)\n",
    "    \n",
    "# with open(\"avg_amplitude_ratios.json\") as f:\n",
    "#     avg_amplitude_ratios = json.load(f)\n",
    "\n",
    "with open(\"results.csv\") as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "strings = [\"h_E\", \"B\", \"G\", \"D\", \"A\", \"E\"]\n",
    "labels = np.array([0,1,2,3,4,5])\n",
    "# strings = [\"1-2h_E\", \"1-2B\", \"1-2G\", \"1-2D\", \"1-2A\", \"1-2E\", \"2-2h_E\", \"2-2B\", \"2-2G\", \"2-2D\", \"2-2A\", \"2-2E\"]\n",
    "# labels = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "\n",
    "\n",
    "data = []\n",
    "label_list = []\n",
    "\n",
    "for i, line in enumerate(results):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    string,metric,amp_ra,deviation,f0 = line.split(\",\")\n",
    "    if string in strings:\n",
    "        metric = float(metric)\n",
    "        amp_ra = float(amp_ra)\n",
    "        deviation = float(deviation)\n",
    "        f0 = float(f0)\n",
    "        data.append([metric,amp_ra, deviation,f0])\n",
    "        label_list.append(labels[strings.index(string)])\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "label_count = 6\n",
    "labels_categorical = tf.keras.utils.to_categorical(label_list, num_classes=label_count)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert your data to numpy arrays if they are not already\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "val_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 2)\n",
    "print(f\"Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_62          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_63          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_103 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_62          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_70 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_104 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_63          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_71 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_105 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m390\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,054</span> (39.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,054\u001b[0m (39.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,670</span> (37.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,670\u001b[0m (37.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.1534 - loss: 2.5544 - val_accuracy: 0.2982 - val_loss: 1.7830\n",
      "Epoch 2/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3197 - loss: 1.9211 - val_accuracy: 0.3772 - val_loss: 1.7224\n",
      "Epoch 3/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4211 - loss: 1.6045 - val_accuracy: 0.4035 - val_loss: 1.6893\n",
      "Epoch 4/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4424 - loss: 1.4020 - val_accuracy: 0.4035 - val_loss: 1.6570\n",
      "Epoch 5/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4645 - loss: 1.4182 - val_accuracy: 0.4123 - val_loss: 1.6282\n",
      "Epoch 6/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4330 - loss: 1.3110 - val_accuracy: 0.4474 - val_loss: 1.5929\n",
      "Epoch 7/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5070 - loss: 1.2537 - val_accuracy: 0.5088 - val_loss: 1.5602\n",
      "Epoch 8/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4915 - loss: 1.3027 - val_accuracy: 0.5263 - val_loss: 1.5257\n",
      "Epoch 9/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5285 - loss: 1.2073 - val_accuracy: 0.5439 - val_loss: 1.4958\n",
      "Epoch 10/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5135 - loss: 1.2291 - val_accuracy: 0.5877 - val_loss: 1.4676\n",
      "Epoch 11/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4963 - loss: 1.1930 - val_accuracy: 0.5877 - val_loss: 1.4279\n",
      "Epoch 12/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5574 - loss: 1.1334 - val_accuracy: 0.6053 - val_loss: 1.4073\n",
      "Epoch 13/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5692 - loss: 1.1394 - val_accuracy: 0.6316 - val_loss: 1.3918\n",
      "Epoch 14/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5642 - loss: 1.1517 - val_accuracy: 0.6404 - val_loss: 1.4181\n",
      "Epoch 15/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4765 - loss: 1.1589 - val_accuracy: 0.6842 - val_loss: 1.4236\n",
      "Epoch 16/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5867 - loss: 1.0515 - val_accuracy: 0.7018 - val_loss: 1.4125\n",
      "Epoch 17/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6290 - loss: 1.0325 - val_accuracy: 0.6842 - val_loss: 1.4325\n",
      "Epoch 18/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5747 - loss: 1.0014 - val_accuracy: 0.6930 - val_loss: 1.4206\n",
      "Epoch 19/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5567 - loss: 1.0543 - val_accuracy: 0.7105 - val_loss: 1.4053\n",
      "Epoch 20/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6254 - loss: 0.9251 - val_accuracy: 0.7018 - val_loss: 1.3941\n",
      "Epoch 21/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6374 - loss: 0.9395 - val_accuracy: 0.6930 - val_loss: 1.4315\n",
      "Epoch 22/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5979 - loss: 1.0059 - val_accuracy: 0.7193 - val_loss: 1.4488\n",
      "Epoch 23/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5964 - loss: 0.9766 - val_accuracy: 0.7193 - val_loss: 1.4555\n",
      "Epoch 24/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6192 - loss: 0.9571 - val_accuracy: 0.7105 - val_loss: 1.4816\n",
      "Epoch 25/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6533 - loss: 0.9251 - val_accuracy: 0.7193 - val_loss: 1.5567\n",
      "Epoch 26/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5915 - loss: 0.9523 - val_accuracy: 0.6930 - val_loss: 1.5822\n",
      "Epoch 27/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6370 - loss: 0.9247 - val_accuracy: 0.7193 - val_loss: 1.5861\n",
      "Epoch 28/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5965 - loss: 0.9626 - val_accuracy: 0.7281 - val_loss: 1.6234\n",
      "Epoch 29/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6405 - loss: 0.8807 - val_accuracy: 0.7105 - val_loss: 1.5950\n",
      "Epoch 30/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6168 - loss: 0.8715 - val_accuracy: 0.7368 - val_loss: 1.5999\n",
      "Epoch 31/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6234 - loss: 0.8837 - val_accuracy: 0.7368 - val_loss: 1.6590\n",
      "Epoch 32/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6323 - loss: 0.8938 - val_accuracy: 0.7456 - val_loss: 1.6581\n",
      "Epoch 33/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6359 - loss: 0.8589 - val_accuracy: 0.7281 - val_loss: 1.6517\n",
      "Epoch 34/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6466 - loss: 0.8466 - val_accuracy: 0.7456 - val_loss: 1.7476\n",
      "Epoch 35/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6308 - loss: 0.9173 - val_accuracy: 0.7456 - val_loss: 1.7446\n",
      "Epoch 36/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6189 - loss: 0.9004 - val_accuracy: 0.7368 - val_loss: 1.7896\n",
      "Epoch 37/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6666 - loss: 0.8219 - val_accuracy: 0.7632 - val_loss: 1.7954\n",
      "Epoch 38/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6626 - loss: 0.8941 - val_accuracy: 0.7456 - val_loss: 1.7915\n",
      "Epoch 39/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6461 - loss: 0.8478 - val_accuracy: 0.7632 - val_loss: 1.7475\n",
      "Epoch 40/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 0.9451 - val_accuracy: 0.7719 - val_loss: 1.7550\n",
      "Epoch 41/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6131 - loss: 0.8795 - val_accuracy: 0.7719 - val_loss: 1.7629\n",
      "Epoch 42/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6623 - loss: 0.8735 - val_accuracy: 0.7456 - val_loss: 1.7675\n",
      "Epoch 43/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6968 - loss: 0.8168 - val_accuracy: 0.7719 - val_loss: 1.8128\n",
      "Epoch 44/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6269 - loss: 0.8410 - val_accuracy: 0.7544 - val_loss: 1.7782\n",
      "Epoch 45/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5818 - loss: 1.0023 - val_accuracy: 0.7632 - val_loss: 1.7691\n",
      "Epoch 46/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6904 - loss: 0.8455 - val_accuracy: 0.7807 - val_loss: 1.7767\n",
      "Epoch 47/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.8032 - val_accuracy: 0.7807 - val_loss: 1.8513\n",
      "Epoch 48/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 0.8869 - val_accuracy: 0.7807 - val_loss: 1.9190\n",
      "Epoch 49/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7076 - loss: 0.7274 - val_accuracy: 0.7895 - val_loss: 1.9457\n",
      "Epoch 50/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6643 - loss: 0.8576 - val_accuracy: 0.7719 - val_loss: 1.8263\n",
      "Epoch 51/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6672 - loss: 0.7696 - val_accuracy: 0.8070 - val_loss: 1.7864\n",
      "Epoch 52/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6700 - loss: 0.7683 - val_accuracy: 0.7719 - val_loss: 1.8704\n",
      "Epoch 53/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.7862 - val_accuracy: 0.7895 - val_loss: 1.9301\n",
      "Epoch 54/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6810 - loss: 0.7540 - val_accuracy: 0.7807 - val_loss: 1.9166\n",
      "Epoch 55/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 0.8520 - val_accuracy: 0.7807 - val_loss: 1.9051\n",
      "Epoch 56/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6511 - loss: 0.8592 - val_accuracy: 0.7807 - val_loss: 1.8725\n",
      "Epoch 57/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6966 - loss: 0.7405 - val_accuracy: 0.7632 - val_loss: 1.8767\n",
      "Epoch 58/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.6659 - val_accuracy: 0.7807 - val_loss: 1.9073\n",
      "Epoch 59/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7044 - loss: 0.8248 - val_accuracy: 0.8158 - val_loss: 1.8988\n",
      "Epoch 60/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 0.7786 - val_accuracy: 0.7895 - val_loss: 1.9183\n",
      "Epoch 61/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6970 - loss: 0.6948 - val_accuracy: 0.8158 - val_loss: 1.9154\n",
      "Epoch 62/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.8107 - val_accuracy: 0.7982 - val_loss: 2.0079\n",
      "Epoch 63/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.7083 - val_accuracy: 0.7982 - val_loss: 1.9971\n",
      "Epoch 64/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6872 - loss: 0.7943 - val_accuracy: 0.8070 - val_loss: 2.0169\n",
      "Epoch 65/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6983 - loss: 0.7529 - val_accuracy: 0.7807 - val_loss: 2.0580\n",
      "Epoch 66/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7250 - loss: 0.7184 - val_accuracy: 0.7895 - val_loss: 2.0508\n",
      "Epoch 67/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6986 - loss: 0.7495 - val_accuracy: 0.8421 - val_loss: 2.0213\n",
      "Epoch 68/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6494 - loss: 0.7179 - val_accuracy: 0.7982 - val_loss: 2.0066\n",
      "Epoch 69/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6906 - loss: 0.7728 - val_accuracy: 0.7807 - val_loss: 1.9646\n",
      "Epoch 70/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7140 - loss: 0.7449 - val_accuracy: 0.8158 - val_loss: 1.9585\n",
      "Epoch 71/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6865 - loss: 0.7666 - val_accuracy: 0.7895 - val_loss: 1.9998\n",
      "Epoch 72/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6863 - loss: 0.7875 - val_accuracy: 0.8070 - val_loss: 1.9714\n",
      "Epoch 73/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.6994 - val_accuracy: 0.7807 - val_loss: 2.0049\n",
      "Epoch 74/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7157 - loss: 0.7183 - val_accuracy: 0.8158 - val_loss: 1.8622\n",
      "Epoch 75/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6844 - loss: 0.7538 - val_accuracy: 0.7982 - val_loss: 1.8490\n",
      "Epoch 76/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6568 - loss: 0.8075 - val_accuracy: 0.8158 - val_loss: 1.8689\n",
      "Epoch 77/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6808 - loss: 0.7248 - val_accuracy: 0.8070 - val_loss: 1.8419\n",
      "Epoch 78/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.6409 - val_accuracy: 0.7807 - val_loss: 1.8330\n",
      "Epoch 79/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7081 - loss: 0.7340 - val_accuracy: 0.7807 - val_loss: 1.8421\n",
      "Epoch 80/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6687 - loss: 0.7466 - val_accuracy: 0.7982 - val_loss: 1.9317\n",
      "Epoch 81/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6743 - loss: 0.8229 - val_accuracy: 0.7982 - val_loss: 1.9286\n",
      "Epoch 82/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.7350 - val_accuracy: 0.7807 - val_loss: 1.9539\n",
      "Epoch 83/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7151 - loss: 0.6790 - val_accuracy: 0.7719 - val_loss: 1.9148\n",
      "Epoch 84/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6730 - loss: 0.7834 - val_accuracy: 0.7982 - val_loss: 1.8814\n",
      "Epoch 85/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.7199 - val_accuracy: 0.7895 - val_loss: 1.9027\n",
      "Epoch 86/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6897 - loss: 0.7983 - val_accuracy: 0.8070 - val_loss: 1.9406\n",
      "Epoch 87/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7408 - loss: 0.6641 - val_accuracy: 0.7982 - val_loss: 1.9163\n",
      "Epoch 88/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7169 - loss: 0.7316 - val_accuracy: 0.8158 - val_loss: 1.9401\n",
      "Epoch 89/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7270 - loss: 0.6962 - val_accuracy: 0.7982 - val_loss: 1.9237\n",
      "Epoch 90/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.6692 - val_accuracy: 0.7807 - val_loss: 1.9042\n",
      "Epoch 91/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7679 - loss: 0.5931 - val_accuracy: 0.7982 - val_loss: 1.8845\n",
      "Epoch 92/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7249 - loss: 0.6798 - val_accuracy: 0.8070 - val_loss: 1.9428\n",
      "Epoch 93/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7189 - loss: 0.6976 - val_accuracy: 0.8158 - val_loss: 2.0074\n",
      "Epoch 94/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6806 - loss: 0.7676 - val_accuracy: 0.7895 - val_loss: 1.9315\n",
      "Epoch 95/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6982 - loss: 0.7366 - val_accuracy: 0.8158 - val_loss: 1.9830\n",
      "Epoch 96/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7071 - loss: 0.7063 - val_accuracy: 0.8070 - val_loss: 2.0070\n",
      "Epoch 97/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.6321 - val_accuracy: 0.7895 - val_loss: 2.0087\n",
      "Epoch 98/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7023 - loss: 0.7662 - val_accuracy: 0.8070 - val_loss: 1.9759\n",
      "Epoch 99/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7523 - loss: 0.6273 - val_accuracy: 0.7982 - val_loss: 2.0035\n",
      "Epoch 100/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 0.7061 - val_accuracy: 0.7895 - val_loss: 1.9431\n",
      "Epoch 101/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.5925 - val_accuracy: 0.8070 - val_loss: 1.8674\n",
      "Epoch 102/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.6670 - val_accuracy: 0.7895 - val_loss: 1.8734\n",
      "Epoch 103/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6780 - loss: 0.7372 - val_accuracy: 0.7895 - val_loss: 1.8667\n",
      "Epoch 104/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.6585 - val_accuracy: 0.7807 - val_loss: 1.9003\n",
      "Epoch 105/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6990 - loss: 0.7123 - val_accuracy: 0.7895 - val_loss: 1.8223\n",
      "Epoch 106/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.6281 - val_accuracy: 0.8070 - val_loss: 1.7421\n",
      "Epoch 107/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7048 - loss: 0.6502 - val_accuracy: 0.7982 - val_loss: 1.8005\n",
      "Epoch 108/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.6592 - val_accuracy: 0.8158 - val_loss: 1.9795\n",
      "Epoch 109/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.6710 - val_accuracy: 0.8070 - val_loss: 2.0698\n",
      "Epoch 110/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.6506 - val_accuracy: 0.7807 - val_loss: 2.0333\n",
      "Epoch 111/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7838 - loss: 0.5740 - val_accuracy: 0.7982 - val_loss: 2.0018\n",
      "Epoch 112/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7762 - loss: 0.5570 - val_accuracy: 0.8333 - val_loss: 2.0979\n",
      "Epoch 113/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7396 - loss: 0.6250 - val_accuracy: 0.8509 - val_loss: 2.0774\n",
      "Epoch 114/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.5871 - val_accuracy: 0.8246 - val_loss: 2.0434\n",
      "Epoch 115/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.5666 - val_accuracy: 0.8158 - val_loss: 2.0429\n",
      "Epoch 116/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7724 - loss: 0.5984 - val_accuracy: 0.8246 - val_loss: 2.0287\n",
      "Epoch 117/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.5694 - val_accuracy: 0.8421 - val_loss: 2.1519\n",
      "Epoch 118/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 0.6246 - val_accuracy: 0.7982 - val_loss: 2.1845\n",
      "Epoch 119/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.5720 - val_accuracy: 0.7719 - val_loss: 2.1141\n",
      "Epoch 120/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7169 - loss: 0.6863 - val_accuracy: 0.7719 - val_loss: 2.1013\n",
      "Epoch 121/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7187 - loss: 0.6018 - val_accuracy: 0.8070 - val_loss: 2.1303\n",
      "Epoch 122/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.5617 - val_accuracy: 0.8158 - val_loss: 2.1337\n",
      "Epoch 123/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 0.6141 - val_accuracy: 0.8333 - val_loss: 2.1593\n",
      "Epoch 124/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 0.6227 - val_accuracy: 0.8158 - val_loss: 2.1598\n",
      "Epoch 125/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.5908 - val_accuracy: 0.8246 - val_loss: 2.1154\n",
      "Epoch 126/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.5387 - val_accuracy: 0.8070 - val_loss: 2.1501\n",
      "Epoch 127/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7616 - loss: 0.6176 - val_accuracy: 0.8070 - val_loss: 2.1185\n",
      "Epoch 128/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.6011 - val_accuracy: 0.7982 - val_loss: 2.0956\n",
      "Epoch 129/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7284 - loss: 0.6589 - val_accuracy: 0.7895 - val_loss: 2.1296\n",
      "Epoch 130/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7360 - loss: 0.6202 - val_accuracy: 0.7982 - val_loss: 2.1551\n",
      "Epoch 131/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 0.5815 - val_accuracy: 0.8070 - val_loss: 2.1952\n",
      "Epoch 132/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.5930 - val_accuracy: 0.8158 - val_loss: 2.2636\n",
      "Epoch 133/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.5662 - val_accuracy: 0.8070 - val_loss: 2.3520\n",
      "Epoch 134/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.6005 - val_accuracy: 0.7807 - val_loss: 2.3738\n",
      "Epoch 135/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7506 - loss: 0.6536 - val_accuracy: 0.7895 - val_loss: 2.3480\n",
      "Epoch 136/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7359 - loss: 0.6561 - val_accuracy: 0.7895 - val_loss: 2.4111\n",
      "Epoch 137/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7216 - loss: 0.6847 - val_accuracy: 0.8421 - val_loss: 2.4414\n",
      "Epoch 138/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7702 - loss: 0.5646 - val_accuracy: 0.8246 - val_loss: 2.4107\n",
      "Epoch 139/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7131 - loss: 0.6624 - val_accuracy: 0.8421 - val_loss: 2.4084\n",
      "Epoch 140/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.5739 - val_accuracy: 0.8684 - val_loss: 2.3695\n",
      "Epoch 141/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.5559 - val_accuracy: 0.8333 - val_loss: 2.3520\n",
      "Epoch 142/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.5874 - val_accuracy: 0.8421 - val_loss: 2.3732\n",
      "Epoch 143/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7599 - loss: 0.5762 - val_accuracy: 0.8509 - val_loss: 2.3577\n",
      "Epoch 144/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7295 - loss: 0.6391 - val_accuracy: 0.8246 - val_loss: 2.3355\n",
      "Epoch 145/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.6095 - val_accuracy: 0.8509 - val_loss: 2.3136\n",
      "Epoch 146/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.6026 - val_accuracy: 0.8246 - val_loss: 2.3137\n",
      "Epoch 147/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7797 - loss: 0.5618 - val_accuracy: 0.7982 - val_loss: 2.3066\n",
      "Epoch 148/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7269 - loss: 0.6137 - val_accuracy: 0.8333 - val_loss: 2.2923\n",
      "Epoch 149/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7991 - loss: 0.5038 - val_accuracy: 0.8246 - val_loss: 2.3069\n",
      "Epoch 150/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7520 - loss: 0.5728 - val_accuracy: 0.8246 - val_loss: 2.3256\n",
      "Epoch 151/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7160 - loss: 0.6665 - val_accuracy: 0.8246 - val_loss: 2.2961\n",
      "Epoch 152/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7591 - loss: 0.5909 - val_accuracy: 0.8246 - val_loss: 2.2975\n",
      "Epoch 153/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.4856 - val_accuracy: 0.8158 - val_loss: 2.2827\n",
      "Epoch 154/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7636 - loss: 0.6128 - val_accuracy: 0.8158 - val_loss: 2.2077\n",
      "Epoch 155/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.5624 - val_accuracy: 0.7895 - val_loss: 2.2427\n",
      "Epoch 156/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7577 - loss: 0.5720 - val_accuracy: 0.8421 - val_loss: 2.2415\n",
      "Epoch 157/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7844 - loss: 0.5264 - val_accuracy: 0.8421 - val_loss: 2.2197\n",
      "Epoch 158/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7316 - loss: 0.6126 - val_accuracy: 0.8596 - val_loss: 2.2234\n",
      "Epoch 159/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.5424 - val_accuracy: 0.8333 - val_loss: 2.2558\n",
      "Epoch 160/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7598 - loss: 0.6034 - val_accuracy: 0.8246 - val_loss: 2.2738\n",
      "Epoch 161/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7733 - loss: 0.6074 - val_accuracy: 0.8333 - val_loss: 2.2244\n",
      "Epoch 162/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.5251 - val_accuracy: 0.8158 - val_loss: 2.1265\n",
      "Epoch 163/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 0.7770 - val_accuracy: 0.8246 - val_loss: 2.0678\n",
      "Epoch 164/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7835 - loss: 0.6178 - val_accuracy: 0.8333 - val_loss: 2.0206\n",
      "Epoch 165/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7655 - loss: 0.5535 - val_accuracy: 0.8421 - val_loss: 2.0895\n",
      "Epoch 166/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.5685 - val_accuracy: 0.8158 - val_loss: 2.1432\n",
      "Epoch 167/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7588 - loss: 0.5289 - val_accuracy: 0.8509 - val_loss: 2.2420\n",
      "Epoch 168/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7337 - loss: 0.6366 - val_accuracy: 0.8158 - val_loss: 2.2006\n",
      "Epoch 169/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7558 - loss: 0.6015 - val_accuracy: 0.8070 - val_loss: 2.2502\n",
      "Epoch 170/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7954 - loss: 0.5557 - val_accuracy: 0.8246 - val_loss: 2.1978\n",
      "Epoch 171/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4928 - val_accuracy: 0.7807 - val_loss: 2.2076\n",
      "Epoch 172/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7480 - loss: 0.6109 - val_accuracy: 0.7982 - val_loss: 2.2031\n",
      "Epoch 173/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7877 - loss: 0.5627 - val_accuracy: 0.8070 - val_loss: 2.1739\n",
      "Epoch 174/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7742 - loss: 0.5467 - val_accuracy: 0.7982 - val_loss: 2.1553\n",
      "Epoch 175/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7607 - loss: 0.5323 - val_accuracy: 0.8158 - val_loss: 2.2149\n",
      "Epoch 176/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.5103 - val_accuracy: 0.8333 - val_loss: 2.2035\n",
      "Epoch 177/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.5031 - val_accuracy: 0.7982 - val_loss: 2.1667\n",
      "Epoch 178/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7816 - loss: 0.5959 - val_accuracy: 0.7982 - val_loss: 2.1326\n",
      "Epoch 179/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.5811 - val_accuracy: 0.7895 - val_loss: 2.1122\n",
      "Epoch 180/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 0.6008 - val_accuracy: 0.8246 - val_loss: 2.0906\n",
      "Epoch 181/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.5778 - val_accuracy: 0.8070 - val_loss: 2.1515\n",
      "Epoch 182/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7350 - loss: 0.6389 - val_accuracy: 0.8333 - val_loss: 2.1889\n",
      "Epoch 183/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7581 - loss: 0.5743 - val_accuracy: 0.7982 - val_loss: 2.1964\n",
      "Epoch 184/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8310 - loss: 0.4559 - val_accuracy: 0.7895 - val_loss: 2.2097\n",
      "Epoch 185/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.5537 - val_accuracy: 0.7895 - val_loss: 2.2515\n",
      "Epoch 186/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7489 - loss: 0.5777 - val_accuracy: 0.8246 - val_loss: 2.2620\n",
      "Epoch 187/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7708 - loss: 0.6102 - val_accuracy: 0.8158 - val_loss: 2.3018\n",
      "Epoch 188/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.5495 - val_accuracy: 0.8158 - val_loss: 2.2883\n",
      "Epoch 189/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.4870 - val_accuracy: 0.8421 - val_loss: 2.2312\n",
      "Epoch 190/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7236 - loss: 0.6043 - val_accuracy: 0.8333 - val_loss: 2.2450\n",
      "Epoch 191/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 0.5283 - val_accuracy: 0.7982 - val_loss: 2.2237\n",
      "Epoch 192/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7770 - loss: 0.5632 - val_accuracy: 0.8509 - val_loss: 2.2563\n",
      "Epoch 193/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7568 - loss: 0.6029 - val_accuracy: 0.8421 - val_loss: 2.2705\n",
      "Epoch 194/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.5304 - val_accuracy: 0.8246 - val_loss: 2.1543\n",
      "Epoch 195/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7945 - loss: 0.5087 - val_accuracy: 0.8333 - val_loss: 2.2292\n",
      "Epoch 196/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8075 - loss: 0.5337 - val_accuracy: 0.8596 - val_loss: 2.2477\n",
      "Epoch 197/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.5136 - val_accuracy: 0.8421 - val_loss: 2.2563\n",
      "Epoch 198/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.5495 - val_accuracy: 0.8246 - val_loss: 2.2909\n",
      "Epoch 199/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.5089 - val_accuracy: 0.8246 - val_loss: 2.2529\n",
      "Epoch 200/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.5863 - val_accuracy: 0.8246 - val_loss: 2.2848\n",
      "Mean validation accuracy: 0.8245614171028137\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(4,)),  \n",
    "    BatchNormalization(),  # Helps stabilize training\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Dense(32, activation='relu'),\n",
    "    # Dropout(0.2),\n",
    "\n",
    "    Dense(label_count, activation='softmax') \n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(model.summary())\n",
    "history = model.fit(X_train_fold, y_train_fold, epochs=200, batch_size=16, validation_split=0.2)\n",
    "val_accuracies.append(history.history['val_accuracy'][-1])\n",
    "average_val_accuracy = np.mean(val_accuracies)\n",
    "print(f'Mean validation accuracy: {average_val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('B_value_model.h5')\n",
    "\n",
    "\n",
    "\n",
    "model.output_names=['output']\n",
    "input_signature = [tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name='digit')]\n",
    "\n",
    "# Convert the Keras model to ONNX format\n",
    "#onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, opset=13)\n",
    "\n",
    "\n",
    "(onnx_model_proto, storage) = tf2onnx.convert.from_keras(model,input_signature=input_signature, opset=13)\n",
    "with open('modelData.onnx', \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
