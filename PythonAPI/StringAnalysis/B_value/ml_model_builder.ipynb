{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (708, 4)\n",
      "Training labels shape: (708, 6)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"b_values.json\") as f:\n",
    "#     b_values = json.load(f)\n",
    "    \n",
    "# with open(\"avg_amplitude_ratios.json\") as f:\n",
    "#     avg_amplitude_ratios = json.load(f)\n",
    "\n",
    "with open(\"results.csv\") as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "strings = [\"h_E\", \"B\", \"G\", \"D\", \"A\", \"E\"]\n",
    "labels = np.array([0,1,2,3,4,5])\n",
    "# strings = [\"1-2h_E\", \"1-2B\", \"1-2G\", \"1-2D\", \"1-2A\", \"1-2E\", \"2-2h_E\", \"2-2B\", \"2-2G\", \"2-2D\", \"2-2A\", \"2-2E\"]\n",
    "# labels = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "\n",
    "\n",
    "data = []\n",
    "label_list = []\n",
    "\n",
    "for i, line in enumerate(results):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    string,metric,amp_ra,deviation,f0 = line.split(\",\")\n",
    "    if string in strings:\n",
    "        metric = float(metric)\n",
    "        amp_ra = float(amp_ra)\n",
    "        deviation = float(deviation)\n",
    "        f0 = float(f0)\n",
    "        data.append([metric,amp_ra, deviation,f0])\n",
    "        label_list.append(labels[strings.index(string)])\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "label_count = 6\n",
    "labels_categorical = tf.keras.utils.to_categorical(label_list, num_classes=label_count)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert your data to numpy arrays if they are not already\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "val_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 2)\n",
    "print(f\"Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1742 - loss: 2.1382 - val_accuracy: 0.1972 - val_loss: 1.8053\n",
      "Epoch 2/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1769 - loss: 1.9946 - val_accuracy: 0.1690 - val_loss: 1.7928\n",
      "Epoch 3/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2294 - loss: 1.9579 - val_accuracy: 0.1831 - val_loss: 1.7794\n",
      "Epoch 4/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2275 - loss: 1.8540 - val_accuracy: 0.1901 - val_loss: 1.7654\n",
      "Epoch 5/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2183 - loss: 1.8784 - val_accuracy: 0.2394 - val_loss: 1.7501\n",
      "Epoch 6/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2071 - loss: 1.8245 - val_accuracy: 0.2817 - val_loss: 1.7337\n",
      "Epoch 7/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2524 - loss: 1.7562 - val_accuracy: 0.2958 - val_loss: 1.7171\n",
      "Epoch 8/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2635 - loss: 1.7286 - val_accuracy: 0.2958 - val_loss: 1.7003\n",
      "Epoch 9/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3258 - loss: 1.6342 - val_accuracy: 0.3028 - val_loss: 1.6817\n",
      "Epoch 10/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2789 - loss: 1.6617 - val_accuracy: 0.3239 - val_loss: 1.6631\n",
      "Epoch 11/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2816 - loss: 1.5989 - val_accuracy: 0.3380 - val_loss: 1.6457\n",
      "Epoch 12/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3166 - loss: 1.5861 - val_accuracy: 0.3451 - val_loss: 1.6273\n",
      "Epoch 13/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2909 - loss: 1.5754 - val_accuracy: 0.3521 - val_loss: 1.6079\n",
      "Epoch 14/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2866 - loss: 1.5494 - val_accuracy: 0.3592 - val_loss: 1.5890\n",
      "Epoch 15/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3341 - loss: 1.5221 - val_accuracy: 0.3592 - val_loss: 1.5683\n",
      "Epoch 16/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3868 - loss: 1.4787 - val_accuracy: 0.3803 - val_loss: 1.5457\n",
      "Epoch 17/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3558 - loss: 1.4482 - val_accuracy: 0.4014 - val_loss: 1.5244\n",
      "Epoch 18/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3776 - loss: 1.4422 - val_accuracy: 0.3944 - val_loss: 1.5037\n",
      "Epoch 19/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4239 - loss: 1.3904 - val_accuracy: 0.3873 - val_loss: 1.4811\n",
      "Epoch 20/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4003 - loss: 1.4278 - val_accuracy: 0.3944 - val_loss: 1.4597\n",
      "Epoch 21/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3937 - loss: 1.3797 - val_accuracy: 0.4085 - val_loss: 1.4388\n",
      "Epoch 22/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4209 - loss: 1.3611 - val_accuracy: 0.4296 - val_loss: 1.4173\n",
      "Epoch 23/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4320 - loss: 1.3427 - val_accuracy: 0.4437 - val_loss: 1.3973\n",
      "Epoch 24/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4273 - loss: 1.3609 - val_accuracy: 0.4577 - val_loss: 1.3778\n",
      "Epoch 25/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4216 - loss: 1.3395 - val_accuracy: 0.4577 - val_loss: 1.3564\n",
      "Epoch 26/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4810 - loss: 1.2992 - val_accuracy: 0.4507 - val_loss: 1.3379\n",
      "Epoch 27/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4737 - loss: 1.3058 - val_accuracy: 0.4718 - val_loss: 1.3212\n",
      "Epoch 28/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4610 - loss: 1.2983 - val_accuracy: 0.4789 - val_loss: 1.3060\n",
      "Epoch 29/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4794 - loss: 1.2836 - val_accuracy: 0.5000 - val_loss: 1.2893\n",
      "Epoch 30/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5056 - loss: 1.2519 - val_accuracy: 0.5211 - val_loss: 1.2731\n",
      "Epoch 31/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5476 - loss: 1.2316 - val_accuracy: 0.5211 - val_loss: 1.2578\n",
      "Epoch 32/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4892 - loss: 1.2100 - val_accuracy: 0.5211 - val_loss: 1.2471\n",
      "Epoch 33/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5282 - loss: 1.1840 - val_accuracy: 0.5282 - val_loss: 1.2357\n",
      "Epoch 34/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5893 - loss: 1.1467 - val_accuracy: 0.5634 - val_loss: 1.2284\n",
      "Epoch 35/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5867 - loss: 1.1557 - val_accuracy: 0.5704 - val_loss: 1.2182\n",
      "Epoch 36/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5272 - loss: 1.1262 - val_accuracy: 0.5704 - val_loss: 1.2090\n",
      "Epoch 37/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5441 - loss: 1.1525 - val_accuracy: 0.5775 - val_loss: 1.2003\n",
      "Epoch 38/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5488 - loss: 1.1381 - val_accuracy: 0.5775 - val_loss: 1.1946\n",
      "Epoch 39/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5749 - loss: 1.1076 - val_accuracy: 0.5845 - val_loss: 1.1869\n",
      "Epoch 40/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6002 - loss: 1.1099 - val_accuracy: 0.5986 - val_loss: 1.1806\n",
      "Epoch 41/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5199 - loss: 1.1670 - val_accuracy: 0.6056 - val_loss: 1.1738\n",
      "Epoch 42/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5979 - loss: 1.0986 - val_accuracy: 0.6127 - val_loss: 1.1669\n",
      "Epoch 43/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5843 - loss: 1.0445 - val_accuracy: 0.6127 - val_loss: 1.1628\n",
      "Epoch 44/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5682 - loss: 1.0908 - val_accuracy: 0.6127 - val_loss: 1.1574\n",
      "Epoch 45/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5311 - loss: 1.1491 - val_accuracy: 0.6197 - val_loss: 1.1507\n",
      "Epoch 46/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5896 - loss: 1.0750 - val_accuracy: 0.6338 - val_loss: 1.1454\n",
      "Epoch 47/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5450 - loss: 1.1216 - val_accuracy: 0.6268 - val_loss: 1.1436\n",
      "Epoch 48/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6062 - loss: 1.0166 - val_accuracy: 0.6268 - val_loss: 1.1379\n",
      "Epoch 49/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6131 - loss: 1.0641 - val_accuracy: 0.6268 - val_loss: 1.1337\n",
      "Epoch 50/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 1.1034 - val_accuracy: 0.6268 - val_loss: 1.1309\n",
      "Epoch 51/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6021 - loss: 1.0401 - val_accuracy: 0.6408 - val_loss: 1.1304\n",
      "Epoch 52/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 1.0823 - val_accuracy: 0.6268 - val_loss: 1.1245\n",
      "Epoch 53/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6197 - loss: 1.0553 - val_accuracy: 0.6268 - val_loss: 1.1206\n",
      "Epoch 54/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6104 - loss: 0.9811 - val_accuracy: 0.6338 - val_loss: 1.1178\n",
      "Epoch 55/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6097 - loss: 1.0153 - val_accuracy: 0.6338 - val_loss: 1.1167\n",
      "Epoch 56/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5873 - loss: 1.0512 - val_accuracy: 0.6408 - val_loss: 1.1125\n",
      "Epoch 57/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6057 - loss: 0.9743 - val_accuracy: 0.6408 - val_loss: 1.1092\n",
      "Epoch 58/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6383 - loss: 0.9530 - val_accuracy: 0.6268 - val_loss: 1.1045\n",
      "Epoch 59/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6150 - loss: 0.9925 - val_accuracy: 0.6338 - val_loss: 1.1019\n",
      "Epoch 60/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6298 - loss: 0.9812 - val_accuracy: 0.6549 - val_loss: 1.1003\n",
      "Epoch 61/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6391 - loss: 0.9468 - val_accuracy: 0.6338 - val_loss: 1.0935\n",
      "Epoch 62/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6612 - loss: 0.9319 - val_accuracy: 0.6479 - val_loss: 1.0928\n",
      "Epoch 63/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6302 - loss: 0.9806 - val_accuracy: 0.6549 - val_loss: 1.0910\n",
      "Epoch 64/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5795 - loss: 0.9799 - val_accuracy: 0.6549 - val_loss: 1.0870\n",
      "Epoch 65/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5437 - loss: 1.0690 - val_accuracy: 0.6549 - val_loss: 1.0868\n",
      "Epoch 66/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6631 - loss: 0.9328 - val_accuracy: 0.6549 - val_loss: 1.0845\n",
      "Epoch 67/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6570 - loss: 0.9106 - val_accuracy: 0.6479 - val_loss: 1.0829\n",
      "Epoch 68/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6425 - loss: 0.9506 - val_accuracy: 0.6479 - val_loss: 1.0827\n",
      "Epoch 69/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6429 - loss: 0.9080 - val_accuracy: 0.6549 - val_loss: 1.0810\n",
      "Epoch 70/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6292 - loss: 0.9314 - val_accuracy: 0.6479 - val_loss: 1.0815\n",
      "Epoch 71/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6467 - loss: 0.9033 - val_accuracy: 0.6479 - val_loss: 1.0813\n",
      "Epoch 72/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6162 - loss: 0.9679 - val_accuracy: 0.6479 - val_loss: 1.0757\n",
      "Epoch 73/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.9101 - val_accuracy: 0.6549 - val_loss: 1.0734\n",
      "Epoch 74/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6075 - loss: 0.9356 - val_accuracy: 0.6620 - val_loss: 1.0718\n",
      "Epoch 75/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6306 - loss: 0.9508 - val_accuracy: 0.6620 - val_loss: 1.0654\n",
      "Epoch 76/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6293 - loss: 0.9408 - val_accuracy: 0.6620 - val_loss: 1.0614\n",
      "Epoch 77/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6625 - loss: 0.9154 - val_accuracy: 0.6690 - val_loss: 1.0624\n",
      "Epoch 78/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6145 - loss: 0.9253 - val_accuracy: 0.6690 - val_loss: 1.0611\n",
      "Epoch 79/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6280 - loss: 0.9350 - val_accuracy: 0.6690 - val_loss: 1.0590\n",
      "Epoch 80/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6139 - loss: 0.9756 - val_accuracy: 0.6761 - val_loss: 1.0580\n",
      "Epoch 81/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5993 - loss: 0.9615 - val_accuracy: 0.6761 - val_loss: 1.0580\n",
      "Epoch 82/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6274 - loss: 0.9036 - val_accuracy: 0.6761 - val_loss: 1.0566\n",
      "Epoch 83/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6248 - loss: 0.9011 - val_accuracy: 0.6831 - val_loss: 1.0570\n",
      "Epoch 84/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6069 - loss: 0.9763 - val_accuracy: 0.6831 - val_loss: 1.0525\n",
      "Epoch 85/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6352 - loss: 0.9137 - val_accuracy: 0.6831 - val_loss: 1.0507\n",
      "Epoch 86/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6340 - loss: 0.9183 - val_accuracy: 0.6901 - val_loss: 1.0532\n",
      "Epoch 87/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6040 - loss: 0.9410 - val_accuracy: 0.6901 - val_loss: 1.0537\n",
      "Epoch 88/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6577 - loss: 0.8790 - val_accuracy: 0.6901 - val_loss: 1.0525\n",
      "Epoch 89/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6021 - loss: 0.9568 - val_accuracy: 0.6972 - val_loss: 1.0517\n",
      "Epoch 90/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6325 - loss: 0.9131 - val_accuracy: 0.6972 - val_loss: 1.0451\n",
      "Epoch 91/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6493 - loss: 0.8594 - val_accuracy: 0.7042 - val_loss: 1.0435\n",
      "Epoch 92/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6657 - loss: 0.8746 - val_accuracy: 0.7042 - val_loss: 1.0413\n",
      "Epoch 93/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5957 - loss: 0.9429 - val_accuracy: 0.6972 - val_loss: 1.0414\n",
      "Epoch 94/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6303 - loss: 0.9088 - val_accuracy: 0.7042 - val_loss: 1.0403\n",
      "Epoch 95/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6758 - loss: 0.8267 - val_accuracy: 0.7042 - val_loss: 1.0387\n",
      "Epoch 96/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6505 - loss: 0.8897 - val_accuracy: 0.7042 - val_loss: 1.0332\n",
      "Epoch 97/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 0.8821 - val_accuracy: 0.7042 - val_loss: 1.0325\n",
      "Epoch 98/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6621 - loss: 0.8365 - val_accuracy: 0.7042 - val_loss: 1.0310\n",
      "Epoch 99/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6452 - loss: 0.8695 - val_accuracy: 0.7042 - val_loss: 1.0298\n",
      "Epoch 100/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.8387 - val_accuracy: 0.7113 - val_loss: 1.0285\n",
      "Epoch 101/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.8550 - val_accuracy: 0.7042 - val_loss: 1.0217\n",
      "Epoch 102/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6590 - loss: 0.8134 - val_accuracy: 0.6972 - val_loss: 1.0198\n",
      "Epoch 103/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6829 - loss: 0.8333 - val_accuracy: 0.7042 - val_loss: 1.0146\n",
      "Epoch 104/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6898 - loss: 0.8083 - val_accuracy: 0.7113 - val_loss: 1.0124\n",
      "Epoch 105/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.8178 - val_accuracy: 0.7113 - val_loss: 1.0093\n",
      "Epoch 106/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6536 - loss: 0.8266 - val_accuracy: 0.7113 - val_loss: 1.0081\n",
      "Epoch 107/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6804 - loss: 0.8087 - val_accuracy: 0.7113 - val_loss: 0.9971\n",
      "Epoch 108/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6647 - loss: 0.8196 - val_accuracy: 0.7042 - val_loss: 0.9936\n",
      "Epoch 109/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 0.8511 - val_accuracy: 0.7113 - val_loss: 0.9953\n",
      "Epoch 110/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.8820 - val_accuracy: 0.7113 - val_loss: 0.9949\n",
      "Epoch 111/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6747 - loss: 0.8563 - val_accuracy: 0.7113 - val_loss: 0.9940\n",
      "Epoch 112/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6381 - loss: 0.8449 - val_accuracy: 0.7113 - val_loss: 0.9897\n",
      "Epoch 113/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6832 - loss: 0.8702 - val_accuracy: 0.7113 - val_loss: 0.9923\n",
      "Epoch 114/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6397 - loss: 0.8606 - val_accuracy: 0.7113 - val_loss: 0.9908\n",
      "Epoch 115/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6530 - loss: 0.8222 - val_accuracy: 0.7113 - val_loss: 0.9930\n",
      "Epoch 116/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.8027 - val_accuracy: 0.7113 - val_loss: 0.9904\n",
      "Epoch 117/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.7646 - val_accuracy: 0.7113 - val_loss: 0.9960\n",
      "Epoch 118/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6499 - loss: 0.8783 - val_accuracy: 0.7113 - val_loss: 0.9969\n",
      "Epoch 119/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6577 - loss: 0.8803 - val_accuracy: 0.7113 - val_loss: 0.9961\n",
      "Epoch 120/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6985 - loss: 0.7897 - val_accuracy: 0.7113 - val_loss: 0.9990\n",
      "Epoch 121/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.8117 - val_accuracy: 0.7113 - val_loss: 1.0011\n",
      "Epoch 122/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6151 - loss: 0.8655 - val_accuracy: 0.7113 - val_loss: 1.0066\n",
      "Epoch 123/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6668 - loss: 0.7910 - val_accuracy: 0.7113 - val_loss: 0.9995\n",
      "Epoch 124/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6206 - loss: 0.8982 - val_accuracy: 0.7113 - val_loss: 1.0013\n",
      "Epoch 125/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7043 - loss: 0.7694 - val_accuracy: 0.7042 - val_loss: 1.0051\n",
      "Epoch 126/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7084 - loss: 0.7851 - val_accuracy: 0.7042 - val_loss: 1.0039\n",
      "Epoch 127/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6513 - loss: 0.8113 - val_accuracy: 0.7113 - val_loss: 1.0035\n",
      "Epoch 128/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6182 - loss: 0.8596 - val_accuracy: 0.7042 - val_loss: 1.0040\n",
      "Epoch 129/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7181 - loss: 0.7430 - val_accuracy: 0.7042 - val_loss: 0.9986\n",
      "Epoch 130/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6844 - loss: 0.7839 - val_accuracy: 0.7113 - val_loss: 0.9929\n",
      "Epoch 131/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6054 - loss: 0.8898 - val_accuracy: 0.7183 - val_loss: 0.9901\n",
      "Epoch 132/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6544 - loss: 0.8000 - val_accuracy: 0.7113 - val_loss: 0.9834\n",
      "Epoch 133/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6648 - loss: 0.8215 - val_accuracy: 0.7183 - val_loss: 0.9813\n",
      "Epoch 134/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.8212 - val_accuracy: 0.7254 - val_loss: 0.9838\n",
      "Epoch 135/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6704 - loss: 0.8505 - val_accuracy: 0.7113 - val_loss: 0.9793\n",
      "Epoch 136/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 0.8385 - val_accuracy: 0.7183 - val_loss: 0.9724\n",
      "Epoch 137/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6407 - loss: 0.8031 - val_accuracy: 0.7183 - val_loss: 0.9676\n",
      "Epoch 138/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.7607 - val_accuracy: 0.7254 - val_loss: 0.9657\n",
      "Epoch 139/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.7866 - val_accuracy: 0.7113 - val_loss: 0.9637\n",
      "Epoch 140/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6883 - loss: 0.8105 - val_accuracy: 0.7183 - val_loss: 0.9648\n",
      "Epoch 141/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6319 - loss: 0.7925 - val_accuracy: 0.7113 - val_loss: 0.9663\n",
      "Epoch 142/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7366 - loss: 0.7296 - val_accuracy: 0.7113 - val_loss: 0.9674\n",
      "Epoch 143/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 0.8372 - val_accuracy: 0.7113 - val_loss: 0.9614\n",
      "Epoch 144/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7187 - loss: 0.7383 - val_accuracy: 0.7183 - val_loss: 0.9603\n",
      "Epoch 145/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6695 - loss: 0.7940 - val_accuracy: 0.7113 - val_loss: 0.9620\n",
      "Epoch 146/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6589 - loss: 0.7954 - val_accuracy: 0.7183 - val_loss: 0.9621\n",
      "Epoch 147/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.7511 - val_accuracy: 0.7183 - val_loss: 0.9548\n",
      "Epoch 148/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6702 - loss: 0.7772 - val_accuracy: 0.7183 - val_loss: 0.9523\n",
      "Epoch 149/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6584 - loss: 0.7961 - val_accuracy: 0.7183 - val_loss: 0.9429\n",
      "Epoch 150/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6612 - loss: 0.7867 - val_accuracy: 0.7113 - val_loss: 0.9357\n",
      "Epoch 151/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6542 - loss: 0.8005 - val_accuracy: 0.7113 - val_loss: 0.9365\n",
      "Epoch 152/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7093 - loss: 0.7306 - val_accuracy: 0.7113 - val_loss: 0.9331\n",
      "Epoch 153/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 0.8340 - val_accuracy: 0.7254 - val_loss: 0.9320\n",
      "Epoch 154/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6345 - loss: 0.8472 - val_accuracy: 0.7183 - val_loss: 0.9289\n",
      "Epoch 155/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6836 - loss: 0.8034 - val_accuracy: 0.7113 - val_loss: 0.9274\n",
      "Epoch 156/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6799 - loss: 0.8238 - val_accuracy: 0.7113 - val_loss: 0.9242\n",
      "Epoch 157/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7059 - loss: 0.7536 - val_accuracy: 0.7183 - val_loss: 0.9235\n",
      "Epoch 158/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7070 - loss: 0.7718 - val_accuracy: 0.7113 - val_loss: 0.9255\n",
      "Epoch 159/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.7186 - val_accuracy: 0.7042 - val_loss: 0.9180\n",
      "Epoch 160/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6963 - loss: 0.8001 - val_accuracy: 0.7113 - val_loss: 0.9104\n",
      "Epoch 161/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 0.7600 - val_accuracy: 0.7254 - val_loss: 0.9082\n",
      "Epoch 162/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.7815 - val_accuracy: 0.7254 - val_loss: 0.9097\n",
      "Epoch 163/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6987 - loss: 0.7436 - val_accuracy: 0.7113 - val_loss: 0.9111\n",
      "Epoch 164/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6794 - loss: 0.7440 - val_accuracy: 0.7113 - val_loss: 0.9097\n",
      "Epoch 165/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6851 - loss: 0.7739 - val_accuracy: 0.7183 - val_loss: 0.9063\n",
      "Epoch 166/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6973 - loss: 0.7041 - val_accuracy: 0.7183 - val_loss: 0.9046\n",
      "Epoch 167/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7146 - loss: 0.7516 - val_accuracy: 0.7183 - val_loss: 0.9017\n",
      "Epoch 168/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6699 - loss: 0.7965 - val_accuracy: 0.7183 - val_loss: 0.9039\n",
      "Epoch 169/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.7415 - val_accuracy: 0.7183 - val_loss: 0.9018\n",
      "Epoch 170/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.7026 - val_accuracy: 0.7183 - val_loss: 0.8978\n",
      "Epoch 171/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7209 - loss: 0.7405 - val_accuracy: 0.7183 - val_loss: 0.8905\n",
      "Epoch 172/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6850 - loss: 0.7853 - val_accuracy: 0.7183 - val_loss: 0.8889\n",
      "Epoch 173/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6977 - loss: 0.7386 - val_accuracy: 0.7254 - val_loss: 0.8929\n",
      "Epoch 174/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7449 - loss: 0.7101 - val_accuracy: 0.7183 - val_loss: 0.8854\n",
      "Epoch 175/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6946 - loss: 0.7654 - val_accuracy: 0.7254 - val_loss: 0.8887\n",
      "Epoch 176/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7211 - loss: 0.7500 - val_accuracy: 0.7254 - val_loss: 0.8852\n",
      "Epoch 177/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6995 - loss: 0.7277 - val_accuracy: 0.7324 - val_loss: 0.8870\n",
      "Epoch 178/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7106 - loss: 0.7593 - val_accuracy: 0.7254 - val_loss: 0.8881\n",
      "Epoch 179/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7333 - loss: 0.6753 - val_accuracy: 0.7254 - val_loss: 0.8914\n",
      "Epoch 180/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7318 - loss: 0.6970 - val_accuracy: 0.7254 - val_loss: 0.8920\n",
      "Epoch 181/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7126 - loss: 0.7261 - val_accuracy: 0.7254 - val_loss: 0.8917\n",
      "Epoch 182/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.7412 - val_accuracy: 0.7254 - val_loss: 0.8832\n",
      "Epoch 183/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.7567 - val_accuracy: 0.7254 - val_loss: 0.8767\n",
      "Epoch 184/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7005 - loss: 0.7678 - val_accuracy: 0.7324 - val_loss: 0.8746\n",
      "Epoch 185/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.7599 - val_accuracy: 0.7324 - val_loss: 0.8732\n",
      "Epoch 186/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7483 - loss: 0.6807 - val_accuracy: 0.7254 - val_loss: 0.8798\n",
      "Epoch 187/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6958 - loss: 0.7633 - val_accuracy: 0.7324 - val_loss: 0.8799\n",
      "Epoch 188/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7018 - loss: 0.7402 - val_accuracy: 0.7324 - val_loss: 0.8740\n",
      "Epoch 189/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7361 - loss: 0.6492 - val_accuracy: 0.7324 - val_loss: 0.8839\n",
      "Epoch 190/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7035 - loss: 0.7311 - val_accuracy: 0.7324 - val_loss: 0.8802\n",
      "Epoch 191/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.7084 - val_accuracy: 0.7324 - val_loss: 0.8768\n",
      "Epoch 192/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7128 - loss: 0.7353 - val_accuracy: 0.7324 - val_loss: 0.8740\n",
      "Epoch 193/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7002 - loss: 0.7497 - val_accuracy: 0.7324 - val_loss: 0.8780\n",
      "Epoch 194/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7149 - loss: 0.6911 - val_accuracy: 0.7254 - val_loss: 0.8809\n",
      "Epoch 195/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7179 - loss: 0.6881 - val_accuracy: 0.7254 - val_loss: 0.8833\n",
      "Epoch 196/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 0.7244 - val_accuracy: 0.7465 - val_loss: 0.8798\n",
      "Epoch 197/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 0.7586 - val_accuracy: 0.7394 - val_loss: 0.8742\n",
      "Epoch 198/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7286 - loss: 0.6687 - val_accuracy: 0.7394 - val_loss: 0.8763\n",
      "Epoch 199/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.7202 - val_accuracy: 0.7465 - val_loss: 0.8774\n",
      "Epoch 200/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6706 - loss: 0.7901 - val_accuracy: 0.7394 - val_loss: 0.8780\n",
      "Epoch 201/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6686 - loss: 0.7552 - val_accuracy: 0.7394 - val_loss: 0.8773\n",
      "Epoch 202/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6623 - loss: 0.7573 - val_accuracy: 0.7394 - val_loss: 0.8738\n",
      "Epoch 203/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.7406 - val_accuracy: 0.7394 - val_loss: 0.8781\n",
      "Epoch 204/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.7258 - val_accuracy: 0.7394 - val_loss: 0.8769\n",
      "Epoch 205/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 0.7264 - val_accuracy: 0.7394 - val_loss: 0.8798\n",
      "Epoch 206/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6901 - loss: 0.7771 - val_accuracy: 0.7465 - val_loss: 0.8866\n",
      "Epoch 207/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7377 - loss: 0.6582 - val_accuracy: 0.7394 - val_loss: 0.8853\n",
      "Epoch 208/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7144 - loss: 0.7647 - val_accuracy: 0.7324 - val_loss: 0.8903\n",
      "Epoch 209/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6923 - loss: 0.7478 - val_accuracy: 0.7465 - val_loss: 0.8910\n",
      "Epoch 210/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6952 - loss: 0.7209 - val_accuracy: 0.7394 - val_loss: 0.8828\n",
      "Epoch 211/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7004 - loss: 0.6766 - val_accuracy: 0.7465 - val_loss: 0.8889\n",
      "Epoch 212/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.7057 - val_accuracy: 0.7394 - val_loss: 0.8888\n",
      "Epoch 213/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6647 - loss: 0.7544 - val_accuracy: 0.7394 - val_loss: 0.8866\n",
      "Epoch 214/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.7768 - val_accuracy: 0.7394 - val_loss: 0.8793\n",
      "Epoch 215/500\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.7276 - val_accuracy: 0.7394 - val_loss: 0.8788\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(55, activation='relu'),\n",
    "    BatchNormalization(),  # Helps stabilize training\n",
    "    Dropout(0.3),\n",
    "    Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "   \n",
    "    Dense(label_count, activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(learning_rate=0.00008), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(model.summary())\n",
    "#implement early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_split=0.2,callbacks=early_stopping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "stringnames = [\"E\", \"A\", \"D\", \"G\", \"B\", \"h_E\"]\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=stringnames, yticklabels=stringnames)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "ERROR:tf2onnx.tfonnx:rewriter <function rewrite_constant_fold at 0x0000027D46C70550>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4)\n"
     ]
    }
   ],
   "source": [
    "model.save('stringDetectionML.h5')\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "model.output_names=['output']\n",
    "input_signature = [tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name='digit')]\n",
    "print(model.inputs[0].shape) \n",
    "# Convert the Keras model to ONNX format\n",
    "#onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, opset=13)\n",
    "\n",
    "\n",
    "(onnx_model_proto, storage) = tf2onnx.convert.from_keras(model,input_signature=input_signature, opset=13)\n",
    "\n",
    "dir = os.getcwd()\n",
    "dir = dir.split(\"/\")[0]\n",
    "while( path.basename(dir) != \"TabGenerator\"): # go to the TabGenerator directory\n",
    "    dir = os.path.dirname(dir)\n",
    "\n",
    "dir = os.path.join(dir, \"Assets\",\"MachineLearning\",\"MLModels\")\n",
    "onnxpath = os.path.join(dir, \"stringDetectionML_ONNX.onnx\")\n",
    "\n",
    "with open(onnxpath, \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
