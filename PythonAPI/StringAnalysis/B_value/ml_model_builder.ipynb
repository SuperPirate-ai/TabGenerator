{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Normalization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1415, 4)\n",
      "Training labels shape: (1415, 6)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"b_values.json\") as f:\n",
    "#     b_values = json.load(f)\n",
    "    \n",
    "# with open(\"avg_amplitude_ratios.json\") as f:\n",
    "#     avg_amplitude_ratios = json.load(f)\n",
    "\n",
    "with open(\"results.csv\") as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "strings = [\"h_E\", \"B\", \"G\", \"D\", \"A\", \"E\"]\n",
    "labels = np.array([0,1,2,3,4,5])\n",
    "# strings = [\"1-2h_E\", \"1-2B\", \"1-2G\", \"1-2D\", \"1-2A\", \"1-2E\", \"2-2h_E\", \"2-2B\", \"2-2G\", \"2-2D\", \"2-2A\", \"2-2E\"]\n",
    "# labels = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "\n",
    "\n",
    "data = []\n",
    "label_list = []\n",
    "\n",
    "for i, line in enumerate(results):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    string,metric,amp_ra,deviation,f0 = line.split(\",\")\n",
    "    if string in strings:\n",
    "        metric = float(metric)\n",
    "        amp_ra = float(amp_ra)\n",
    "        deviation = float(deviation)\n",
    "        f0 = float(f0)\n",
    "        data.append([metric,amp_ra, deviation,f0])\n",
    "        label_list.append(labels[strings.index(string)])\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_count = 6\n",
    "labels_categorical = tf.keras.utils.to_categorical(label_list, num_classes=label_count)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert your data to numpy arrays if they are not already\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "val_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 2)\n",
    "print(f\"Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#normalize data\n",
    "normalization_layer = Normalization(input_shape=(X_train.shape[1],))\n",
    "normalization_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │           \u001b[38;5;34m275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │         \u001b[38;5;34m3,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,574</span> (21.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,574\u001b[0m (21.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,455</span> (21.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,455\u001b[0m (21.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m119\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.1901 - loss: 1.8952 - val_accuracy: 0.2933 - val_loss: 1.7579\n",
      "Epoch 2/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2258 - loss: 1.7874 - val_accuracy: 0.3428 - val_loss: 1.7318\n",
      "Epoch 3/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2735 - loss: 1.7320 - val_accuracy: 0.3958 - val_loss: 1.7001\n",
      "Epoch 4/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3315 - loss: 1.6129 - val_accuracy: 0.4629 - val_loss: 1.6630\n",
      "Epoch 5/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3382 - loss: 1.5767 - val_accuracy: 0.4947 - val_loss: 1.6219\n",
      "Epoch 6/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3892 - loss: 1.5128 - val_accuracy: 0.5265 - val_loss: 1.5747\n",
      "Epoch 7/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4124 - loss: 1.4574 - val_accuracy: 0.5336 - val_loss: 1.5251\n",
      "Epoch 8/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4250 - loss: 1.4530 - val_accuracy: 0.5371 - val_loss: 1.4743\n",
      "Epoch 9/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4477 - loss: 1.4026 - val_accuracy: 0.5654 - val_loss: 1.4213\n",
      "Epoch 10/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4857 - loss: 1.3480 - val_accuracy: 0.5760 - val_loss: 1.3706\n",
      "Epoch 11/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4454 - loss: 1.3392 - val_accuracy: 0.5830 - val_loss: 1.3238\n",
      "Epoch 12/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4642 - loss: 1.2859 - val_accuracy: 0.6078 - val_loss: 1.2804\n",
      "Epoch 13/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4908 - loss: 1.2486 - val_accuracy: 0.6325 - val_loss: 1.2434\n",
      "Epoch 14/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5118 - loss: 1.2774 - val_accuracy: 0.6325 - val_loss: 1.2081\n",
      "Epoch 15/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5345 - loss: 1.1990 - val_accuracy: 0.6466 - val_loss: 1.1753\n",
      "Epoch 16/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5214 - loss: 1.1790 - val_accuracy: 0.6466 - val_loss: 1.1471\n",
      "Epoch 17/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5242 - loss: 1.1819 - val_accuracy: 0.6502 - val_loss: 1.1189\n",
      "Epoch 18/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5864 - loss: 1.1238 - val_accuracy: 0.6608 - val_loss: 1.0937\n",
      "Epoch 19/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5434 - loss: 1.1583 - val_accuracy: 0.6643 - val_loss: 1.0712\n",
      "Epoch 20/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5734 - loss: 1.1102 - val_accuracy: 0.6678 - val_loss: 1.0484\n",
      "Epoch 21/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 1.0881 - val_accuracy: 0.6820 - val_loss: 1.0263\n",
      "Epoch 22/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5738 - loss: 1.0743 - val_accuracy: 0.6996 - val_loss: 1.0070\n",
      "Epoch 23/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6252 - loss: 1.0193 - val_accuracy: 0.6996 - val_loss: 0.9905\n",
      "Epoch 24/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6166 - loss: 1.0352 - val_accuracy: 0.7067 - val_loss: 0.9755\n",
      "Epoch 25/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5977 - loss: 1.0125 - val_accuracy: 0.7138 - val_loss: 0.9573\n",
      "Epoch 26/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5968 - loss: 0.9902 - val_accuracy: 0.7067 - val_loss: 0.9455\n",
      "Epoch 27/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6176 - loss: 0.9869 - val_accuracy: 0.6926 - val_loss: 0.9312\n",
      "Epoch 28/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6159 - loss: 0.9956 - val_accuracy: 0.7173 - val_loss: 0.9174\n",
      "Epoch 29/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5975 - loss: 1.0065 - val_accuracy: 0.7173 - val_loss: 0.9048\n",
      "Epoch 30/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6199 - loss: 0.9622 - val_accuracy: 0.7138 - val_loss: 0.8951\n",
      "Epoch 31/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6097 - loss: 0.9564 - val_accuracy: 0.7173 - val_loss: 0.8843\n",
      "Epoch 32/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.9416 - val_accuracy: 0.7350 - val_loss: 0.8705\n",
      "Epoch 33/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6278 - loss: 0.9077 - val_accuracy: 0.7350 - val_loss: 0.8585\n",
      "Epoch 34/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6388 - loss: 0.9239 - val_accuracy: 0.7279 - val_loss: 0.8518\n",
      "Epoch 35/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6395 - loss: 0.9225 - val_accuracy: 0.7279 - val_loss: 0.8448\n",
      "Epoch 36/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6443 - loss: 0.8882 - val_accuracy: 0.7385 - val_loss: 0.8330\n",
      "Epoch 37/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6356 - loss: 0.8937 - val_accuracy: 0.7491 - val_loss: 0.8234\n",
      "Epoch 38/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6388 - loss: 0.8773 - val_accuracy: 0.7420 - val_loss: 0.8159\n",
      "Epoch 39/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6168 - loss: 0.8937 - val_accuracy: 0.7420 - val_loss: 0.8086\n",
      "Epoch 40/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6139 - loss: 0.9078 - val_accuracy: 0.7420 - val_loss: 0.8050\n",
      "Epoch 41/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6344 - loss: 0.8713 - val_accuracy: 0.7456 - val_loss: 0.7962\n",
      "Epoch 42/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6156 - loss: 0.8879 - val_accuracy: 0.7597 - val_loss: 0.7867\n",
      "Epoch 43/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 0.8973 - val_accuracy: 0.7491 - val_loss: 0.7807\n",
      "Epoch 44/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6400 - loss: 0.8882 - val_accuracy: 0.7562 - val_loss: 0.7733\n",
      "Epoch 45/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.9090 - val_accuracy: 0.7562 - val_loss: 0.7691\n",
      "Epoch 46/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6381 - loss: 0.8732 - val_accuracy: 0.7633 - val_loss: 0.7628\n",
      "Epoch 47/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 0.8588 - val_accuracy: 0.7633 - val_loss: 0.7595\n",
      "Epoch 48/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6815 - loss: 0.8138 - val_accuracy: 0.7633 - val_loss: 0.7543\n",
      "Epoch 49/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6415 - loss: 0.8579 - val_accuracy: 0.7633 - val_loss: 0.7489\n",
      "Epoch 50/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6681 - loss: 0.8129 - val_accuracy: 0.7668 - val_loss: 0.7423\n",
      "Epoch 51/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6479 - loss: 0.8624 - val_accuracy: 0.7668 - val_loss: 0.7371\n",
      "Epoch 52/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6630 - loss: 0.8208 - val_accuracy: 0.7668 - val_loss: 0.7337\n",
      "Epoch 53/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.7899 - val_accuracy: 0.7597 - val_loss: 0.7312\n",
      "Epoch 54/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6892 - loss: 0.7939 - val_accuracy: 0.7597 - val_loss: 0.7255\n",
      "Epoch 55/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6730 - loss: 0.8477 - val_accuracy: 0.7527 - val_loss: 0.7219\n",
      "Epoch 56/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6862 - loss: 0.7952 - val_accuracy: 0.7597 - val_loss: 0.7192\n",
      "Epoch 57/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6654 - loss: 0.8198 - val_accuracy: 0.7597 - val_loss: 0.7126\n",
      "Epoch 58/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6545 - loss: 0.8351 - val_accuracy: 0.7562 - val_loss: 0.7090\n",
      "Epoch 59/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7213 - loss: 0.7399 - val_accuracy: 0.7668 - val_loss: 0.7063\n",
      "Epoch 60/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6723 - loss: 0.8011 - val_accuracy: 0.7597 - val_loss: 0.7030\n",
      "Epoch 61/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.8133 - val_accuracy: 0.7633 - val_loss: 0.6994\n",
      "Epoch 62/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6510 - loss: 0.7990 - val_accuracy: 0.7633 - val_loss: 0.6965\n",
      "Epoch 63/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6800 - loss: 0.7871 - val_accuracy: 0.7562 - val_loss: 0.6947\n",
      "Epoch 64/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6778 - loss: 0.7795 - val_accuracy: 0.7597 - val_loss: 0.6941\n",
      "Epoch 65/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6856 - loss: 0.7875 - val_accuracy: 0.7562 - val_loss: 0.6916\n",
      "Epoch 66/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6647 - loss: 0.8245 - val_accuracy: 0.7597 - val_loss: 0.6887\n",
      "Epoch 67/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.7590 - val_accuracy: 0.7668 - val_loss: 0.6832\n",
      "Epoch 68/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6755 - loss: 0.7740 - val_accuracy: 0.7703 - val_loss: 0.6805\n",
      "Epoch 69/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6723 - loss: 0.7672 - val_accuracy: 0.7739 - val_loss: 0.6779\n",
      "Epoch 70/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7051 - loss: 0.7345 - val_accuracy: 0.7739 - val_loss: 0.6752\n",
      "Epoch 71/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 0.7836 - val_accuracy: 0.7668 - val_loss: 0.6719\n",
      "Epoch 72/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.7937 - val_accuracy: 0.7774 - val_loss: 0.6702\n",
      "Epoch 73/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6454 - loss: 0.7890 - val_accuracy: 0.7809 - val_loss: 0.6667\n",
      "Epoch 74/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.7393 - val_accuracy: 0.7774 - val_loss: 0.6670\n",
      "Epoch 75/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6553 - loss: 0.7906 - val_accuracy: 0.7703 - val_loss: 0.6635\n",
      "Epoch 76/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6809 - loss: 0.7507 - val_accuracy: 0.7774 - val_loss: 0.6629\n",
      "Epoch 77/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7065 - loss: 0.7686 - val_accuracy: 0.7845 - val_loss: 0.6593\n",
      "Epoch 78/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7152 - loss: 0.7413 - val_accuracy: 0.8057 - val_loss: 0.6566\n",
      "Epoch 79/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6724 - loss: 0.7769 - val_accuracy: 0.8021 - val_loss: 0.6537\n",
      "Epoch 80/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.7195 - val_accuracy: 0.8021 - val_loss: 0.6514\n",
      "Epoch 81/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6986 - loss: 0.7511 - val_accuracy: 0.8092 - val_loss: 0.6497\n",
      "Epoch 82/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7029 - loss: 0.7293 - val_accuracy: 0.7951 - val_loss: 0.6507\n",
      "Epoch 83/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7289 - loss: 0.7321 - val_accuracy: 0.8057 - val_loss: 0.6464\n",
      "Epoch 84/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7114 - loss: 0.7715 - val_accuracy: 0.8092 - val_loss: 0.6433\n",
      "Epoch 85/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6835 - loss: 0.7583 - val_accuracy: 0.8092 - val_loss: 0.6414\n",
      "Epoch 86/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7069 - loss: 0.7255 - val_accuracy: 0.8163 - val_loss: 0.6401\n",
      "Epoch 87/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.7291 - val_accuracy: 0.8127 - val_loss: 0.6365\n",
      "Epoch 88/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.7581 - val_accuracy: 0.8092 - val_loss: 0.6350\n",
      "Epoch 89/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7052 - loss: 0.7190 - val_accuracy: 0.8057 - val_loss: 0.6340\n",
      "Epoch 90/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7175 - loss: 0.6969 - val_accuracy: 0.8057 - val_loss: 0.6353\n",
      "Epoch 91/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6931 - loss: 0.7269 - val_accuracy: 0.7986 - val_loss: 0.6338\n",
      "Epoch 92/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7137 - loss: 0.7268 - val_accuracy: 0.8092 - val_loss: 0.6308\n",
      "Epoch 93/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7143 - loss: 0.7015 - val_accuracy: 0.8092 - val_loss: 0.6300\n",
      "Epoch 94/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7179 - loss: 0.7147 - val_accuracy: 0.7986 - val_loss: 0.6296\n",
      "Epoch 95/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6973 - loss: 0.7311 - val_accuracy: 0.8057 - val_loss: 0.6262\n",
      "Epoch 96/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.6945 - val_accuracy: 0.8057 - val_loss: 0.6263\n",
      "Epoch 97/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6823 - loss: 0.7548 - val_accuracy: 0.8057 - val_loss: 0.6256\n",
      "Epoch 98/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 0.7332 - val_accuracy: 0.8057 - val_loss: 0.6239\n",
      "Epoch 99/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7148 - loss: 0.7083 - val_accuracy: 0.8021 - val_loss: 0.6221\n",
      "Epoch 100/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.7291 - val_accuracy: 0.8021 - val_loss: 0.6233\n",
      "Epoch 101/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6771 - loss: 0.7658 - val_accuracy: 0.7951 - val_loss: 0.6212\n",
      "Epoch 102/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6828 - loss: 0.7183 - val_accuracy: 0.8092 - val_loss: 0.6182\n",
      "Epoch 103/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.7562 - val_accuracy: 0.8021 - val_loss: 0.6177\n",
      "Epoch 104/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6726 - loss: 0.7662 - val_accuracy: 0.8057 - val_loss: 0.6136\n",
      "Epoch 105/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7152 - loss: 0.6984 - val_accuracy: 0.8163 - val_loss: 0.6105\n",
      "Epoch 106/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.7166 - val_accuracy: 0.8127 - val_loss: 0.6094\n",
      "Epoch 107/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6974 - loss: 0.7201 - val_accuracy: 0.8198 - val_loss: 0.6061\n",
      "Epoch 108/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7352 - loss: 0.6596 - val_accuracy: 0.8127 - val_loss: 0.6066\n",
      "Epoch 109/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.6914 - val_accuracy: 0.8057 - val_loss: 0.6069\n",
      "Epoch 110/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.7002 - val_accuracy: 0.8127 - val_loss: 0.6074\n",
      "Epoch 111/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7046 - loss: 0.7031 - val_accuracy: 0.8057 - val_loss: 0.6054\n",
      "Epoch 112/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7165 - loss: 0.7076 - val_accuracy: 0.8127 - val_loss: 0.6045\n",
      "Epoch 113/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.6494 - val_accuracy: 0.8163 - val_loss: 0.6008\n",
      "Epoch 114/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6957 - loss: 0.7242 - val_accuracy: 0.8198 - val_loss: 0.6013\n",
      "Epoch 115/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6777 - loss: 0.7327 - val_accuracy: 0.8198 - val_loss: 0.6007\n",
      "Epoch 116/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.6714 - val_accuracy: 0.8127 - val_loss: 0.6007\n",
      "Epoch 117/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7027 - loss: 0.7077 - val_accuracy: 0.8163 - val_loss: 0.5998\n",
      "Epoch 118/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.6660 - val_accuracy: 0.8269 - val_loss: 0.5957\n",
      "Epoch 119/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7242 - loss: 0.7013 - val_accuracy: 0.8304 - val_loss: 0.5950\n",
      "Epoch 120/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7233 - loss: 0.6869 - val_accuracy: 0.8198 - val_loss: 0.5937\n",
      "Epoch 121/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7575 - loss: 0.6515 - val_accuracy: 0.8269 - val_loss: 0.5914\n",
      "Epoch 122/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7148 - loss: 0.7104 - val_accuracy: 0.8233 - val_loss: 0.5891\n",
      "Epoch 123/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 0.6372 - val_accuracy: 0.8269 - val_loss: 0.5881\n",
      "Epoch 124/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7014 - loss: 0.7040 - val_accuracy: 0.8269 - val_loss: 0.5886\n",
      "Epoch 125/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7352 - loss: 0.6533 - val_accuracy: 0.8269 - val_loss: 0.5848\n",
      "Epoch 126/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7131 - loss: 0.7209 - val_accuracy: 0.8304 - val_loss: 0.5853\n",
      "Epoch 127/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.7239 - val_accuracy: 0.8304 - val_loss: 0.5834\n",
      "Epoch 128/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7588 - loss: 0.6541 - val_accuracy: 0.8304 - val_loss: 0.5833\n",
      "Epoch 129/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.6637 - val_accuracy: 0.8269 - val_loss: 0.5835\n",
      "Epoch 130/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 0.6921 - val_accuracy: 0.8269 - val_loss: 0.5835\n",
      "Epoch 131/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7541 - loss: 0.6596 - val_accuracy: 0.8198 - val_loss: 0.5831\n",
      "Epoch 132/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7445 - loss: 0.6747 - val_accuracy: 0.8163 - val_loss: 0.5825\n",
      "Epoch 133/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7234 - loss: 0.6624 - val_accuracy: 0.8198 - val_loss: 0.5822\n",
      "Epoch 134/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.6090 - val_accuracy: 0.8163 - val_loss: 0.5822\n",
      "Epoch 135/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7280 - loss: 0.6928 - val_accuracy: 0.8163 - val_loss: 0.5822\n",
      "Epoch 136/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.6650 - val_accuracy: 0.8233 - val_loss: 0.5802\n",
      "Epoch 137/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7301 - loss: 0.6480 - val_accuracy: 0.8233 - val_loss: 0.5781\n",
      "Epoch 138/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7277 - loss: 0.6808 - val_accuracy: 0.8269 - val_loss: 0.5750\n",
      "Epoch 139/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7076 - loss: 0.7089 - val_accuracy: 0.8269 - val_loss: 0.5724\n",
      "Epoch 140/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7592 - loss: 0.6121 - val_accuracy: 0.8304 - val_loss: 0.5709\n",
      "Epoch 141/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7240 - loss: 0.6644 - val_accuracy: 0.8269 - val_loss: 0.5717\n",
      "Epoch 142/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6973 - loss: 0.6823 - val_accuracy: 0.8198 - val_loss: 0.5713\n",
      "Epoch 143/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7121 - loss: 0.6925 - val_accuracy: 0.8233 - val_loss: 0.5694\n",
      "Epoch 144/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7361 - loss: 0.6593 - val_accuracy: 0.8198 - val_loss: 0.5697\n",
      "Epoch 145/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7229 - loss: 0.6672 - val_accuracy: 0.8163 - val_loss: 0.5686\n",
      "Epoch 146/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7254 - loss: 0.6688 - val_accuracy: 0.8304 - val_loss: 0.5645\n",
      "Epoch 147/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 0.6808 - val_accuracy: 0.8304 - val_loss: 0.5633\n",
      "Epoch 148/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.6504 - val_accuracy: 0.8304 - val_loss: 0.5631\n",
      "Epoch 149/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.7024 - val_accuracy: 0.8304 - val_loss: 0.5631\n",
      "Epoch 150/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7159 - loss: 0.7091 - val_accuracy: 0.8304 - val_loss: 0.5600\n",
      "Epoch 151/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7245 - loss: 0.6841 - val_accuracy: 0.8339 - val_loss: 0.5608\n",
      "Epoch 152/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7321 - loss: 0.6616 - val_accuracy: 0.8233 - val_loss: 0.5625\n",
      "Epoch 153/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.6436 - val_accuracy: 0.8304 - val_loss: 0.5582\n",
      "Epoch 154/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7232 - loss: 0.6629 - val_accuracy: 0.8339 - val_loss: 0.5589\n",
      "Epoch 155/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7091 - loss: 0.6918 - val_accuracy: 0.8304 - val_loss: 0.5564\n",
      "Epoch 156/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.6807 - val_accuracy: 0.8304 - val_loss: 0.5577\n",
      "Epoch 157/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.6730 - val_accuracy: 0.8339 - val_loss: 0.5561\n",
      "Epoch 158/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7347 - loss: 0.6545 - val_accuracy: 0.8304 - val_loss: 0.5583\n",
      "Epoch 159/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7115 - loss: 0.6931 - val_accuracy: 0.8304 - val_loss: 0.5571\n",
      "Epoch 160/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7418 - loss: 0.6557 - val_accuracy: 0.8304 - val_loss: 0.5558\n",
      "Epoch 161/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.6175 - val_accuracy: 0.8304 - val_loss: 0.5549\n",
      "Epoch 162/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7168 - loss: 0.7033 - val_accuracy: 0.8339 - val_loss: 0.5531\n",
      "Epoch 163/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7548 - loss: 0.6107 - val_accuracy: 0.8339 - val_loss: 0.5516\n",
      "Epoch 164/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7257 - loss: 0.6623 - val_accuracy: 0.8304 - val_loss: 0.5534\n",
      "Epoch 165/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7553 - loss: 0.6328 - val_accuracy: 0.8339 - val_loss: 0.5509\n",
      "Epoch 166/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7460 - loss: 0.6207 - val_accuracy: 0.8304 - val_loss: 0.5510\n",
      "Epoch 167/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.6358 - val_accuracy: 0.8339 - val_loss: 0.5516\n",
      "Epoch 168/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7414 - loss: 0.6387 - val_accuracy: 0.8375 - val_loss: 0.5483\n",
      "Epoch 169/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7318 - loss: 0.6611 - val_accuracy: 0.8375 - val_loss: 0.5496\n",
      "Epoch 170/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7238 - loss: 0.6989 - val_accuracy: 0.8339 - val_loss: 0.5476\n",
      "Epoch 171/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7362 - loss: 0.6466 - val_accuracy: 0.8304 - val_loss: 0.5455\n",
      "Epoch 172/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 0.6864 - val_accuracy: 0.8375 - val_loss: 0.5451\n",
      "Epoch 173/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7412 - loss: 0.6499 - val_accuracy: 0.8339 - val_loss: 0.5443\n",
      "Epoch 174/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7549 - loss: 0.6516 - val_accuracy: 0.8269 - val_loss: 0.5451\n",
      "Epoch 175/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7325 - loss: 0.6514 - val_accuracy: 0.8339 - val_loss: 0.5430\n",
      "Epoch 176/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7276 - loss: 0.6905 - val_accuracy: 0.8304 - val_loss: 0.5410\n",
      "Epoch 177/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7390 - loss: 0.6460 - val_accuracy: 0.8375 - val_loss: 0.5381\n",
      "Epoch 178/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7588 - loss: 0.6296 - val_accuracy: 0.8410 - val_loss: 0.5370\n",
      "Epoch 179/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7267 - loss: 0.6813 - val_accuracy: 0.8375 - val_loss: 0.5385\n",
      "Epoch 180/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7252 - loss: 0.6975 - val_accuracy: 0.8375 - val_loss: 0.5393\n",
      "Epoch 181/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7399 - loss: 0.6460 - val_accuracy: 0.8269 - val_loss: 0.5394\n",
      "Epoch 182/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7304 - loss: 0.6346 - val_accuracy: 0.8339 - val_loss: 0.5400\n",
      "Epoch 183/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7489 - loss: 0.6209 - val_accuracy: 0.8304 - val_loss: 0.5388\n",
      "Epoch 184/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 0.6416 - val_accuracy: 0.8304 - val_loss: 0.5370\n",
      "Epoch 185/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.6609 - val_accuracy: 0.8269 - val_loss: 0.5354\n",
      "Epoch 186/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7726 - loss: 0.6048 - val_accuracy: 0.8339 - val_loss: 0.5334\n",
      "Epoch 187/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7353 - loss: 0.6447 - val_accuracy: 0.8339 - val_loss: 0.5315\n",
      "Epoch 188/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.6331 - val_accuracy: 0.8269 - val_loss: 0.5304\n",
      "Epoch 189/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.6235 - val_accuracy: 0.8339 - val_loss: 0.5301\n",
      "Epoch 190/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7433 - loss: 0.6526 - val_accuracy: 0.8375 - val_loss: 0.5303\n",
      "Epoch 191/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7144 - loss: 0.7054 - val_accuracy: 0.8375 - val_loss: 0.5284\n",
      "Epoch 192/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7316 - loss: 0.6483 - val_accuracy: 0.8339 - val_loss: 0.5299\n",
      "Epoch 193/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7536 - loss: 0.6850 - val_accuracy: 0.8410 - val_loss: 0.5324\n",
      "Epoch 194/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7659 - loss: 0.5739 - val_accuracy: 0.8375 - val_loss: 0.5334\n",
      "Epoch 195/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7616 - loss: 0.5851 - val_accuracy: 0.8410 - val_loss: 0.5325\n",
      "Epoch 196/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7671 - loss: 0.5989 - val_accuracy: 0.8410 - val_loss: 0.5270\n",
      "Epoch 197/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6153 - val_accuracy: 0.8375 - val_loss: 0.5251\n",
      "Epoch 198/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7413 - loss: 0.6114 - val_accuracy: 0.8339 - val_loss: 0.5277\n",
      "Epoch 199/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7655 - loss: 0.6397 - val_accuracy: 0.8375 - val_loss: 0.5253\n",
      "Epoch 200/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7606 - loss: 0.5772 - val_accuracy: 0.8375 - val_loss: 0.5232\n",
      "Epoch 201/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.5751 - val_accuracy: 0.8375 - val_loss: 0.5212\n",
      "Epoch 202/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 0.5925 - val_accuracy: 0.8375 - val_loss: 0.5210\n",
      "Epoch 203/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7391 - loss: 0.6614 - val_accuracy: 0.8410 - val_loss: 0.5210\n",
      "Epoch 204/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.6072 - val_accuracy: 0.8375 - val_loss: 0.5214\n",
      "Epoch 205/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 0.5803 - val_accuracy: 0.8410 - val_loss: 0.5228\n",
      "Epoch 206/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7654 - loss: 0.6149 - val_accuracy: 0.8410 - val_loss: 0.5218\n",
      "Epoch 207/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.6377 - val_accuracy: 0.8375 - val_loss: 0.5196\n",
      "Epoch 208/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7440 - loss: 0.5977 - val_accuracy: 0.8410 - val_loss: 0.5192\n",
      "Epoch 209/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.6097 - val_accuracy: 0.8410 - val_loss: 0.5201\n",
      "Epoch 210/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 0.5954 - val_accuracy: 0.8445 - val_loss: 0.5172\n",
      "Epoch 211/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7609 - loss: 0.5886 - val_accuracy: 0.8410 - val_loss: 0.5124\n",
      "Epoch 212/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7683 - loss: 0.6242 - val_accuracy: 0.8481 - val_loss: 0.5124\n",
      "Epoch 213/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7305 - loss: 0.6732 - val_accuracy: 0.8410 - val_loss: 0.5142\n",
      "Epoch 214/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.6305 - val_accuracy: 0.8481 - val_loss: 0.5125\n",
      "Epoch 215/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.6240 - val_accuracy: 0.8410 - val_loss: 0.5108\n",
      "Epoch 216/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.5903 - val_accuracy: 0.8410 - val_loss: 0.5094\n",
      "Epoch 217/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.6029 - val_accuracy: 0.8445 - val_loss: 0.5087\n",
      "Epoch 218/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.5697 - val_accuracy: 0.8445 - val_loss: 0.5074\n",
      "Epoch 219/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.5829 - val_accuracy: 0.8481 - val_loss: 0.5078\n",
      "Epoch 220/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7829 - loss: 0.6096 - val_accuracy: 0.8481 - val_loss: 0.5062\n",
      "Epoch 221/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7469 - loss: 0.6251 - val_accuracy: 0.8481 - val_loss: 0.5050\n",
      "Epoch 222/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.5563 - val_accuracy: 0.8445 - val_loss: 0.5043\n",
      "Epoch 223/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7543 - loss: 0.6179 - val_accuracy: 0.8481 - val_loss: 0.5050\n",
      "Epoch 224/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7589 - loss: 0.6354 - val_accuracy: 0.8481 - val_loss: 0.5059\n",
      "Epoch 225/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.5613 - val_accuracy: 0.8445 - val_loss: 0.5060\n",
      "Epoch 226/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7466 - loss: 0.6171 - val_accuracy: 0.8481 - val_loss: 0.5038\n",
      "Epoch 227/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.5474 - val_accuracy: 0.8481 - val_loss: 0.5035\n",
      "Epoch 228/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7460 - loss: 0.6363 - val_accuracy: 0.8481 - val_loss: 0.5023\n",
      "Epoch 229/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.6150 - val_accuracy: 0.8551 - val_loss: 0.5023\n",
      "Epoch 230/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7610 - loss: 0.5724 - val_accuracy: 0.8481 - val_loss: 0.5005\n",
      "Epoch 231/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7387 - loss: 0.6361 - val_accuracy: 0.8481 - val_loss: 0.4982\n",
      "Epoch 232/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7552 - loss: 0.5778 - val_accuracy: 0.8481 - val_loss: 0.4968\n",
      "Epoch 233/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.5896 - val_accuracy: 0.8481 - val_loss: 0.4962\n",
      "Epoch 234/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7586 - loss: 0.6342 - val_accuracy: 0.8481 - val_loss: 0.4963\n",
      "Epoch 235/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7826 - loss: 0.5849 - val_accuracy: 0.8481 - val_loss: 0.4939\n",
      "Epoch 236/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7425 - loss: 0.6373 - val_accuracy: 0.8445 - val_loss: 0.4932\n",
      "Epoch 237/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.5663 - val_accuracy: 0.8445 - val_loss: 0.4942\n",
      "Epoch 238/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7956 - loss: 0.5388 - val_accuracy: 0.8481 - val_loss: 0.4931\n",
      "Epoch 239/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7908 - loss: 0.5567 - val_accuracy: 0.8445 - val_loss: 0.4911\n",
      "Epoch 240/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7920 - loss: 0.5389 - val_accuracy: 0.8445 - val_loss: 0.4902\n",
      "Epoch 241/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7681 - loss: 0.5928 - val_accuracy: 0.8445 - val_loss: 0.4884\n",
      "Epoch 242/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7910 - loss: 0.5706 - val_accuracy: 0.8445 - val_loss: 0.4875\n",
      "Epoch 243/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7400 - loss: 0.6095 - val_accuracy: 0.8516 - val_loss: 0.4895\n",
      "Epoch 244/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.5855 - val_accuracy: 0.8516 - val_loss: 0.4886\n",
      "Epoch 245/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7562 - loss: 0.5886 - val_accuracy: 0.8481 - val_loss: 0.4871\n",
      "Epoch 246/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7561 - loss: 0.5769 - val_accuracy: 0.8445 - val_loss: 0.4844\n",
      "Epoch 247/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7729 - loss: 0.5651 - val_accuracy: 0.8516 - val_loss: 0.4855\n",
      "Epoch 248/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7544 - loss: 0.6026 - val_accuracy: 0.8551 - val_loss: 0.4854\n",
      "Epoch 249/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7538 - loss: 0.6108 - val_accuracy: 0.8516 - val_loss: 0.4838\n",
      "Epoch 250/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.5797 - val_accuracy: 0.8551 - val_loss: 0.4839\n",
      "Epoch 251/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.5884 - val_accuracy: 0.8551 - val_loss: 0.4815\n",
      "Epoch 252/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7790 - loss: 0.5776 - val_accuracy: 0.8516 - val_loss: 0.4816\n",
      "Epoch 253/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7466 - loss: 0.6166 - val_accuracy: 0.8551 - val_loss: 0.4805\n",
      "Epoch 254/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7715 - loss: 0.5588 - val_accuracy: 0.8551 - val_loss: 0.4806\n",
      "Epoch 255/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7796 - loss: 0.5639 - val_accuracy: 0.8516 - val_loss: 0.4796\n",
      "Epoch 256/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7722 - loss: 0.5883 - val_accuracy: 0.8516 - val_loss: 0.4805\n",
      "Epoch 257/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.6028 - val_accuracy: 0.8551 - val_loss: 0.4812\n",
      "Epoch 258/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7635 - loss: 0.5847 - val_accuracy: 0.8516 - val_loss: 0.4799\n",
      "Epoch 259/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.5435 - val_accuracy: 0.8587 - val_loss: 0.4791\n",
      "Epoch 260/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7842 - loss: 0.5556 - val_accuracy: 0.8622 - val_loss: 0.4807\n",
      "Epoch 261/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.5713 - val_accuracy: 0.8551 - val_loss: 0.4785\n",
      "Epoch 262/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.5518 - val_accuracy: 0.8551 - val_loss: 0.4781\n",
      "Epoch 263/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7728 - loss: 0.5953 - val_accuracy: 0.8587 - val_loss: 0.4770\n",
      "Epoch 264/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.5789 - val_accuracy: 0.8587 - val_loss: 0.4775\n",
      "Epoch 265/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.5671 - val_accuracy: 0.8587 - val_loss: 0.4788\n",
      "Epoch 266/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.5382 - val_accuracy: 0.8551 - val_loss: 0.4787\n",
      "Epoch 267/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 0.6030 - val_accuracy: 0.8551 - val_loss: 0.4770\n",
      "Epoch 268/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.6034 - val_accuracy: 0.8551 - val_loss: 0.4761\n",
      "Epoch 269/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7800 - loss: 0.5407 - val_accuracy: 0.8551 - val_loss: 0.4762\n",
      "Epoch 270/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.5597 - val_accuracy: 0.8551 - val_loss: 0.4755\n",
      "Epoch 271/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.5773 - val_accuracy: 0.8622 - val_loss: 0.4727\n",
      "Epoch 272/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.5119 - val_accuracy: 0.8551 - val_loss: 0.4715\n",
      "Epoch 273/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.5626 - val_accuracy: 0.8587 - val_loss: 0.4701\n",
      "Epoch 274/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 0.6338 - val_accuracy: 0.8693 - val_loss: 0.4700\n",
      "Epoch 275/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.5512 - val_accuracy: 0.8551 - val_loss: 0.4717\n",
      "Epoch 276/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7701 - loss: 0.5323 - val_accuracy: 0.8657 - val_loss: 0.4713\n",
      "Epoch 277/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.5416 - val_accuracy: 0.8622 - val_loss: 0.4699\n",
      "Epoch 278/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.5500 - val_accuracy: 0.8587 - val_loss: 0.4683\n",
      "Epoch 279/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.5380 - val_accuracy: 0.8551 - val_loss: 0.4680\n",
      "Epoch 280/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7744 - loss: 0.5541 - val_accuracy: 0.8551 - val_loss: 0.4689\n",
      "Epoch 281/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7726 - loss: 0.5797 - val_accuracy: 0.8551 - val_loss: 0.4675\n",
      "Epoch 282/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7830 - loss: 0.5458 - val_accuracy: 0.8657 - val_loss: 0.4663\n",
      "Epoch 283/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7672 - loss: 0.5775 - val_accuracy: 0.8587 - val_loss: 0.4640\n",
      "Epoch 284/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.5716 - val_accuracy: 0.8551 - val_loss: 0.4644\n",
      "Epoch 285/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.5653 - val_accuracy: 0.8551 - val_loss: 0.4640\n",
      "Epoch 286/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.5121 - val_accuracy: 0.8551 - val_loss: 0.4620\n",
      "Epoch 287/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.5693 - val_accuracy: 0.8551 - val_loss: 0.4600\n",
      "Epoch 288/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.5065 - val_accuracy: 0.8551 - val_loss: 0.4589\n",
      "Epoch 289/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.5341 - val_accuracy: 0.8622 - val_loss: 0.4593\n",
      "Epoch 290/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7469 - loss: 0.6371 - val_accuracy: 0.8551 - val_loss: 0.4602\n",
      "Epoch 291/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.5446 - val_accuracy: 0.8622 - val_loss: 0.4576\n",
      "Epoch 292/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.5437 - val_accuracy: 0.8622 - val_loss: 0.4577\n",
      "Epoch 293/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7911 - loss: 0.5448 - val_accuracy: 0.8587 - val_loss: 0.4572\n",
      "Epoch 294/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.5454 - val_accuracy: 0.8587 - val_loss: 0.4571\n",
      "Epoch 295/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8055 - loss: 0.5115 - val_accuracy: 0.8657 - val_loss: 0.4555\n",
      "Epoch 296/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7544 - loss: 0.5943 - val_accuracy: 0.8622 - val_loss: 0.4542\n",
      "Epoch 297/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4993 - val_accuracy: 0.8657 - val_loss: 0.4562\n",
      "Epoch 298/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.5463 - val_accuracy: 0.8622 - val_loss: 0.4562\n",
      "Epoch 299/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.5773 - val_accuracy: 0.8587 - val_loss: 0.4561\n",
      "Epoch 300/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7738 - loss: 0.5375 - val_accuracy: 0.8622 - val_loss: 0.4557\n",
      "Epoch 301/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.5044 - val_accuracy: 0.8622 - val_loss: 0.4534\n",
      "Epoch 302/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.5465 - val_accuracy: 0.8657 - val_loss: 0.4523\n",
      "Epoch 303/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.6161 - val_accuracy: 0.8622 - val_loss: 0.4566\n",
      "Epoch 304/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7743 - loss: 0.5667 - val_accuracy: 0.8657 - val_loss: 0.4527\n",
      "Epoch 305/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7589 - loss: 0.5785 - val_accuracy: 0.8657 - val_loss: 0.4498\n",
      "Epoch 306/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.5376 - val_accuracy: 0.8693 - val_loss: 0.4499\n",
      "Epoch 307/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7739 - loss: 0.5342 - val_accuracy: 0.8657 - val_loss: 0.4506\n",
      "Epoch 308/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 0.5678 - val_accuracy: 0.8657 - val_loss: 0.4512\n",
      "Epoch 309/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.4732 - val_accuracy: 0.8622 - val_loss: 0.4529\n",
      "Epoch 310/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.4952 - val_accuracy: 0.8657 - val_loss: 0.4497\n",
      "Epoch 311/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7773 - loss: 0.5705 - val_accuracy: 0.8657 - val_loss: 0.4522\n",
      "Epoch 312/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7733 - loss: 0.5640 - val_accuracy: 0.8657 - val_loss: 0.4525\n",
      "Epoch 313/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7788 - loss: 0.5507 - val_accuracy: 0.8693 - val_loss: 0.4527\n",
      "Epoch 314/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.5728 - val_accuracy: 0.8728 - val_loss: 0.4513\n",
      "Epoch 315/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.5830 - val_accuracy: 0.8657 - val_loss: 0.4500\n",
      "Epoch 316/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.5691 - val_accuracy: 0.8657 - val_loss: 0.4463\n",
      "Epoch 317/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.5550 - val_accuracy: 0.8693 - val_loss: 0.4448\n",
      "Epoch 318/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.5107 - val_accuracy: 0.8693 - val_loss: 0.4440\n",
      "Epoch 319/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.5171 - val_accuracy: 0.8657 - val_loss: 0.4429\n",
      "Epoch 320/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.5271 - val_accuracy: 0.8657 - val_loss: 0.4417\n",
      "Epoch 321/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.5440 - val_accuracy: 0.8657 - val_loss: 0.4422\n",
      "Epoch 322/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7476 - loss: 0.6466 - val_accuracy: 0.8622 - val_loss: 0.4415\n",
      "Epoch 323/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7830 - loss: 0.5249 - val_accuracy: 0.8657 - val_loss: 0.4392\n",
      "Epoch 324/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4907 - val_accuracy: 0.8657 - val_loss: 0.4402\n",
      "Epoch 325/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5397 - val_accuracy: 0.8693 - val_loss: 0.4417\n",
      "Epoch 326/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7539 - loss: 0.5764 - val_accuracy: 0.8657 - val_loss: 0.4401\n",
      "Epoch 327/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7804 - loss: 0.5331 - val_accuracy: 0.8693 - val_loss: 0.4417\n",
      "Epoch 328/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.5461 - val_accuracy: 0.8693 - val_loss: 0.4402\n",
      "Epoch 329/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7727 - loss: 0.5689 - val_accuracy: 0.8763 - val_loss: 0.4420\n",
      "Epoch 330/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.5203 - val_accuracy: 0.8728 - val_loss: 0.4405\n",
      "Epoch 331/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.5217 - val_accuracy: 0.8622 - val_loss: 0.4413\n",
      "Epoch 332/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7921 - loss: 0.5622 - val_accuracy: 0.8693 - val_loss: 0.4384\n",
      "Epoch 333/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.5667 - val_accuracy: 0.8693 - val_loss: 0.4363\n",
      "Epoch 334/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.5314 - val_accuracy: 0.8693 - val_loss: 0.4343\n",
      "Epoch 335/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.5434 - val_accuracy: 0.8728 - val_loss: 0.4339\n",
      "Epoch 336/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.5392 - val_accuracy: 0.8728 - val_loss: 0.4333\n",
      "Epoch 337/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7779 - loss: 0.5670 - val_accuracy: 0.8693 - val_loss: 0.4328\n",
      "Epoch 338/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.5252 - val_accuracy: 0.8693 - val_loss: 0.4334\n",
      "Epoch 339/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7938 - loss: 0.5075 - val_accuracy: 0.8657 - val_loss: 0.4357\n",
      "Epoch 340/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 0.5431 - val_accuracy: 0.8728 - val_loss: 0.4333\n",
      "Epoch 341/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7857 - loss: 0.5360 - val_accuracy: 0.8693 - val_loss: 0.4326\n",
      "Epoch 342/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7738 - loss: 0.5827 - val_accuracy: 0.8657 - val_loss: 0.4341\n",
      "Epoch 343/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.5210 - val_accuracy: 0.8622 - val_loss: 0.4341\n",
      "Epoch 344/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.5267 - val_accuracy: 0.8657 - val_loss: 0.4326\n",
      "Epoch 345/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.4989 - val_accuracy: 0.8622 - val_loss: 0.4304\n",
      "Epoch 346/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.5064 - val_accuracy: 0.8622 - val_loss: 0.4285\n",
      "Epoch 347/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.5396 - val_accuracy: 0.8622 - val_loss: 0.4293\n",
      "Epoch 348/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.5286 - val_accuracy: 0.8693 - val_loss: 0.4308\n",
      "Epoch 349/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7806 - loss: 0.5678 - val_accuracy: 0.8693 - val_loss: 0.4314\n",
      "Epoch 350/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.5357 - val_accuracy: 0.8657 - val_loss: 0.4300\n",
      "Epoch 351/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.5505 - val_accuracy: 0.8728 - val_loss: 0.4285\n",
      "Epoch 352/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 0.5486 - val_accuracy: 0.8693 - val_loss: 0.4293\n",
      "Epoch 353/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.5211 - val_accuracy: 0.8763 - val_loss: 0.4281\n",
      "Epoch 354/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7656 - loss: 0.5956 - val_accuracy: 0.8728 - val_loss: 0.4264\n",
      "Epoch 355/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.5539 - val_accuracy: 0.8763 - val_loss: 0.4286\n",
      "Epoch 356/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4907 - val_accuracy: 0.8693 - val_loss: 0.4276\n",
      "Epoch 357/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5794 - val_accuracy: 0.8728 - val_loss: 0.4265\n",
      "Epoch 358/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.4969 - val_accuracy: 0.8728 - val_loss: 0.4289\n",
      "Epoch 359/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.5183 - val_accuracy: 0.8728 - val_loss: 0.4278\n",
      "Epoch 360/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4998 - val_accuracy: 0.8763 - val_loss: 0.4293\n",
      "Epoch 361/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7976 - loss: 0.5318 - val_accuracy: 0.8728 - val_loss: 0.4268\n",
      "Epoch 362/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5610 - val_accuracy: 0.8728 - val_loss: 0.4255\n",
      "Epoch 363/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.5311 - val_accuracy: 0.8728 - val_loss: 0.4247\n",
      "Epoch 364/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.5178 - val_accuracy: 0.8728 - val_loss: 0.4241\n",
      "Epoch 365/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.5020 - val_accuracy: 0.8693 - val_loss: 0.4237\n",
      "Epoch 366/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.5181 - val_accuracy: 0.8657 - val_loss: 0.4240\n",
      "Epoch 367/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7954 - loss: 0.5479 - val_accuracy: 0.8693 - val_loss: 0.4261\n",
      "Epoch 368/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.5410 - val_accuracy: 0.8693 - val_loss: 0.4246\n",
      "Epoch 369/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7994 - loss: 0.5431 - val_accuracy: 0.8728 - val_loss: 0.4249\n",
      "Epoch 370/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8050 - loss: 0.4713 - val_accuracy: 0.8728 - val_loss: 0.4255\n",
      "Epoch 371/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4973 - val_accuracy: 0.8728 - val_loss: 0.4239\n",
      "Epoch 372/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7851 - loss: 0.5221 - val_accuracy: 0.8763 - val_loss: 0.4254\n",
      "Epoch 373/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.5220 - val_accuracy: 0.8763 - val_loss: 0.4254\n",
      "Epoch 374/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.5186 - val_accuracy: 0.8763 - val_loss: 0.4227\n",
      "Epoch 375/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.5178 - val_accuracy: 0.8799 - val_loss: 0.4218\n",
      "Epoch 376/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 0.5428 - val_accuracy: 0.8799 - val_loss: 0.4206\n",
      "Epoch 377/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.5087 - val_accuracy: 0.8763 - val_loss: 0.4193\n",
      "Epoch 378/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.5341 - val_accuracy: 0.8834 - val_loss: 0.4203\n",
      "Epoch 379/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.5424 - val_accuracy: 0.8728 - val_loss: 0.4218\n",
      "Epoch 380/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7592 - loss: 0.5943 - val_accuracy: 0.8763 - val_loss: 0.4215\n",
      "Epoch 381/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.5143 - val_accuracy: 0.8763 - val_loss: 0.4191\n",
      "Epoch 382/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4871 - val_accuracy: 0.8763 - val_loss: 0.4169\n",
      "Epoch 383/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.5374 - val_accuracy: 0.8763 - val_loss: 0.4181\n",
      "Epoch 384/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.5235 - val_accuracy: 0.8799 - val_loss: 0.4172\n",
      "Epoch 385/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.5093 - val_accuracy: 0.8799 - val_loss: 0.4170\n",
      "Epoch 386/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.5291 - val_accuracy: 0.8763 - val_loss: 0.4179\n",
      "Epoch 387/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.5222 - val_accuracy: 0.8728 - val_loss: 0.4173\n",
      "Epoch 388/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.4424 - val_accuracy: 0.8763 - val_loss: 0.4174\n",
      "Epoch 389/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.4903 - val_accuracy: 0.8763 - val_loss: 0.4178\n",
      "Epoch 390/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.4985 - val_accuracy: 0.8728 - val_loss: 0.4175\n",
      "Epoch 391/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.5650 - val_accuracy: 0.8728 - val_loss: 0.4172\n",
      "Epoch 392/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4716 - val_accuracy: 0.8763 - val_loss: 0.4164\n",
      "Epoch 393/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.4671 - val_accuracy: 0.8763 - val_loss: 0.4163\n",
      "Epoch 394/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4911 - val_accuracy: 0.8763 - val_loss: 0.4153\n",
      "Epoch 395/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.5154 - val_accuracy: 0.8763 - val_loss: 0.4148\n",
      "Epoch 396/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.5070 - val_accuracy: 0.8728 - val_loss: 0.4168\n",
      "Epoch 397/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.5264 - val_accuracy: 0.8799 - val_loss: 0.4160\n",
      "Epoch 398/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.4908 - val_accuracy: 0.8728 - val_loss: 0.4151\n",
      "Epoch 399/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.5471 - val_accuracy: 0.8834 - val_loss: 0.4121\n",
      "Epoch 400/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.5105 - val_accuracy: 0.8763 - val_loss: 0.4146\n",
      "Epoch 401/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4896 - val_accuracy: 0.8763 - val_loss: 0.4142\n",
      "Epoch 402/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.4915 - val_accuracy: 0.8763 - val_loss: 0.4129\n",
      "Epoch 403/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4599 - val_accuracy: 0.8799 - val_loss: 0.4128\n",
      "Epoch 404/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4959 - val_accuracy: 0.8763 - val_loss: 0.4129\n",
      "Epoch 405/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.4664 - val_accuracy: 0.8763 - val_loss: 0.4102\n",
      "Epoch 406/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4785 - val_accuracy: 0.8728 - val_loss: 0.4097\n",
      "Epoch 407/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.5025 - val_accuracy: 0.8763 - val_loss: 0.4112\n",
      "Epoch 408/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.4615 - val_accuracy: 0.8763 - val_loss: 0.4093\n",
      "Epoch 409/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.5232 - val_accuracy: 0.8763 - val_loss: 0.4112\n",
      "Epoch 410/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7952 - loss: 0.5200 - val_accuracy: 0.8799 - val_loss: 0.4082\n",
      "Epoch 411/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8140 - loss: 0.4757 - val_accuracy: 0.8763 - val_loss: 0.4099\n",
      "Epoch 412/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7613 - loss: 0.5849 - val_accuracy: 0.8799 - val_loss: 0.4085\n",
      "Epoch 413/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8059 - loss: 0.4958 - val_accuracy: 0.8799 - val_loss: 0.4088\n",
      "Epoch 414/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.5081 - val_accuracy: 0.8799 - val_loss: 0.4090\n",
      "Epoch 415/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7871 - loss: 0.5348 - val_accuracy: 0.8799 - val_loss: 0.4107\n",
      "Epoch 416/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.5196 - val_accuracy: 0.8834 - val_loss: 0.4086\n",
      "Epoch 417/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4906 - val_accuracy: 0.8799 - val_loss: 0.4079\n",
      "Epoch 418/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8072 - loss: 0.5155 - val_accuracy: 0.8799 - val_loss: 0.4072\n",
      "Epoch 419/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7784 - loss: 0.5587 - val_accuracy: 0.8799 - val_loss: 0.4105\n",
      "Epoch 420/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8128 - loss: 0.4663 - val_accuracy: 0.8799 - val_loss: 0.4094\n",
      "Epoch 421/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.4617 - val_accuracy: 0.8799 - val_loss: 0.4077\n",
      "Epoch 422/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.5165 - val_accuracy: 0.8763 - val_loss: 0.4074\n",
      "Epoch 423/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.5048 - val_accuracy: 0.8799 - val_loss: 0.4095\n",
      "Epoch 424/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.4695 - val_accuracy: 0.8799 - val_loss: 0.4088\n",
      "Epoch 425/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.5263 - val_accuracy: 0.8799 - val_loss: 0.4082\n",
      "Epoch 426/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8318 - loss: 0.4793 - val_accuracy: 0.8834 - val_loss: 0.4067\n",
      "Epoch 427/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.5379 - val_accuracy: 0.8834 - val_loss: 0.4051\n",
      "Epoch 428/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.5166 - val_accuracy: 0.8834 - val_loss: 0.4036\n",
      "Epoch 429/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.5243 - val_accuracy: 0.8834 - val_loss: 0.4038\n",
      "Epoch 430/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.4877 - val_accuracy: 0.8834 - val_loss: 0.4029\n",
      "Epoch 431/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4892 - val_accuracy: 0.8834 - val_loss: 0.4012\n",
      "Epoch 432/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.4382 - val_accuracy: 0.8799 - val_loss: 0.4007\n",
      "Epoch 433/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4724 - val_accuracy: 0.8834 - val_loss: 0.4009\n",
      "Epoch 434/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4979 - val_accuracy: 0.8834 - val_loss: 0.3998\n",
      "Epoch 435/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 0.4621 - val_accuracy: 0.8799 - val_loss: 0.4007\n",
      "Epoch 436/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8043 - loss: 0.4683 - val_accuracy: 0.8869 - val_loss: 0.3995\n",
      "Epoch 437/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.4851 - val_accuracy: 0.8763 - val_loss: 0.4013\n",
      "Epoch 438/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8126 - loss: 0.4757 - val_accuracy: 0.8799 - val_loss: 0.4035\n",
      "Epoch 439/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.4675 - val_accuracy: 0.8799 - val_loss: 0.4003\n",
      "Epoch 440/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4887 - val_accuracy: 0.8799 - val_loss: 0.4006\n",
      "Epoch 441/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.4694 - val_accuracy: 0.8799 - val_loss: 0.3998\n",
      "Epoch 442/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.5131 - val_accuracy: 0.8799 - val_loss: 0.3997\n",
      "Epoch 443/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.4919 - val_accuracy: 0.8799 - val_loss: 0.3995\n",
      "Epoch 444/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8156 - loss: 0.4932 - val_accuracy: 0.8869 - val_loss: 0.3984\n",
      "Epoch 445/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.4773 - val_accuracy: 0.8834 - val_loss: 0.3998\n",
      "Epoch 446/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8328 - loss: 0.4481 - val_accuracy: 0.8834 - val_loss: 0.4012\n",
      "Epoch 447/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7955 - loss: 0.5017 - val_accuracy: 0.8834 - val_loss: 0.3978\n",
      "Epoch 448/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.5077 - val_accuracy: 0.8834 - val_loss: 0.3999\n",
      "Epoch 449/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.5371 - val_accuracy: 0.8834 - val_loss: 0.4002\n",
      "Epoch 450/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.4625 - val_accuracy: 0.8834 - val_loss: 0.3988\n",
      "Epoch 451/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8195 - loss: 0.4667 - val_accuracy: 0.8799 - val_loss: 0.3983\n",
      "Epoch 452/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.5222 - val_accuracy: 0.8834 - val_loss: 0.3977\n",
      "Epoch 453/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.4545 - val_accuracy: 0.8834 - val_loss: 0.3972\n",
      "Epoch 454/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4932 - val_accuracy: 0.8799 - val_loss: 0.3969\n",
      "Epoch 455/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7959 - loss: 0.5159 - val_accuracy: 0.8834 - val_loss: 0.3963\n",
      "Epoch 456/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 0.4509 - val_accuracy: 0.8834 - val_loss: 0.3969\n",
      "Epoch 457/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.4683 - val_accuracy: 0.8834 - val_loss: 0.3955\n",
      "Epoch 458/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.4653 - val_accuracy: 0.8869 - val_loss: 0.3936\n",
      "Epoch 459/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4803 - val_accuracy: 0.8834 - val_loss: 0.3929\n",
      "Epoch 460/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7656 - loss: 0.5620 - val_accuracy: 0.8834 - val_loss: 0.3930\n",
      "Epoch 461/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.4664 - val_accuracy: 0.8869 - val_loss: 0.3937\n",
      "Epoch 462/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8041 - loss: 0.4889 - val_accuracy: 0.8834 - val_loss: 0.3942\n",
      "Epoch 463/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8143 - loss: 0.4303 - val_accuracy: 0.8869 - val_loss: 0.3934\n",
      "Epoch 464/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8220 - loss: 0.4651 - val_accuracy: 0.8869 - val_loss: 0.3937\n",
      "Epoch 465/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.4678 - val_accuracy: 0.8869 - val_loss: 0.3932\n",
      "Epoch 466/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.4775 - val_accuracy: 0.8834 - val_loss: 0.3950\n",
      "Epoch 467/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.4901 - val_accuracy: 0.8834 - val_loss: 0.3936\n",
      "Epoch 468/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.4427 - val_accuracy: 0.8834 - val_loss: 0.3931\n",
      "Epoch 469/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8176 - loss: 0.4590 - val_accuracy: 0.8869 - val_loss: 0.3926\n",
      "Epoch 470/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4845 - val_accuracy: 0.8834 - val_loss: 0.3914\n",
      "Epoch 471/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.5028 - val_accuracy: 0.8834 - val_loss: 0.3927\n",
      "Epoch 472/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4727 - val_accuracy: 0.8834 - val_loss: 0.3923\n",
      "Epoch 473/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8198 - loss: 0.4772 - val_accuracy: 0.8799 - val_loss: 0.3923\n",
      "Epoch 474/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.5159 - val_accuracy: 0.8799 - val_loss: 0.3905\n",
      "Epoch 475/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4853 - val_accuracy: 0.8869 - val_loss: 0.3910\n",
      "Epoch 476/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.4590 - val_accuracy: 0.8869 - val_loss: 0.3891\n",
      "Epoch 477/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8007 - loss: 0.5073 - val_accuracy: 0.8869 - val_loss: 0.3913\n",
      "Epoch 478/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.4587 - val_accuracy: 0.8869 - val_loss: 0.3890\n",
      "Epoch 479/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7977 - loss: 0.5154 - val_accuracy: 0.8869 - val_loss: 0.3893\n",
      "Epoch 480/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8103 - loss: 0.4691 - val_accuracy: 0.8869 - val_loss: 0.3905\n",
      "Epoch 481/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4750 - val_accuracy: 0.8869 - val_loss: 0.3907\n",
      "Epoch 482/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7943 - loss: 0.4759 - val_accuracy: 0.8834 - val_loss: 0.3917\n",
      "Epoch 483/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.4415 - val_accuracy: 0.8799 - val_loss: 0.3916\n",
      "Epoch 484/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8048 - loss: 0.4944 - val_accuracy: 0.8834 - val_loss: 0.3893\n",
      "Epoch 485/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.4843 - val_accuracy: 0.8834 - val_loss: 0.3857\n",
      "Epoch 486/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.4567 - val_accuracy: 0.8834 - val_loss: 0.3870\n",
      "Epoch 487/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.5068 - val_accuracy: 0.8799 - val_loss: 0.3867\n",
      "Epoch 488/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.4328 - val_accuracy: 0.8834 - val_loss: 0.3864\n",
      "Epoch 489/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.4676 - val_accuracy: 0.8834 - val_loss: 0.3878\n",
      "Epoch 490/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.4423 - val_accuracy: 0.8834 - val_loss: 0.3882\n",
      "Epoch 491/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8108 - loss: 0.4679 - val_accuracy: 0.8869 - val_loss: 0.3868\n",
      "Epoch 492/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.5473 - val_accuracy: 0.8799 - val_loss: 0.3864\n",
      "Epoch 493/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.5126 - val_accuracy: 0.8799 - val_loss: 0.3875\n",
      "Epoch 494/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.4298 - val_accuracy: 0.8834 - val_loss: 0.3862\n",
      "Epoch 495/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.4533 - val_accuracy: 0.8834 - val_loss: 0.3855\n",
      "Epoch 496/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 0.4865 - val_accuracy: 0.8763 - val_loss: 0.3858\n",
      "Epoch 497/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8342 - loss: 0.4578 - val_accuracy: 0.8763 - val_loss: 0.3839\n",
      "Epoch 498/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.4668 - val_accuracy: 0.8799 - val_loss: 0.3843\n",
      "Epoch 499/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.4412 - val_accuracy: 0.8834 - val_loss: 0.3866\n",
      "Epoch 500/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4890 - val_accuracy: 0.8763 - val_loss: 0.3889\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    normalization_layer,\n",
    "    Dense(55, activation='relu'),\n",
    "    BatchNormalization(),  # Helps stabilize training\n",
    "    Dropout(0.3),\n",
    "    Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "   \n",
    "    Dense(label_count, activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(learning_rate=0.00008), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(model.summary())\n",
    "#implement early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_split=0.2,callbacks=early_stopping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "stringnames = [\"E\", \"A\", \"D\", \"G\", \"B\", \"h_E\"]\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=stringnames, yticklabels=stringnames)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4)\n"
     ]
    }
   ],
   "source": [
    "model.save('stringDetectionML.h5')\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "model.output_names=['output']\n",
    "input_signature = [tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name='digit')]\n",
    "print(model.inputs[0].shape) \n",
    "# Convert the Keras model to ONNX format\n",
    "#onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, opset=13)\n",
    "\n",
    "\n",
    "(onnx_model_proto, storage) = tf2onnx.convert.from_keras(model,input_signature=input_signature, opset=13)\n",
    "\n",
    "dir = os.getcwd()\n",
    "dir = dir.split(\"/\")[0]\n",
    "while( path.basename(dir) != \"TabGenerator\"): # go to the TabGenerator directory\n",
    "    dir = os.path.dirname(dir)\n",
    "\n",
    "dir = os.path.join(dir, \"Assets\",\"MachineLearning\",\"MLModels\")\n",
    "onnxpath = os.path.join(dir, \"stringDetectionML_ONNX.onnx\")\n",
    "\n",
    "with open(onnxpath, \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
