{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (708, 4)\n",
      "Training labels shape: (708, 6)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"b_values.json\") as f:\n",
    "#     b_values = json.load(f)\n",
    "    \n",
    "# with open(\"avg_amplitude_ratios.json\") as f:\n",
    "#     avg_amplitude_ratios = json.load(f)\n",
    "\n",
    "with open(\"results.csv\") as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "strings = [\"h_E\", \"B\", \"G\", \"D\", \"A\", \"E\"]\n",
    "labels = np.array([0,1,2,3,4,5])\n",
    "# strings = [\"1-2h_E\", \"1-2B\", \"1-2G\", \"1-2D\", \"1-2A\", \"1-2E\", \"2-2h_E\", \"2-2B\", \"2-2G\", \"2-2D\", \"2-2A\", \"2-2E\"]\n",
    "# labels = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "\n",
    "\n",
    "data = []\n",
    "label_list = []\n",
    "\n",
    "for i, line in enumerate(results):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    string,metric,amp_ra,deviation,f0 = line.split(\",\")\n",
    "    if string in strings:\n",
    "        metric = float(metric)\n",
    "        amp_ra = float(amp_ra)\n",
    "        deviation = float(deviation)\n",
    "        f0 = float(f0)\n",
    "        data.append([metric, amp_ra, deviation, f0])\n",
    "        label_list.append(labels[strings.index(string)])\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "label_count = 6\n",
    "labels_categorical = tf.keras.utils.to_categorical(label_list, num_classes=label_count)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 2)\n",
    "print(f\"Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_72 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_42          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_43          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,070</span> (47.15 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,070\u001b[0m (47.15 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,622</span> (45.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,622\u001b[0m (45.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.2164 - loss: 2.4530 - val_accuracy: 0.2254 - val_loss: 1.7590\n",
      "Epoch 2/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3199 - loss: 1.9890 - val_accuracy: 0.2042 - val_loss: 1.7065\n",
      "Epoch 3/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3528 - loss: 1.7095 - val_accuracy: 0.2324 - val_loss: 1.6593\n",
      "Epoch 4/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3730 - loss: 1.6863 - val_accuracy: 0.2254 - val_loss: 1.6224\n",
      "Epoch 5/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3967 - loss: 1.5040 - val_accuracy: 0.2817 - val_loss: 1.5668\n",
      "Epoch 6/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3963 - loss: 1.4958 - val_accuracy: 0.3099 - val_loss: 1.5379\n",
      "Epoch 7/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4145 - loss: 1.4147 - val_accuracy: 0.4155 - val_loss: 1.4920\n",
      "Epoch 8/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4109 - loss: 1.4246 - val_accuracy: 0.5000 - val_loss: 1.4194\n",
      "Epoch 9/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4785 - loss: 1.3721 - val_accuracy: 0.5141 - val_loss: 1.3936\n",
      "Epoch 10/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5348 - loss: 1.2361 - val_accuracy: 0.5845 - val_loss: 1.3604\n",
      "Epoch 11/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4784 - loss: 1.2917 - val_accuracy: 0.5775 - val_loss: 1.3349\n",
      "Epoch 12/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5477 - loss: 1.1424 - val_accuracy: 0.6056 - val_loss: 1.3267\n",
      "Epoch 13/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5081 - loss: 1.2121 - val_accuracy: 0.6408 - val_loss: 1.2963\n",
      "Epoch 14/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5025 - loss: 1.2209 - val_accuracy: 0.7042 - val_loss: 1.3034\n",
      "Epoch 15/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5487 - loss: 1.1100 - val_accuracy: 0.7254 - val_loss: 1.3063\n",
      "Epoch 16/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5555 - loss: 1.1544 - val_accuracy: 0.7042 - val_loss: 1.2906\n",
      "Epoch 17/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4960 - loss: 1.3155 - val_accuracy: 0.7254 - val_loss: 1.3225\n",
      "Epoch 18/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5006 - loss: 1.2272 - val_accuracy: 0.7254 - val_loss: 1.3124\n",
      "Epoch 19/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5519 - loss: 1.1569 - val_accuracy: 0.7324 - val_loss: 1.3050\n",
      "Epoch 20/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5542 - loss: 1.1219 - val_accuracy: 0.7042 - val_loss: 1.2772\n",
      "Epoch 21/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5823 - loss: 1.0841 - val_accuracy: 0.6972 - val_loss: 1.3004\n",
      "Epoch 22/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5922 - loss: 1.0357 - val_accuracy: 0.7113 - val_loss: 1.3448\n",
      "Epoch 23/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5945 - loss: 1.0140 - val_accuracy: 0.7183 - val_loss: 1.3740\n",
      "Epoch 24/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5561 - loss: 1.0872 - val_accuracy: 0.7324 - val_loss: 1.3721\n",
      "Epoch 25/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5609 - loss: 1.0173 - val_accuracy: 0.7324 - val_loss: 1.3811\n",
      "Epoch 26/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5893 - loss: 1.0037 - val_accuracy: 0.7324 - val_loss: 1.3711\n",
      "Epoch 27/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 1.0361 - val_accuracy: 0.7394 - val_loss: 1.3795\n",
      "Epoch 28/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5768 - loss: 0.9905 - val_accuracy: 0.7324 - val_loss: 1.3852\n",
      "Epoch 29/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5739 - loss: 1.0669 - val_accuracy: 0.7606 - val_loss: 1.3281\n",
      "Epoch 30/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6060 - loss: 0.9768 - val_accuracy: 0.7324 - val_loss: 1.3526\n",
      "Epoch 31/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6030 - loss: 1.0664 - val_accuracy: 0.7324 - val_loss: 1.3505\n",
      "Epoch 32/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5877 - loss: 1.0208 - val_accuracy: 0.7746 - val_loss: 1.3702\n",
      "Epoch 33/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6105 - loss: 0.9196 - val_accuracy: 0.7606 - val_loss: 1.3380\n",
      "Epoch 34/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5428 - loss: 1.0509 - val_accuracy: 0.7465 - val_loss: 1.3118\n",
      "Epoch 35/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6431 - loss: 0.9067 - val_accuracy: 0.7465 - val_loss: 1.3114\n",
      "Epoch 36/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6255 - loss: 0.9572 - val_accuracy: 0.7535 - val_loss: 1.3334\n",
      "Epoch 37/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5701 - loss: 1.0296 - val_accuracy: 0.7606 - val_loss: 1.2935\n",
      "Epoch 38/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6200 - loss: 0.9814 - val_accuracy: 0.7958 - val_loss: 1.2780\n",
      "Epoch 39/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5755 - loss: 1.0815 - val_accuracy: 0.7746 - val_loss: 1.2611\n",
      "Epoch 40/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6316 - loss: 0.9019 - val_accuracy: 0.7817 - val_loss: 1.3031\n",
      "Epoch 41/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6695 - loss: 0.9021 - val_accuracy: 0.7676 - val_loss: 1.3417\n",
      "Epoch 42/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6453 - loss: 0.9368 - val_accuracy: 0.7465 - val_loss: 1.3427\n",
      "Epoch 43/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5841 - loss: 1.0709 - val_accuracy: 0.7465 - val_loss: 1.3438\n",
      "Epoch 44/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6122 - loss: 0.9802 - val_accuracy: 0.7606 - val_loss: 1.3407\n",
      "Epoch 45/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5827 - loss: 0.9846 - val_accuracy: 0.7887 - val_loss: 1.3606\n",
      "Epoch 46/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 0.8458 - val_accuracy: 0.7817 - val_loss: 1.3812\n",
      "Epoch 47/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 0.9196 - val_accuracy: 0.7606 - val_loss: 1.3322\n",
      "Epoch 48/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6677 - loss: 0.9076 - val_accuracy: 0.7817 - val_loss: 1.3545\n",
      "Epoch 49/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6302 - loss: 0.9047 - val_accuracy: 0.7606 - val_loss: 1.4007\n",
      "Epoch 50/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.7968 - val_accuracy: 0.7606 - val_loss: 1.3919\n",
      "Epoch 51/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6210 - loss: 0.9306 - val_accuracy: 0.7817 - val_loss: 1.4452\n",
      "Epoch 52/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6167 - loss: 0.9082 - val_accuracy: 0.7887 - val_loss: 1.4264\n",
      "Epoch 53/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6462 - loss: 0.8365 - val_accuracy: 0.7676 - val_loss: 1.4306\n",
      "Epoch 54/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6602 - loss: 0.8933 - val_accuracy: 0.7676 - val_loss: 1.4315\n",
      "Epoch 55/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6550 - loss: 0.8849 - val_accuracy: 0.7676 - val_loss: 1.4375\n",
      "Epoch 56/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6087 - loss: 0.8871 - val_accuracy: 0.7746 - val_loss: 1.4353\n",
      "Epoch 57/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6428 - loss: 0.8378 - val_accuracy: 0.7887 - val_loss: 1.4321\n",
      "Epoch 58/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6210 - loss: 0.9022 - val_accuracy: 0.7746 - val_loss: 1.3796\n",
      "Epoch 59/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6321 - loss: 0.9276 - val_accuracy: 0.7606 - val_loss: 1.3783\n",
      "Epoch 60/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6430 - loss: 0.8729 - val_accuracy: 0.7535 - val_loss: 1.3316\n",
      "Epoch 61/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6480 - loss: 0.9046 - val_accuracy: 0.7887 - val_loss: 1.3608\n",
      "Epoch 62/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6156 - loss: 0.9488 - val_accuracy: 0.8099 - val_loss: 1.3507\n",
      "Epoch 63/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6542 - loss: 0.8740 - val_accuracy: 0.7817 - val_loss: 1.2932\n",
      "Epoch 64/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5987 - loss: 0.8968 - val_accuracy: 0.7676 - val_loss: 1.2855\n",
      "Epoch 65/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6594 - loss: 0.8445 - val_accuracy: 0.7535 - val_loss: 1.2956\n",
      "Epoch 66/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6595 - loss: 0.8052 - val_accuracy: 0.7394 - val_loss: 1.3787\n",
      "Epoch 67/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6831 - loss: 0.8422 - val_accuracy: 0.7324 - val_loss: 1.4075\n",
      "Epoch 68/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6459 - loss: 0.8912 - val_accuracy: 0.7465 - val_loss: 1.4011\n",
      "Epoch 69/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6470 - loss: 0.9176 - val_accuracy: 0.7535 - val_loss: 1.3941\n",
      "Epoch 70/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6783 - loss: 0.8290 - val_accuracy: 0.7465 - val_loss: 1.3792\n",
      "Epoch 71/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6696 - loss: 0.8488 - val_accuracy: 0.7394 - val_loss: 1.3872\n",
      "Epoch 72/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6542 - loss: 0.8377 - val_accuracy: 0.7676 - val_loss: 1.3855\n",
      "Epoch 73/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7123 - loss: 0.7784 - val_accuracy: 0.7535 - val_loss: 1.4101\n",
      "Epoch 74/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 0.8095 - val_accuracy: 0.7465 - val_loss: 1.3543\n",
      "Epoch 75/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - loss: 0.7788 - val_accuracy: 0.7465 - val_loss: 1.3813\n",
      "Epoch 76/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6486 - loss: 0.8427 - val_accuracy: 0.7606 - val_loss: 1.3747\n",
      "Epoch 77/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6769 - loss: 0.8112 - val_accuracy: 0.7746 - val_loss: 1.3485\n",
      "Epoch 78/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6382 - loss: 0.8353 - val_accuracy: 0.7817 - val_loss: 1.3337\n",
      "Epoch 79/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6470 - loss: 0.9284 - val_accuracy: 0.7535 - val_loss: 1.3134\n",
      "Epoch 80/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6361 - loss: 0.8465 - val_accuracy: 0.7606 - val_loss: 1.3176\n",
      "Epoch 81/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6779 - loss: 0.8536 - val_accuracy: 0.8099 - val_loss: 1.3323\n",
      "Epoch 82/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6587 - loss: 0.8230 - val_accuracy: 0.8028 - val_loss: 1.3571\n",
      "Epoch 83/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6687 - loss: 0.8099 - val_accuracy: 0.8028 - val_loss: 1.3659\n",
      "Epoch 84/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 0.7964 - val_accuracy: 0.7817 - val_loss: 1.4123\n",
      "Epoch 85/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6490 - loss: 0.8971 - val_accuracy: 0.7465 - val_loss: 1.4603\n",
      "Epoch 86/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6765 - loss: 0.8217 - val_accuracy: 0.7465 - val_loss: 1.3812\n",
      "Epoch 87/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6246 - loss: 0.8345 - val_accuracy: 0.7746 - val_loss: 1.3904\n",
      "Epoch 88/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7097 - loss: 0.7525 - val_accuracy: 0.7817 - val_loss: 1.3828\n",
      "Epoch 89/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6920 - loss: 0.7988 - val_accuracy: 0.7958 - val_loss: 1.3657\n",
      "Epoch 90/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6607 - loss: 0.8285 - val_accuracy: 0.8099 - val_loss: 1.3542\n",
      "Epoch 91/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7061 - loss: 0.7892 - val_accuracy: 0.8028 - val_loss: 1.3415\n",
      "Epoch 92/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 0.7296 - val_accuracy: 0.8028 - val_loss: 1.3506\n",
      "Epoch 93/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6968 - loss: 0.7156 - val_accuracy: 0.8028 - val_loss: 1.3355\n",
      "Epoch 94/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6863 - loss: 0.7391 - val_accuracy: 0.7887 - val_loss: 1.3569\n",
      "Epoch 95/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6570 - loss: 0.8583 - val_accuracy: 0.7958 - val_loss: 1.3858\n",
      "Epoch 96/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6987 - loss: 0.7613 - val_accuracy: 0.7887 - val_loss: 1.3624\n",
      "Epoch 97/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6483 - loss: 0.8991 - val_accuracy: 0.7958 - val_loss: 1.3879\n",
      "Epoch 98/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6441 - loss: 0.8254 - val_accuracy: 0.8310 - val_loss: 1.3963\n",
      "Epoch 99/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6806 - loss: 0.7808 - val_accuracy: 0.8099 - val_loss: 1.3501\n",
      "Epoch 100/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6949 - loss: 0.8468 - val_accuracy: 0.7746 - val_loss: 1.2980\n",
      "Epoch 101/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.7904 - val_accuracy: 0.7958 - val_loss: 1.2757\n",
      "Epoch 102/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 0.7872 - val_accuracy: 0.7887 - val_loss: 1.2897\n",
      "Epoch 103/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7004 - loss: 0.7354 - val_accuracy: 0.8028 - val_loss: 1.3303\n",
      "Epoch 104/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6869 - loss: 0.8612 - val_accuracy: 0.7887 - val_loss: 1.2904\n",
      "Epoch 105/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 0.7751 - val_accuracy: 0.7958 - val_loss: 1.2828\n",
      "Epoch 106/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.7368 - val_accuracy: 0.7887 - val_loss: 1.2686\n",
      "Epoch 107/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.7901 - val_accuracy: 0.7746 - val_loss: 1.2509\n",
      "Epoch 108/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6958 - loss: 0.7506 - val_accuracy: 0.7676 - val_loss: 1.2921\n",
      "Epoch 109/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7062 - loss: 0.6880 - val_accuracy: 0.7817 - val_loss: 1.2605\n",
      "Epoch 110/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6900 - loss: 0.7665 - val_accuracy: 0.8169 - val_loss: 1.2164\n",
      "Epoch 111/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6463 - loss: 0.8582 - val_accuracy: 0.8028 - val_loss: 1.1442\n",
      "Epoch 112/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7203 - loss: 0.7230 - val_accuracy: 0.8239 - val_loss: 1.1523\n",
      "Epoch 113/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6913 - loss: 0.8078 - val_accuracy: 0.8310 - val_loss: 1.1226\n",
      "Epoch 114/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.6924 - val_accuracy: 0.7887 - val_loss: 1.1508\n",
      "Epoch 115/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7058 - loss: 0.7204 - val_accuracy: 0.8169 - val_loss: 1.1574\n",
      "Epoch 116/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7012 - loss: 0.7826 - val_accuracy: 0.8169 - val_loss: 1.1895\n",
      "Epoch 117/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7052 - loss: 0.7155 - val_accuracy: 0.8310 - val_loss: 1.2291\n",
      "Epoch 118/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6833 - loss: 0.7861 - val_accuracy: 0.7887 - val_loss: 1.3095\n",
      "Epoch 119/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7512 - loss: 0.6723 - val_accuracy: 0.8099 - val_loss: 1.3107\n",
      "Epoch 120/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6824 - loss: 0.7510 - val_accuracy: 0.7958 - val_loss: 1.3020\n",
      "Epoch 121/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7196 - loss: 0.7434 - val_accuracy: 0.8028 - val_loss: 1.2693\n",
      "Epoch 122/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.7697 - val_accuracy: 0.8239 - val_loss: 1.2938\n",
      "Epoch 123/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6739 - loss: 0.7220 - val_accuracy: 0.8028 - val_loss: 1.2400\n",
      "Epoch 124/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.7510 - val_accuracy: 0.8028 - val_loss: 1.2635\n",
      "Epoch 125/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7253 - loss: 0.7123 - val_accuracy: 0.7958 - val_loss: 1.2678\n",
      "Epoch 126/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.6369 - val_accuracy: 0.7958 - val_loss: 1.2177\n",
      "Epoch 127/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7022 - loss: 0.7342 - val_accuracy: 0.8239 - val_loss: 1.2537\n",
      "Epoch 128/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.7018 - val_accuracy: 0.8028 - val_loss: 1.2099\n",
      "Epoch 129/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7141 - loss: 0.7482 - val_accuracy: 0.8028 - val_loss: 1.2397\n",
      "Epoch 130/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7184 - loss: 0.7188 - val_accuracy: 0.8028 - val_loss: 1.2550\n",
      "Epoch 131/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6758 - loss: 0.7406 - val_accuracy: 0.8028 - val_loss: 1.1947\n",
      "Epoch 132/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7409 - loss: 0.6415 - val_accuracy: 0.7817 - val_loss: 1.2316\n",
      "Epoch 133/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6854 - loss: 0.7824 - val_accuracy: 0.7958 - val_loss: 1.2880\n",
      "Epoch 134/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7211 - loss: 0.7162 - val_accuracy: 0.8239 - val_loss: 1.3249\n",
      "Epoch 135/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.7124 - val_accuracy: 0.8310 - val_loss: 1.2884\n",
      "Epoch 136/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.7139 - val_accuracy: 0.8239 - val_loss: 1.2680\n",
      "Epoch 137/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7324 - loss: 0.6589 - val_accuracy: 0.8099 - val_loss: 1.2564\n",
      "Epoch 138/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7394 - loss: 0.6402 - val_accuracy: 0.8028 - val_loss: 1.2266\n",
      "Epoch 139/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7148 - loss: 0.7336 - val_accuracy: 0.8028 - val_loss: 1.2062\n",
      "Epoch 140/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.6362 - val_accuracy: 0.8099 - val_loss: 1.1845\n",
      "Epoch 141/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.6752 - val_accuracy: 0.8239 - val_loss: 1.1878\n",
      "Epoch 142/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7469 - loss: 0.7159 - val_accuracy: 0.8169 - val_loss: 1.1043\n",
      "Epoch 143/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.6373 - val_accuracy: 0.7958 - val_loss: 1.0847\n",
      "Epoch 144/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7370 - loss: 0.6446 - val_accuracy: 0.8028 - val_loss: 1.1126\n",
      "Epoch 145/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6838 - loss: 0.7361 - val_accuracy: 0.8099 - val_loss: 1.1404\n",
      "Epoch 146/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7517 - loss: 0.6550 - val_accuracy: 0.8169 - val_loss: 1.1506\n",
      "Epoch 147/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7168 - loss: 0.7664 - val_accuracy: 0.8099 - val_loss: 1.1528\n",
      "Epoch 148/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7389 - loss: 0.6748 - val_accuracy: 0.8169 - val_loss: 1.1441\n",
      "Epoch 149/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7173 - loss: 0.6763 - val_accuracy: 0.8310 - val_loss: 1.1442\n",
      "Epoch 150/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.6614 - val_accuracy: 0.8239 - val_loss: 1.1680\n",
      "Epoch 151/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.7132 - val_accuracy: 0.8310 - val_loss: 1.1519\n",
      "Epoch 152/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7003 - loss: 0.6740 - val_accuracy: 0.8169 - val_loss: 1.1892\n",
      "Epoch 153/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7240 - loss: 0.7259 - val_accuracy: 0.7958 - val_loss: 1.2119\n",
      "Epoch 154/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6776 - loss: 0.7378 - val_accuracy: 0.7958 - val_loss: 1.2469\n",
      "Epoch 155/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.6707 - val_accuracy: 0.8028 - val_loss: 1.1963\n",
      "Epoch 156/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7463 - loss: 0.6638 - val_accuracy: 0.8099 - val_loss: 1.1670\n",
      "Epoch 157/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7339 - loss: 0.6935 - val_accuracy: 0.8239 - val_loss: 1.1657\n",
      "Epoch 158/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7235 - loss: 0.6837 - val_accuracy: 0.8310 - val_loss: 1.1617\n",
      "Epoch 159/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7196 - loss: 0.7364 - val_accuracy: 0.8099 - val_loss: 1.1689\n",
      "Epoch 160/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7342 - loss: 0.6722 - val_accuracy: 0.8310 - val_loss: 1.1941\n",
      "Epoch 161/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7233 - loss: 0.6448 - val_accuracy: 0.8310 - val_loss: 1.1374\n",
      "Epoch 162/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6997 - loss: 0.7275 - val_accuracy: 0.8169 - val_loss: 1.0927\n",
      "Epoch 163/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7145 - loss: 0.7171 - val_accuracy: 0.7958 - val_loss: 1.1004\n",
      "Epoch 164/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7539 - loss: 0.6324 - val_accuracy: 0.8310 - val_loss: 1.1037\n",
      "Epoch 165/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7123 - loss: 0.7028 - val_accuracy: 0.8169 - val_loss: 1.0974\n",
      "Epoch 166/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7401 - loss: 0.6502 - val_accuracy: 0.8099 - val_loss: 1.0602\n",
      "Epoch 167/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.5828 - val_accuracy: 0.8099 - val_loss: 1.0789\n",
      "Epoch 168/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.6370 - val_accuracy: 0.8239 - val_loss: 1.1026\n",
      "Epoch 169/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.6483 - val_accuracy: 0.8310 - val_loss: 1.1372\n",
      "Epoch 170/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7102 - loss: 0.7428 - val_accuracy: 0.8099 - val_loss: 1.1708\n",
      "Epoch 171/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7168 - loss: 0.6852 - val_accuracy: 0.8169 - val_loss: 1.1607\n",
      "Epoch 172/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7493 - loss: 0.6271 - val_accuracy: 0.8169 - val_loss: 1.1837\n",
      "Epoch 173/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7592 - loss: 0.6543 - val_accuracy: 0.8380 - val_loss: 1.1780\n",
      "Epoch 174/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.6331 - val_accuracy: 0.8028 - val_loss: 1.2057\n",
      "Epoch 175/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6989 - loss: 0.6825 - val_accuracy: 0.8099 - val_loss: 1.2311\n",
      "Epoch 176/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7442 - loss: 0.6076 - val_accuracy: 0.8310 - val_loss: 1.2184\n",
      "Epoch 177/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.7300 - val_accuracy: 0.8239 - val_loss: 1.2275\n",
      "Epoch 178/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7455 - loss: 0.6498 - val_accuracy: 0.8310 - val_loss: 1.2253\n",
      "Epoch 179/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7519 - loss: 0.6293 - val_accuracy: 0.8239 - val_loss: 1.2321\n",
      "Epoch 180/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7122 - loss: 0.7173 - val_accuracy: 0.8380 - val_loss: 1.2021\n",
      "Epoch 181/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.6591 - val_accuracy: 0.8310 - val_loss: 1.2230\n",
      "Epoch 182/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7473 - loss: 0.7058 - val_accuracy: 0.8380 - val_loss: 1.2066\n",
      "Epoch 183/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7908 - loss: 0.5207 - val_accuracy: 0.8310 - val_loss: 1.2419\n",
      "Epoch 184/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7704 - loss: 0.5940 - val_accuracy: 0.8239 - val_loss: 1.2725\n",
      "Epoch 185/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 0.6740 - val_accuracy: 0.8310 - val_loss: 1.2475\n",
      "Epoch 186/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7653 - loss: 0.5748 - val_accuracy: 0.8380 - val_loss: 1.2557\n",
      "Epoch 187/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7695 - loss: 0.5992 - val_accuracy: 0.8521 - val_loss: 1.1410\n",
      "Epoch 188/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7348 - loss: 0.6674 - val_accuracy: 0.8380 - val_loss: 1.1234\n",
      "Epoch 189/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7753 - loss: 0.6082 - val_accuracy: 0.8380 - val_loss: 1.1483\n",
      "Epoch 190/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.6295 - val_accuracy: 0.8380 - val_loss: 1.1606\n",
      "Epoch 191/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7695 - loss: 0.6375 - val_accuracy: 0.8239 - val_loss: 1.1177\n",
      "Epoch 192/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.5545 - val_accuracy: 0.8169 - val_loss: 1.2234\n",
      "Epoch 193/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7319 - loss: 0.6914 - val_accuracy: 0.8521 - val_loss: 1.3128\n",
      "Epoch 194/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7613 - loss: 0.5587 - val_accuracy: 0.8380 - val_loss: 1.3660\n",
      "Epoch 195/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7754 - loss: 0.5607 - val_accuracy: 0.8451 - val_loss: 1.2625\n",
      "Epoch 196/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.6130 - val_accuracy: 0.8239 - val_loss: 1.1633\n",
      "Epoch 197/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 0.6046 - val_accuracy: 0.8592 - val_loss: 1.1569\n",
      "Epoch 198/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7052 - loss: 0.6791 - val_accuracy: 0.8310 - val_loss: 1.2067\n",
      "Epoch 199/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 0.5860 - val_accuracy: 0.8239 - val_loss: 1.1987\n",
      "Epoch 200/200\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.6649 - val_accuracy: 0.8239 - val_loss: 1.2328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2825b21cc20>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(4,)),  \n",
    "    BatchNormalization(),  # Helps stabilize training\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    # Dense(32, activation='relu'),\n",
    "    # Dropout(0.2),\n",
    "\n",
    "    Dense(label_count, activation='softmax') \n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(learning_rate=0.0005), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(model.summary())\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=16, validation_split=0.2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('B_value_model.h5')\n",
    "\n",
    "\n",
    "\n",
    "model.output_names=['output']\n",
    "input_signature = [tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name='digit')]\n",
    "\n",
    "# Convert the Keras model to ONNX format\n",
    "#onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, opset=13)\n",
    "\n",
    "\n",
    "(onnx_model_proto, storage) = tf2onnx.convert.from_keras(model,input_signature=input_signature, opset=13)\n",
    "with open('modelData.onnx', \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
