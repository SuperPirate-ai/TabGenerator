{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1415, 4)\n",
      "Training labels shape: (1415, 6)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"b_values.json\") as f:\n",
    "#     b_values = json.load(f)\n",
    "    \n",
    "# with open(\"avg_amplitude_ratios.json\") as f:\n",
    "#     avg_amplitude_ratios = json.load(f)\n",
    "\n",
    "with open(\"results.csv\") as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "strings = [\"h_E\", \"B\", \"G\", \"D\", \"A\", \"E\"]\n",
    "labels = np.array([0,1,2,3,4,5])\n",
    "# strings = [\"1-2h_E\", \"1-2B\", \"1-2G\", \"1-2D\", \"1-2A\", \"1-2E\", \"2-2h_E\", \"2-2B\", \"2-2G\", \"2-2D\", \"2-2A\", \"2-2E\"]\n",
    "# labels = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "\n",
    "\n",
    "data = []\n",
    "label_list = []\n",
    "\n",
    "for i, line in enumerate(results):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    string,metric,amp_ra,deviation,f0 = line.split(\",\")\n",
    "    if string in strings:\n",
    "        metric = float(metric)\n",
    "        amp_ra = float(amp_ra)\n",
    "        deviation = float(deviation)\n",
    "        f0 = float(f0)\n",
    "        data.append([metric,amp_ra, deviation,f0])\n",
    "        label_list.append(labels[strings.index(string)])\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "label_count = 6\n",
    "labels_categorical = tf.keras.utils.to_categorical(label_list, num_classes=label_count)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert your data to numpy arrays if they are not already\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "val_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 2)\n",
    "print(f\"Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1382 - loss: 2.1307 - val_accuracy: 0.1767 - val_loss: 1.7856\n",
      "Epoch 2/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1770 - loss: 1.9308 - val_accuracy: 0.2085 - val_loss: 1.7588\n",
      "Epoch 3/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1948 - loss: 1.8192 - val_accuracy: 0.2686 - val_loss: 1.7262\n",
      "Epoch 4/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2589 - loss: 1.7174 - val_accuracy: 0.3110 - val_loss: 1.6890\n",
      "Epoch 5/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2898 - loss: 1.6487 - val_accuracy: 0.3463 - val_loss: 1.6464\n",
      "Epoch 6/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3526 - loss: 1.5850 - val_accuracy: 0.3816 - val_loss: 1.6007\n",
      "Epoch 7/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3461 - loss: 1.5363 - val_accuracy: 0.3887 - val_loss: 1.5535\n",
      "Epoch 8/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3634 - loss: 1.4873 - val_accuracy: 0.4170 - val_loss: 1.5052\n",
      "Epoch 9/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4079 - loss: 1.4895 - val_accuracy: 0.4558 - val_loss: 1.4602\n",
      "Epoch 10/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4241 - loss: 1.4113 - val_accuracy: 0.4594 - val_loss: 1.4153\n",
      "Epoch 11/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4472 - loss: 1.3851 - val_accuracy: 0.4876 - val_loss: 1.3736\n",
      "Epoch 12/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4471 - loss: 1.3559 - val_accuracy: 0.5230 - val_loss: 1.3337\n",
      "Epoch 13/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4586 - loss: 1.3286 - val_accuracy: 0.5442 - val_loss: 1.2975\n",
      "Epoch 14/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5101 - loss: 1.2775 - val_accuracy: 0.5618 - val_loss: 1.2639\n",
      "Epoch 15/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5101 - loss: 1.2726 - val_accuracy: 0.5724 - val_loss: 1.2314\n",
      "Epoch 16/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5026 - loss: 1.2312 - val_accuracy: 0.5724 - val_loss: 1.2021\n",
      "Epoch 17/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5296 - loss: 1.1950 - val_accuracy: 0.5689 - val_loss: 1.1750\n",
      "Epoch 18/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5520 - loss: 1.1890 - val_accuracy: 0.5724 - val_loss: 1.1497\n",
      "Epoch 19/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5374 - loss: 1.1481 - val_accuracy: 0.5689 - val_loss: 1.1263\n",
      "Epoch 20/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5526 - loss: 1.1462 - val_accuracy: 0.5795 - val_loss: 1.1042\n",
      "Epoch 21/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 1.1204 - val_accuracy: 0.6148 - val_loss: 1.0823\n",
      "Epoch 22/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5752 - loss: 1.0892 - val_accuracy: 0.6219 - val_loss: 1.0639\n",
      "Epoch 23/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5574 - loss: 1.0816 - val_accuracy: 0.6325 - val_loss: 1.0454\n",
      "Epoch 24/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5652 - loss: 1.1010 - val_accuracy: 0.6608 - val_loss: 1.0251\n",
      "Epoch 25/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5672 - loss: 1.0579 - val_accuracy: 0.6502 - val_loss: 1.0095\n",
      "Epoch 26/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5970 - loss: 1.0270 - val_accuracy: 0.6572 - val_loss: 0.9942\n",
      "Epoch 27/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5968 - loss: 1.0299 - val_accuracy: 0.6643 - val_loss: 0.9785\n",
      "Epoch 28/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5553 - loss: 1.0495 - val_accuracy: 0.6714 - val_loss: 0.9634\n",
      "Epoch 29/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5865 - loss: 1.0371 - val_accuracy: 0.6855 - val_loss: 0.9495\n",
      "Epoch 30/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5946 - loss: 0.9954 - val_accuracy: 0.6926 - val_loss: 0.9352\n",
      "Epoch 31/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6409 - loss: 0.9364 - val_accuracy: 0.6855 - val_loss: 0.9206\n",
      "Epoch 32/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6024 - loss: 0.9621 - val_accuracy: 0.6855 - val_loss: 0.9063\n",
      "Epoch 33/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6437 - loss: 0.9277 - val_accuracy: 0.7032 - val_loss: 0.8945\n",
      "Epoch 34/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6242 - loss: 0.9209 - val_accuracy: 0.6961 - val_loss: 0.8838\n",
      "Epoch 35/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6268 - loss: 0.9258 - val_accuracy: 0.7067 - val_loss: 0.8712\n",
      "Epoch 36/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.9378 - val_accuracy: 0.7173 - val_loss: 0.8595\n",
      "Epoch 37/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6374 - loss: 0.8861 - val_accuracy: 0.7138 - val_loss: 0.8499\n",
      "Epoch 38/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: 0.8966 - val_accuracy: 0.7173 - val_loss: 0.8434\n",
      "Epoch 39/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6161 - loss: 0.9029 - val_accuracy: 0.7173 - val_loss: 0.8332\n",
      "Epoch 40/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 0.9038 - val_accuracy: 0.7208 - val_loss: 0.8259\n",
      "Epoch 41/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6736 - loss: 0.8871 - val_accuracy: 0.7208 - val_loss: 0.8197\n",
      "Epoch 42/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6181 - loss: 0.8860 - val_accuracy: 0.7279 - val_loss: 0.8104\n",
      "Epoch 43/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6781 - loss: 0.8387 - val_accuracy: 0.7314 - val_loss: 0.8029\n",
      "Epoch 44/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.8696 - val_accuracy: 0.7350 - val_loss: 0.7972\n",
      "Epoch 45/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6649 - loss: 0.8556 - val_accuracy: 0.7456 - val_loss: 0.7893\n",
      "Epoch 46/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6353 - loss: 0.8767 - val_accuracy: 0.7420 - val_loss: 0.7840\n",
      "Epoch 47/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6672 - loss: 0.8534 - val_accuracy: 0.7456 - val_loss: 0.7755\n",
      "Epoch 48/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.8050 - val_accuracy: 0.7456 - val_loss: 0.7697\n",
      "Epoch 49/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6514 - loss: 0.8347 - val_accuracy: 0.7491 - val_loss: 0.7648\n",
      "Epoch 50/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6719 - loss: 0.8044 - val_accuracy: 0.7456 - val_loss: 0.7612\n",
      "Epoch 51/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6493 - loss: 0.8657 - val_accuracy: 0.7527 - val_loss: 0.7544\n",
      "Epoch 52/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6270 - loss: 0.8633 - val_accuracy: 0.7562 - val_loss: 0.7501\n",
      "Epoch 53/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6497 - loss: 0.8565 - val_accuracy: 0.7491 - val_loss: 0.7474\n",
      "Epoch 54/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7006 - loss: 0.7630 - val_accuracy: 0.7633 - val_loss: 0.7425\n",
      "Epoch 55/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.7829 - val_accuracy: 0.7597 - val_loss: 0.7389\n",
      "Epoch 56/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6641 - loss: 0.8248 - val_accuracy: 0.7562 - val_loss: 0.7353\n",
      "Epoch 57/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7101 - loss: 0.7503 - val_accuracy: 0.7597 - val_loss: 0.7319\n",
      "Epoch 58/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6799 - loss: 0.7518 - val_accuracy: 0.7668 - val_loss: 0.7267\n",
      "Epoch 59/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6659 - loss: 0.8065 - val_accuracy: 0.7739 - val_loss: 0.7220\n",
      "Epoch 60/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6650 - loss: 0.7974 - val_accuracy: 0.7597 - val_loss: 0.7170\n",
      "Epoch 61/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6763 - loss: 0.7706 - val_accuracy: 0.7633 - val_loss: 0.7150\n",
      "Epoch 62/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.7923 - val_accuracy: 0.7668 - val_loss: 0.7121\n",
      "Epoch 63/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6926 - loss: 0.7896 - val_accuracy: 0.7703 - val_loss: 0.7080\n",
      "Epoch 64/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6866 - loss: 0.7787 - val_accuracy: 0.7774 - val_loss: 0.7043\n",
      "Epoch 65/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6621 - loss: 0.7892 - val_accuracy: 0.7809 - val_loss: 0.7028\n",
      "Epoch 66/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6792 - loss: 0.7799 - val_accuracy: 0.7774 - val_loss: 0.6988\n",
      "Epoch 67/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6814 - loss: 0.7520 - val_accuracy: 0.7845 - val_loss: 0.6945\n",
      "Epoch 68/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6902 - loss: 0.7558 - val_accuracy: 0.7845 - val_loss: 0.6925\n",
      "Epoch 69/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6637 - loss: 0.7770 - val_accuracy: 0.7915 - val_loss: 0.6882\n",
      "Epoch 70/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7057 - loss: 0.7241 - val_accuracy: 0.7951 - val_loss: 0.6846\n",
      "Epoch 71/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6555 - loss: 0.7983 - val_accuracy: 0.7951 - val_loss: 0.6835\n",
      "Epoch 72/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 0.8025 - val_accuracy: 0.7880 - val_loss: 0.6837\n",
      "Epoch 73/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.7609 - val_accuracy: 0.7809 - val_loss: 0.6825\n",
      "Epoch 74/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6824 - loss: 0.7205 - val_accuracy: 0.7845 - val_loss: 0.6802\n",
      "Epoch 75/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6622 - loss: 0.8468 - val_accuracy: 0.7880 - val_loss: 0.6751\n",
      "Epoch 76/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6738 - loss: 0.7752 - val_accuracy: 0.7915 - val_loss: 0.6749\n",
      "Epoch 77/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6749 - loss: 0.7856 - val_accuracy: 0.7951 - val_loss: 0.6731\n",
      "Epoch 78/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6986 - loss: 0.7239 - val_accuracy: 0.7986 - val_loss: 0.6707\n",
      "Epoch 79/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.7424 - val_accuracy: 0.7880 - val_loss: 0.6682\n",
      "Epoch 80/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6769 - loss: 0.7646 - val_accuracy: 0.7809 - val_loss: 0.6661\n",
      "Epoch 81/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.7781 - val_accuracy: 0.7986 - val_loss: 0.6623\n",
      "Epoch 82/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6941 - loss: 0.7591 - val_accuracy: 0.8021 - val_loss: 0.6602\n",
      "Epoch 83/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.7320 - val_accuracy: 0.8021 - val_loss: 0.6592\n",
      "Epoch 84/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.6785 - val_accuracy: 0.8057 - val_loss: 0.6585\n",
      "Epoch 85/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.7006 - val_accuracy: 0.8092 - val_loss: 0.6562\n",
      "Epoch 86/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7080 - loss: 0.7343 - val_accuracy: 0.8092 - val_loss: 0.6532\n",
      "Epoch 87/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6899 - loss: 0.7461 - val_accuracy: 0.8198 - val_loss: 0.6496\n",
      "Epoch 88/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.7309 - val_accuracy: 0.8163 - val_loss: 0.6470\n",
      "Epoch 89/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6887 - loss: 0.7588 - val_accuracy: 0.8092 - val_loss: 0.6472\n",
      "Epoch 90/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6722 - loss: 0.7635 - val_accuracy: 0.8127 - val_loss: 0.6461\n",
      "Epoch 91/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.6869 - val_accuracy: 0.8092 - val_loss: 0.6438\n",
      "Epoch 92/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.6901 - val_accuracy: 0.8127 - val_loss: 0.6410\n",
      "Epoch 93/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7127 - loss: 0.7167 - val_accuracy: 0.8127 - val_loss: 0.6407\n",
      "Epoch 94/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6795 - loss: 0.7181 - val_accuracy: 0.8198 - val_loss: 0.6382\n",
      "Epoch 95/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7060 - loss: 0.7139 - val_accuracy: 0.8163 - val_loss: 0.6389\n",
      "Epoch 96/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7160 - loss: 0.6980 - val_accuracy: 0.8127 - val_loss: 0.6372\n",
      "Epoch 97/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.6897 - val_accuracy: 0.8163 - val_loss: 0.6340\n",
      "Epoch 98/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.7074 - val_accuracy: 0.8127 - val_loss: 0.6322\n",
      "Epoch 99/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.7097 - val_accuracy: 0.8163 - val_loss: 0.6305\n",
      "Epoch 100/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7183 - loss: 0.7095 - val_accuracy: 0.8163 - val_loss: 0.6293\n",
      "Epoch 101/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.7227 - val_accuracy: 0.8163 - val_loss: 0.6281\n",
      "Epoch 102/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.6577 - val_accuracy: 0.8198 - val_loss: 0.6269\n",
      "Epoch 103/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.7109 - val_accuracy: 0.8198 - val_loss: 0.6256\n",
      "Epoch 104/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6896 - loss: 0.7397 - val_accuracy: 0.8233 - val_loss: 0.6243\n",
      "Epoch 105/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6794 - loss: 0.7837 - val_accuracy: 0.8163 - val_loss: 0.6240\n",
      "Epoch 106/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7213 - loss: 0.6758 - val_accuracy: 0.8198 - val_loss: 0.6251\n",
      "Epoch 107/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.7348 - val_accuracy: 0.8233 - val_loss: 0.6217\n",
      "Epoch 108/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6987 - loss: 0.7442 - val_accuracy: 0.8233 - val_loss: 0.6206\n",
      "Epoch 109/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7087 - loss: 0.6837 - val_accuracy: 0.8127 - val_loss: 0.6199\n",
      "Epoch 110/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7173 - loss: 0.7101 - val_accuracy: 0.8233 - val_loss: 0.6182\n",
      "Epoch 111/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.6692 - val_accuracy: 0.8163 - val_loss: 0.6161\n",
      "Epoch 112/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6995 - loss: 0.7250 - val_accuracy: 0.8163 - val_loss: 0.6155\n",
      "Epoch 113/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6925 - loss: 0.7336 - val_accuracy: 0.8163 - val_loss: 0.6128\n",
      "Epoch 114/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7053 - loss: 0.6898 - val_accuracy: 0.8198 - val_loss: 0.6129\n",
      "Epoch 115/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7122 - loss: 0.7023 - val_accuracy: 0.8269 - val_loss: 0.6099\n",
      "Epoch 116/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.6810 - val_accuracy: 0.8163 - val_loss: 0.6088\n",
      "Epoch 117/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.6598 - val_accuracy: 0.8163 - val_loss: 0.6064\n",
      "Epoch 118/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.6654 - val_accuracy: 0.8198 - val_loss: 0.6049\n",
      "Epoch 119/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.7083 - val_accuracy: 0.8233 - val_loss: 0.6077\n",
      "Epoch 120/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.6411 - val_accuracy: 0.8233 - val_loss: 0.6026\n",
      "Epoch 121/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7004 - loss: 0.7377 - val_accuracy: 0.8198 - val_loss: 0.6020\n",
      "Epoch 122/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.6345 - val_accuracy: 0.8269 - val_loss: 0.6025\n",
      "Epoch 123/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.6460 - val_accuracy: 0.8269 - val_loss: 0.6022\n",
      "Epoch 124/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.7095 - val_accuracy: 0.8233 - val_loss: 0.6021\n",
      "Epoch 125/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.6636 - val_accuracy: 0.8233 - val_loss: 0.5976\n",
      "Epoch 126/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.6380 - val_accuracy: 0.8269 - val_loss: 0.5962\n",
      "Epoch 127/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.6397 - val_accuracy: 0.8304 - val_loss: 0.5944\n",
      "Epoch 128/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7511 - loss: 0.6261 - val_accuracy: 0.8269 - val_loss: 0.5942\n",
      "Epoch 129/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6818 - loss: 0.7178 - val_accuracy: 0.8233 - val_loss: 0.5915\n",
      "Epoch 130/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.6743 - val_accuracy: 0.8304 - val_loss: 0.5939\n",
      "Epoch 131/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.6334 - val_accuracy: 0.8304 - val_loss: 0.5909\n",
      "Epoch 132/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.6708 - val_accuracy: 0.8269 - val_loss: 0.5896\n",
      "Epoch 133/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.6513 - val_accuracy: 0.8339 - val_loss: 0.5877\n",
      "Epoch 134/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.6805 - val_accuracy: 0.8269 - val_loss: 0.5871\n",
      "Epoch 135/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.6521 - val_accuracy: 0.8339 - val_loss: 0.5863\n",
      "Epoch 136/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.6492 - val_accuracy: 0.8339 - val_loss: 0.5818\n",
      "Epoch 137/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6979 - loss: 0.7343 - val_accuracy: 0.8339 - val_loss: 0.5812\n",
      "Epoch 138/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.6380 - val_accuracy: 0.8269 - val_loss: 0.5832\n",
      "Epoch 139/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.6498 - val_accuracy: 0.8339 - val_loss: 0.5797\n",
      "Epoch 140/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.6937 - val_accuracy: 0.8445 - val_loss: 0.5789\n",
      "Epoch 141/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.6360 - val_accuracy: 0.8304 - val_loss: 0.5779\n",
      "Epoch 142/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.6427 - val_accuracy: 0.8339 - val_loss: 0.5765\n",
      "Epoch 143/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7587 - loss: 0.6260 - val_accuracy: 0.8375 - val_loss: 0.5744\n",
      "Epoch 144/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.5996 - val_accuracy: 0.8375 - val_loss: 0.5719\n",
      "Epoch 145/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.7074 - val_accuracy: 0.8375 - val_loss: 0.5712\n",
      "Epoch 146/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7521 - loss: 0.6409 - val_accuracy: 0.8304 - val_loss: 0.5695\n",
      "Epoch 147/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7208 - loss: 0.6910 - val_accuracy: 0.8375 - val_loss: 0.5685\n",
      "Epoch 148/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7093 - loss: 0.7192 - val_accuracy: 0.8375 - val_loss: 0.5685\n",
      "Epoch 149/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6938 - loss: 0.7080 - val_accuracy: 0.8410 - val_loss: 0.5676\n",
      "Epoch 150/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7142 - loss: 0.6430 - val_accuracy: 0.8410 - val_loss: 0.5670\n",
      "Epoch 151/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7599 - loss: 0.6497 - val_accuracy: 0.8410 - val_loss: 0.5664\n",
      "Epoch 152/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.6543 - val_accuracy: 0.8410 - val_loss: 0.5652\n",
      "Epoch 153/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.7304 - val_accuracy: 0.8445 - val_loss: 0.5648\n",
      "Epoch 154/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.6690 - val_accuracy: 0.8410 - val_loss: 0.5637\n",
      "Epoch 155/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.6446 - val_accuracy: 0.8445 - val_loss: 0.5639\n",
      "Epoch 156/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7534 - loss: 0.6154 - val_accuracy: 0.8410 - val_loss: 0.5640\n",
      "Epoch 157/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7246 - loss: 0.6544 - val_accuracy: 0.8445 - val_loss: 0.5621\n",
      "Epoch 158/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.6670 - val_accuracy: 0.8410 - val_loss: 0.5620\n",
      "Epoch 159/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.6271 - val_accuracy: 0.8445 - val_loss: 0.5636\n",
      "Epoch 160/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7524 - loss: 0.6279 - val_accuracy: 0.8445 - val_loss: 0.5619\n",
      "Epoch 161/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.6212 - val_accuracy: 0.8481 - val_loss: 0.5603\n",
      "Epoch 162/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7530 - loss: 0.6183 - val_accuracy: 0.8445 - val_loss: 0.5583\n",
      "Epoch 163/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.6390 - val_accuracy: 0.8481 - val_loss: 0.5564\n",
      "Epoch 164/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.6217 - val_accuracy: 0.8445 - val_loss: 0.5554\n",
      "Epoch 165/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.6460 - val_accuracy: 0.8481 - val_loss: 0.5561\n",
      "Epoch 166/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7479 - loss: 0.6324 - val_accuracy: 0.8481 - val_loss: 0.5561\n",
      "Epoch 167/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.6447 - val_accuracy: 0.8481 - val_loss: 0.5549\n",
      "Epoch 168/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.6551 - val_accuracy: 0.8481 - val_loss: 0.5526\n",
      "Epoch 169/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.6836 - val_accuracy: 0.8481 - val_loss: 0.5524\n",
      "Epoch 170/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.6942 - val_accuracy: 0.8481 - val_loss: 0.5510\n",
      "Epoch 171/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7490 - loss: 0.6342 - val_accuracy: 0.8587 - val_loss: 0.5511\n",
      "Epoch 172/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7236 - loss: 0.6655 - val_accuracy: 0.8551 - val_loss: 0.5492\n",
      "Epoch 173/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7517 - loss: 0.6156 - val_accuracy: 0.8587 - val_loss: 0.5485\n",
      "Epoch 174/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.6397 - val_accuracy: 0.8516 - val_loss: 0.5488\n",
      "Epoch 175/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7249 - loss: 0.6704 - val_accuracy: 0.8587 - val_loss: 0.5459\n",
      "Epoch 176/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.6047 - val_accuracy: 0.8587 - val_loss: 0.5446\n",
      "Epoch 177/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.5857 - val_accuracy: 0.8587 - val_loss: 0.5460\n",
      "Epoch 178/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.6279 - val_accuracy: 0.8445 - val_loss: 0.5463\n",
      "Epoch 179/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.5951 - val_accuracy: 0.8551 - val_loss: 0.5436\n",
      "Epoch 180/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.6469 - val_accuracy: 0.8551 - val_loss: 0.5422\n",
      "Epoch 181/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.6251 - val_accuracy: 0.8516 - val_loss: 0.5418\n",
      "Epoch 182/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.6378 - val_accuracy: 0.8516 - val_loss: 0.5410\n",
      "Epoch 183/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7509 - loss: 0.6299 - val_accuracy: 0.8481 - val_loss: 0.5410\n",
      "Epoch 184/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.6057 - val_accuracy: 0.8516 - val_loss: 0.5391\n",
      "Epoch 185/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.6419 - val_accuracy: 0.8516 - val_loss: 0.5402\n",
      "Epoch 186/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 0.6332 - val_accuracy: 0.8516 - val_loss: 0.5411\n",
      "Epoch 187/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.5961 - val_accuracy: 0.8516 - val_loss: 0.5380\n",
      "Epoch 188/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7646 - loss: 0.6311 - val_accuracy: 0.8516 - val_loss: 0.5371\n",
      "Epoch 189/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 0.6291 - val_accuracy: 0.8551 - val_loss: 0.5369\n",
      "Epoch 190/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.6145 - val_accuracy: 0.8551 - val_loss: 0.5375\n",
      "Epoch 191/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7581 - loss: 0.6128 - val_accuracy: 0.8481 - val_loss: 0.5388\n",
      "Epoch 192/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.6086 - val_accuracy: 0.8551 - val_loss: 0.5387\n",
      "Epoch 193/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7529 - loss: 0.5922 - val_accuracy: 0.8551 - val_loss: 0.5368\n",
      "Epoch 194/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.6001 - val_accuracy: 0.8516 - val_loss: 0.5346\n",
      "Epoch 195/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7530 - loss: 0.6052 - val_accuracy: 0.8587 - val_loss: 0.5328\n",
      "Epoch 196/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7612 - loss: 0.6259 - val_accuracy: 0.8622 - val_loss: 0.5302\n",
      "Epoch 197/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.6055 - val_accuracy: 0.8445 - val_loss: 0.5307\n",
      "Epoch 198/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.6144 - val_accuracy: 0.8622 - val_loss: 0.5328\n",
      "Epoch 199/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7632 - loss: 0.5739 - val_accuracy: 0.8587 - val_loss: 0.5323\n",
      "Epoch 200/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.6197 - val_accuracy: 0.8587 - val_loss: 0.5315\n",
      "Epoch 201/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7624 - loss: 0.6113 - val_accuracy: 0.8587 - val_loss: 0.5331\n",
      "Epoch 202/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.6145 - val_accuracy: 0.8657 - val_loss: 0.5308\n",
      "Epoch 203/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.5849 - val_accuracy: 0.8622 - val_loss: 0.5286\n",
      "Epoch 204/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.5868 - val_accuracy: 0.8587 - val_loss: 0.5295\n",
      "Epoch 205/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7635 - loss: 0.6063 - val_accuracy: 0.8622 - val_loss: 0.5271\n",
      "Epoch 206/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7826 - loss: 0.5547 - val_accuracy: 0.8622 - val_loss: 0.5264\n",
      "Epoch 207/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.6091 - val_accuracy: 0.8657 - val_loss: 0.5258\n",
      "Epoch 208/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.5739 - val_accuracy: 0.8622 - val_loss: 0.5240\n",
      "Epoch 209/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.5955 - val_accuracy: 0.8657 - val_loss: 0.5235\n",
      "Epoch 210/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.6897 - val_accuracy: 0.8657 - val_loss: 0.5204\n",
      "Epoch 211/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.6015 - val_accuracy: 0.8622 - val_loss: 0.5218\n",
      "Epoch 212/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7475 - loss: 0.6139 - val_accuracy: 0.8657 - val_loss: 0.5201\n",
      "Epoch 213/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.6155 - val_accuracy: 0.8693 - val_loss: 0.5176\n",
      "Epoch 214/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7811 - loss: 0.5767 - val_accuracy: 0.8657 - val_loss: 0.5176\n",
      "Epoch 215/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.6470 - val_accuracy: 0.8622 - val_loss: 0.5177\n",
      "Epoch 216/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.5604 - val_accuracy: 0.8551 - val_loss: 0.5173\n",
      "Epoch 217/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.5622 - val_accuracy: 0.8551 - val_loss: 0.5178\n",
      "Epoch 218/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7611 - loss: 0.5738 - val_accuracy: 0.8587 - val_loss: 0.5165\n",
      "Epoch 219/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.6022 - val_accuracy: 0.8587 - val_loss: 0.5162\n",
      "Epoch 220/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7490 - loss: 0.5871 - val_accuracy: 0.8622 - val_loss: 0.5149\n",
      "Epoch 221/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7580 - loss: 0.5930 - val_accuracy: 0.8657 - val_loss: 0.5153\n",
      "Epoch 222/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7837 - loss: 0.5676 - val_accuracy: 0.8657 - val_loss: 0.5133\n",
      "Epoch 223/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7472 - loss: 0.6236 - val_accuracy: 0.8657 - val_loss: 0.5135\n",
      "Epoch 224/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.6092 - val_accuracy: 0.8587 - val_loss: 0.5147\n",
      "Epoch 225/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7542 - loss: 0.6066 - val_accuracy: 0.8551 - val_loss: 0.5140\n",
      "Epoch 226/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7492 - loss: 0.6072 - val_accuracy: 0.8587 - val_loss: 0.5131\n",
      "Epoch 227/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.5325 - val_accuracy: 0.8587 - val_loss: 0.5121\n",
      "Epoch 228/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7776 - loss: 0.5661 - val_accuracy: 0.8551 - val_loss: 0.5113\n",
      "Epoch 229/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.5818 - val_accuracy: 0.8622 - val_loss: 0.5099\n",
      "Epoch 230/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.6641 - val_accuracy: 0.8587 - val_loss: 0.5119\n",
      "Epoch 231/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.5949 - val_accuracy: 0.8622 - val_loss: 0.5092\n",
      "Epoch 232/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.5550 - val_accuracy: 0.8622 - val_loss: 0.5074\n",
      "Epoch 233/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.5751 - val_accuracy: 0.8657 - val_loss: 0.5068\n",
      "Epoch 234/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7640 - loss: 0.5857 - val_accuracy: 0.8587 - val_loss: 0.5073\n",
      "Epoch 235/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.5380 - val_accuracy: 0.8657 - val_loss: 0.5070\n",
      "Epoch 236/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.5630 - val_accuracy: 0.8657 - val_loss: 0.5062\n",
      "Epoch 237/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7516 - loss: 0.6197 - val_accuracy: 0.8657 - val_loss: 0.5059\n",
      "Epoch 238/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.6112 - val_accuracy: 0.8657 - val_loss: 0.5058\n",
      "Epoch 239/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.6375 - val_accuracy: 0.8587 - val_loss: 0.5064\n",
      "Epoch 240/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.5718 - val_accuracy: 0.8551 - val_loss: 0.5064\n",
      "Epoch 241/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.5747 - val_accuracy: 0.8622 - val_loss: 0.5075\n",
      "Epoch 242/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.5511 - val_accuracy: 0.8657 - val_loss: 0.5061\n",
      "Epoch 243/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.5643 - val_accuracy: 0.8657 - val_loss: 0.5062\n",
      "Epoch 244/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7615 - loss: 0.5849 - val_accuracy: 0.8622 - val_loss: 0.5047\n",
      "Epoch 245/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5921 - val_accuracy: 0.8657 - val_loss: 0.5042\n",
      "Epoch 246/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.5952 - val_accuracy: 0.8657 - val_loss: 0.5032\n",
      "Epoch 247/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7644 - loss: 0.5881 - val_accuracy: 0.8587 - val_loss: 0.5029\n",
      "Epoch 248/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.5273 - val_accuracy: 0.8622 - val_loss: 0.5012\n",
      "Epoch 249/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.5137 - val_accuracy: 0.8622 - val_loss: 0.5010\n",
      "Epoch 250/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.5695 - val_accuracy: 0.8622 - val_loss: 0.5023\n",
      "Epoch 251/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.6590 - val_accuracy: 0.8657 - val_loss: 0.5002\n",
      "Epoch 252/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7618 - loss: 0.5681 - val_accuracy: 0.8622 - val_loss: 0.4980\n",
      "Epoch 253/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7670 - loss: 0.5896 - val_accuracy: 0.8551 - val_loss: 0.4958\n",
      "Epoch 254/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.5471 - val_accuracy: 0.8551 - val_loss: 0.4951\n",
      "Epoch 255/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7715 - loss: 0.5674 - val_accuracy: 0.8587 - val_loss: 0.4943\n",
      "Epoch 256/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.5665 - val_accuracy: 0.8587 - val_loss: 0.4936\n",
      "Epoch 257/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.6089 - val_accuracy: 0.8587 - val_loss: 0.4949\n",
      "Epoch 258/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7747 - loss: 0.5630 - val_accuracy: 0.8657 - val_loss: 0.4954\n",
      "Epoch 259/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.5313 - val_accuracy: 0.8657 - val_loss: 0.4943\n",
      "Epoch 260/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7710 - loss: 0.5629 - val_accuracy: 0.8587 - val_loss: 0.4932\n",
      "Epoch 261/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.5508 - val_accuracy: 0.8587 - val_loss: 0.4935\n",
      "Epoch 262/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.5902 - val_accuracy: 0.8587 - val_loss: 0.4939\n",
      "Epoch 263/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.5429 - val_accuracy: 0.8587 - val_loss: 0.4919\n",
      "Epoch 264/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7559 - loss: 0.5712 - val_accuracy: 0.8587 - val_loss: 0.4899\n",
      "Epoch 265/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.5913 - val_accuracy: 0.8587 - val_loss: 0.4905\n",
      "Epoch 266/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7798 - loss: 0.5700 - val_accuracy: 0.8587 - val_loss: 0.4897\n",
      "Epoch 267/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.5460 - val_accuracy: 0.8587 - val_loss: 0.4894\n",
      "Epoch 268/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.5699 - val_accuracy: 0.8657 - val_loss: 0.4902\n",
      "Epoch 269/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7495 - loss: 0.5946 - val_accuracy: 0.8587 - val_loss: 0.4896\n",
      "Epoch 270/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7849 - loss: 0.6004 - val_accuracy: 0.8587 - val_loss: 0.4883\n",
      "Epoch 271/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.5760 - val_accuracy: 0.8587 - val_loss: 0.4863\n",
      "Epoch 272/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.5926 - val_accuracy: 0.8587 - val_loss: 0.4869\n",
      "Epoch 273/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.5698 - val_accuracy: 0.8587 - val_loss: 0.4863\n",
      "Epoch 274/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7587 - loss: 0.6184 - val_accuracy: 0.8587 - val_loss: 0.4865\n",
      "Epoch 275/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.6044 - val_accuracy: 0.8551 - val_loss: 0.4872\n",
      "Epoch 276/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7387 - loss: 0.6099 - val_accuracy: 0.8622 - val_loss: 0.4853\n",
      "Epoch 277/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7607 - loss: 0.5714 - val_accuracy: 0.8622 - val_loss: 0.4851\n",
      "Epoch 278/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.5595 - val_accuracy: 0.8622 - val_loss: 0.4834\n",
      "Epoch 279/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.5288 - val_accuracy: 0.8657 - val_loss: 0.4843\n",
      "Epoch 280/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.5120 - val_accuracy: 0.8622 - val_loss: 0.4827\n",
      "Epoch 281/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.5388 - val_accuracy: 0.8657 - val_loss: 0.4832\n",
      "Epoch 282/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.5658 - val_accuracy: 0.8657 - val_loss: 0.4817\n",
      "Epoch 283/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5525 - val_accuracy: 0.8622 - val_loss: 0.4823\n",
      "Epoch 284/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 0.5573 - val_accuracy: 0.8622 - val_loss: 0.4822\n",
      "Epoch 285/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.5534 - val_accuracy: 0.8551 - val_loss: 0.4807\n",
      "Epoch 286/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.5379 - val_accuracy: 0.8587 - val_loss: 0.4800\n",
      "Epoch 287/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.5488 - val_accuracy: 0.8587 - val_loss: 0.4789\n",
      "Epoch 288/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7912 - loss: 0.5737 - val_accuracy: 0.8551 - val_loss: 0.4812\n",
      "Epoch 289/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.5594 - val_accuracy: 0.8587 - val_loss: 0.4797\n",
      "Epoch 290/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.5396 - val_accuracy: 0.8587 - val_loss: 0.4799\n",
      "Epoch 291/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.5610 - val_accuracy: 0.8587 - val_loss: 0.4785\n",
      "Epoch 292/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.5407 - val_accuracy: 0.8622 - val_loss: 0.4787\n",
      "Epoch 293/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.5113 - val_accuracy: 0.8622 - val_loss: 0.4778\n",
      "Epoch 294/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.5176 - val_accuracy: 0.8622 - val_loss: 0.4798\n",
      "Epoch 295/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.5389 - val_accuracy: 0.8622 - val_loss: 0.4784\n",
      "Epoch 296/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7274 - loss: 0.6868 - val_accuracy: 0.8587 - val_loss: 0.4770\n",
      "Epoch 297/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7902 - loss: 0.5408 - val_accuracy: 0.8622 - val_loss: 0.4766\n",
      "Epoch 298/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.5475 - val_accuracy: 0.8622 - val_loss: 0.4751\n",
      "Epoch 299/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7738 - loss: 0.5620 - val_accuracy: 0.8657 - val_loss: 0.4758\n",
      "Epoch 300/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7879 - loss: 0.5446 - val_accuracy: 0.8622 - val_loss: 0.4764\n",
      "Epoch 301/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.5179 - val_accuracy: 0.8622 - val_loss: 0.4757\n",
      "Epoch 302/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.5407 - val_accuracy: 0.8622 - val_loss: 0.4759\n",
      "Epoch 303/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.5146 - val_accuracy: 0.8622 - val_loss: 0.4744\n",
      "Epoch 304/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.5776 - val_accuracy: 0.8622 - val_loss: 0.4741\n",
      "Epoch 305/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.5639 - val_accuracy: 0.8657 - val_loss: 0.4745\n",
      "Epoch 306/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5070 - val_accuracy: 0.8587 - val_loss: 0.4721\n",
      "Epoch 307/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.5154 - val_accuracy: 0.8657 - val_loss: 0.4733\n",
      "Epoch 308/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.5396 - val_accuracy: 0.8622 - val_loss: 0.4714\n",
      "Epoch 309/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5285 - val_accuracy: 0.8622 - val_loss: 0.4712\n",
      "Epoch 310/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.5238 - val_accuracy: 0.8587 - val_loss: 0.4716\n",
      "Epoch 311/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5190 - val_accuracy: 0.8622 - val_loss: 0.4729\n",
      "Epoch 312/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.5428 - val_accuracy: 0.8693 - val_loss: 0.4715\n",
      "Epoch 313/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8007 - loss: 0.5338 - val_accuracy: 0.8693 - val_loss: 0.4708\n",
      "Epoch 314/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7847 - loss: 0.5268 - val_accuracy: 0.8622 - val_loss: 0.4682\n",
      "Epoch 315/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.5327 - val_accuracy: 0.8622 - val_loss: 0.4683\n",
      "Epoch 316/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.5632 - val_accuracy: 0.8622 - val_loss: 0.4706\n",
      "Epoch 317/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7786 - loss: 0.5655 - val_accuracy: 0.8622 - val_loss: 0.4677\n",
      "Epoch 318/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7542 - loss: 0.5969 - val_accuracy: 0.8657 - val_loss: 0.4677\n",
      "Epoch 319/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.5393 - val_accuracy: 0.8622 - val_loss: 0.4672\n",
      "Epoch 320/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.5055 - val_accuracy: 0.8622 - val_loss: 0.4668\n",
      "Epoch 321/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.5507 - val_accuracy: 0.8622 - val_loss: 0.4683\n",
      "Epoch 322/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.5280 - val_accuracy: 0.8587 - val_loss: 0.4671\n",
      "Epoch 323/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7792 - loss: 0.5372 - val_accuracy: 0.8622 - val_loss: 0.4665\n",
      "Epoch 324/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.5212 - val_accuracy: 0.8657 - val_loss: 0.4665\n",
      "Epoch 325/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7766 - loss: 0.5322 - val_accuracy: 0.8622 - val_loss: 0.4642\n",
      "Epoch 326/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.5529 - val_accuracy: 0.8763 - val_loss: 0.4625\n",
      "Epoch 327/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8084 - loss: 0.5159 - val_accuracy: 0.8693 - val_loss: 0.4633\n",
      "Epoch 328/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7871 - loss: 0.5314 - val_accuracy: 0.8728 - val_loss: 0.4650\n",
      "Epoch 329/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.5719 - val_accuracy: 0.8657 - val_loss: 0.4632\n",
      "Epoch 330/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.5055 - val_accuracy: 0.8622 - val_loss: 0.4629\n",
      "Epoch 331/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.5385 - val_accuracy: 0.8693 - val_loss: 0.4622\n",
      "Epoch 332/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.5439 - val_accuracy: 0.8657 - val_loss: 0.4631\n",
      "Epoch 333/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7641 - loss: 0.5462 - val_accuracy: 0.8728 - val_loss: 0.4608\n",
      "Epoch 334/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.5373 - val_accuracy: 0.8657 - val_loss: 0.4614\n",
      "Epoch 335/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.5136 - val_accuracy: 0.8728 - val_loss: 0.4614\n",
      "Epoch 336/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.5207 - val_accuracy: 0.8693 - val_loss: 0.4629\n",
      "Epoch 337/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.5358 - val_accuracy: 0.8693 - val_loss: 0.4631\n",
      "Epoch 338/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.5427 - val_accuracy: 0.8622 - val_loss: 0.4619\n",
      "Epoch 339/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.5298 - val_accuracy: 0.8728 - val_loss: 0.4612\n",
      "Epoch 340/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7724 - loss: 0.5795 - val_accuracy: 0.8693 - val_loss: 0.4595\n",
      "Epoch 341/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7909 - loss: 0.5265 - val_accuracy: 0.8693 - val_loss: 0.4603\n",
      "Epoch 342/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7939 - loss: 0.5219 - val_accuracy: 0.8728 - val_loss: 0.4572\n",
      "Epoch 343/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4844 - val_accuracy: 0.8728 - val_loss: 0.4569\n",
      "Epoch 344/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7893 - loss: 0.5580 - val_accuracy: 0.8763 - val_loss: 0.4555\n",
      "Epoch 345/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.4978 - val_accuracy: 0.8799 - val_loss: 0.4557\n",
      "Epoch 346/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.4954 - val_accuracy: 0.8763 - val_loss: 0.4560\n",
      "Epoch 347/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4989 - val_accuracy: 0.8763 - val_loss: 0.4552\n",
      "Epoch 348/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7939 - loss: 0.5352 - val_accuracy: 0.8763 - val_loss: 0.4536\n",
      "Epoch 349/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.5023 - val_accuracy: 0.8763 - val_loss: 0.4533\n",
      "Epoch 350/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.5448 - val_accuracy: 0.8693 - val_loss: 0.4560\n",
      "Epoch 351/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.4803 - val_accuracy: 0.8728 - val_loss: 0.4561\n",
      "Epoch 352/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.5273 - val_accuracy: 0.8763 - val_loss: 0.4556\n",
      "Epoch 353/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4854 - val_accuracy: 0.8763 - val_loss: 0.4533\n",
      "Epoch 354/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.5265 - val_accuracy: 0.8799 - val_loss: 0.4536\n",
      "Epoch 355/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.5121 - val_accuracy: 0.8799 - val_loss: 0.4547\n",
      "Epoch 356/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.5527 - val_accuracy: 0.8763 - val_loss: 0.4521\n",
      "Epoch 357/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7710 - loss: 0.5395 - val_accuracy: 0.8763 - val_loss: 0.4523\n",
      "Epoch 358/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7792 - loss: 0.5585 - val_accuracy: 0.8763 - val_loss: 0.4525\n",
      "Epoch 359/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.5238 - val_accuracy: 0.8728 - val_loss: 0.4521\n",
      "Epoch 360/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.5317 - val_accuracy: 0.8763 - val_loss: 0.4508\n",
      "Epoch 361/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.4984 - val_accuracy: 0.8728 - val_loss: 0.4501\n",
      "Epoch 362/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.5252 - val_accuracy: 0.8763 - val_loss: 0.4505\n",
      "Epoch 363/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.5197 - val_accuracy: 0.8763 - val_loss: 0.4473\n",
      "Epoch 364/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.5474 - val_accuracy: 0.8728 - val_loss: 0.4466\n",
      "Epoch 365/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.5015 - val_accuracy: 0.8728 - val_loss: 0.4468\n",
      "Epoch 366/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.5059 - val_accuracy: 0.8763 - val_loss: 0.4477\n",
      "Epoch 367/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.5087 - val_accuracy: 0.8728 - val_loss: 0.4486\n",
      "Epoch 368/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7735 - loss: 0.5447 - val_accuracy: 0.8763 - val_loss: 0.4467\n",
      "Epoch 369/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.5367 - val_accuracy: 0.8799 - val_loss: 0.4476\n",
      "Epoch 370/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7701 - loss: 0.5406 - val_accuracy: 0.8763 - val_loss: 0.4464\n",
      "Epoch 371/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.4931 - val_accuracy: 0.8763 - val_loss: 0.4454\n",
      "Epoch 372/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4884 - val_accuracy: 0.8799 - val_loss: 0.4450\n",
      "Epoch 373/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.4752 - val_accuracy: 0.8763 - val_loss: 0.4459\n",
      "Epoch 374/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.5556 - val_accuracy: 0.8834 - val_loss: 0.4451\n",
      "Epoch 375/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.5109 - val_accuracy: 0.8799 - val_loss: 0.4439\n",
      "Epoch 376/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.5301 - val_accuracy: 0.8834 - val_loss: 0.4441\n",
      "Epoch 377/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4716 - val_accuracy: 0.8799 - val_loss: 0.4452\n",
      "Epoch 378/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.5218 - val_accuracy: 0.8799 - val_loss: 0.4435\n",
      "Epoch 379/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4890 - val_accuracy: 0.8763 - val_loss: 0.4454\n",
      "Epoch 380/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.5014 - val_accuracy: 0.8799 - val_loss: 0.4449\n",
      "Epoch 381/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4869 - val_accuracy: 0.8834 - val_loss: 0.4471\n",
      "Epoch 382/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.4997 - val_accuracy: 0.8834 - val_loss: 0.4452\n",
      "Epoch 383/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.5100 - val_accuracy: 0.8834 - val_loss: 0.4458\n",
      "Epoch 384/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.5324 - val_accuracy: 0.8834 - val_loss: 0.4437\n",
      "Epoch 385/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8155 - loss: 0.4882 - val_accuracy: 0.8799 - val_loss: 0.4431\n",
      "Epoch 386/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8187 - loss: 0.5080 - val_accuracy: 0.8799 - val_loss: 0.4401\n",
      "Epoch 387/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.5175 - val_accuracy: 0.8763 - val_loss: 0.4428\n",
      "Epoch 388/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8075 - loss: 0.4962 - val_accuracy: 0.8799 - val_loss: 0.4420\n",
      "Epoch 389/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.5158 - val_accuracy: 0.8763 - val_loss: 0.4396\n",
      "Epoch 390/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.5172 - val_accuracy: 0.8869 - val_loss: 0.4395\n",
      "Epoch 391/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7804 - loss: 0.5372 - val_accuracy: 0.8834 - val_loss: 0.4391\n",
      "Epoch 392/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.5259 - val_accuracy: 0.8834 - val_loss: 0.4368\n",
      "Epoch 393/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.4710 - val_accuracy: 0.8834 - val_loss: 0.4389\n",
      "Epoch 394/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.5335 - val_accuracy: 0.8834 - val_loss: 0.4367\n",
      "Epoch 395/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.4939 - val_accuracy: 0.8799 - val_loss: 0.4378\n",
      "Epoch 396/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.5597 - val_accuracy: 0.8728 - val_loss: 0.4372\n",
      "Epoch 397/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.5159 - val_accuracy: 0.8728 - val_loss: 0.4357\n",
      "Epoch 398/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.5059 - val_accuracy: 0.8799 - val_loss: 0.4350\n",
      "Epoch 399/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4688 - val_accuracy: 0.8799 - val_loss: 0.4349\n",
      "Epoch 400/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.5050 - val_accuracy: 0.8728 - val_loss: 0.4345\n",
      "Epoch 401/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.5029 - val_accuracy: 0.8763 - val_loss: 0.4377\n",
      "Epoch 402/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.4723 - val_accuracy: 0.8728 - val_loss: 0.4382\n",
      "Epoch 403/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5233 - val_accuracy: 0.8763 - val_loss: 0.4386\n",
      "Epoch 404/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8012 - loss: 0.5118 - val_accuracy: 0.8728 - val_loss: 0.4408\n",
      "Epoch 405/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7551 - loss: 0.6012 - val_accuracy: 0.8728 - val_loss: 0.4400\n",
      "Epoch 406/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4836 - val_accuracy: 0.8728 - val_loss: 0.4381\n",
      "Epoch 407/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.5333 - val_accuracy: 0.8834 - val_loss: 0.4355\n",
      "Epoch 408/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.4585 - val_accuracy: 0.8834 - val_loss: 0.4351\n",
      "Epoch 409/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.5091 - val_accuracy: 0.8834 - val_loss: 0.4342\n",
      "Epoch 410/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.5574 - val_accuracy: 0.8799 - val_loss: 0.4336\n",
      "Epoch 411/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.4686 - val_accuracy: 0.8728 - val_loss: 0.4326\n",
      "Epoch 412/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.4795 - val_accuracy: 0.8834 - val_loss: 0.4338\n",
      "Epoch 413/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4908 - val_accuracy: 0.8799 - val_loss: 0.4330\n",
      "Epoch 414/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8174 - loss: 0.4578 - val_accuracy: 0.8799 - val_loss: 0.4329\n",
      "Epoch 415/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.5380 - val_accuracy: 0.8834 - val_loss: 0.4322\n",
      "Epoch 416/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8499 - loss: 0.4298 - val_accuracy: 0.8834 - val_loss: 0.4310\n",
      "Epoch 417/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.5141 - val_accuracy: 0.8834 - val_loss: 0.4294\n",
      "Epoch 418/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.4893 - val_accuracy: 0.8869 - val_loss: 0.4299\n",
      "Epoch 419/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.5206 - val_accuracy: 0.8834 - val_loss: 0.4292\n",
      "Epoch 420/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.5319 - val_accuracy: 0.8799 - val_loss: 0.4301\n",
      "Epoch 421/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.4958 - val_accuracy: 0.8693 - val_loss: 0.4298\n",
      "Epoch 422/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.4864 - val_accuracy: 0.8693 - val_loss: 0.4281\n",
      "Epoch 423/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.4884 - val_accuracy: 0.8728 - val_loss: 0.4286\n",
      "Epoch 424/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.4786 - val_accuracy: 0.8799 - val_loss: 0.4282\n",
      "Epoch 425/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.5102 - val_accuracy: 0.8799 - val_loss: 0.4281\n",
      "Epoch 426/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.4780 - val_accuracy: 0.8728 - val_loss: 0.4289\n",
      "Epoch 427/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4611 - val_accuracy: 0.8799 - val_loss: 0.4271\n",
      "Epoch 428/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.4832 - val_accuracy: 0.8799 - val_loss: 0.4315\n",
      "Epoch 429/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.4482 - val_accuracy: 0.8763 - val_loss: 0.4292\n",
      "Epoch 430/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8198 - loss: 0.4565 - val_accuracy: 0.8799 - val_loss: 0.4282\n",
      "Epoch 431/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4769 - val_accuracy: 0.8799 - val_loss: 0.4269\n",
      "Epoch 432/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.4804 - val_accuracy: 0.8834 - val_loss: 0.4252\n",
      "Epoch 433/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7614 - loss: 0.5527 - val_accuracy: 0.8728 - val_loss: 0.4232\n",
      "Epoch 434/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7771 - loss: 0.5316 - val_accuracy: 0.8799 - val_loss: 0.4225\n",
      "Epoch 435/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.5025 - val_accuracy: 0.8763 - val_loss: 0.4235\n",
      "Epoch 436/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8150 - loss: 0.4561 - val_accuracy: 0.8728 - val_loss: 0.4242\n",
      "Epoch 437/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.5265 - val_accuracy: 0.8763 - val_loss: 0.4241\n",
      "Epoch 438/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.5075 - val_accuracy: 0.8869 - val_loss: 0.4253\n",
      "Epoch 439/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.4621 - val_accuracy: 0.8834 - val_loss: 0.4241\n",
      "Epoch 440/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.4998 - val_accuracy: 0.8763 - val_loss: 0.4230\n",
      "Epoch 441/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5002 - val_accuracy: 0.8834 - val_loss: 0.4217\n",
      "Epoch 442/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7713 - loss: 0.5317 - val_accuracy: 0.8763 - val_loss: 0.4231\n",
      "Epoch 443/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4855 - val_accuracy: 0.8905 - val_loss: 0.4239\n",
      "Epoch 444/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7945 - loss: 0.5384 - val_accuracy: 0.8905 - val_loss: 0.4226\n",
      "Epoch 445/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.4904 - val_accuracy: 0.8940 - val_loss: 0.4223\n",
      "Epoch 446/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.5023 - val_accuracy: 0.8869 - val_loss: 0.4216\n",
      "Epoch 447/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.4767 - val_accuracy: 0.8763 - val_loss: 0.4223\n",
      "Epoch 448/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.5041 - val_accuracy: 0.8799 - val_loss: 0.4217\n",
      "Epoch 449/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.4744 - val_accuracy: 0.8834 - val_loss: 0.4220\n",
      "Epoch 450/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.4728 - val_accuracy: 0.8869 - val_loss: 0.4225\n",
      "Epoch 451/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.4985 - val_accuracy: 0.8834 - val_loss: 0.4225\n",
      "Epoch 452/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8380 - loss: 0.4246 - val_accuracy: 0.8763 - val_loss: 0.4227\n",
      "Epoch 453/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.4856 - val_accuracy: 0.8834 - val_loss: 0.4227\n",
      "Epoch 454/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.5149 - val_accuracy: 0.8799 - val_loss: 0.4220\n",
      "Epoch 455/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4593 - val_accuracy: 0.8869 - val_loss: 0.4214\n",
      "Epoch 456/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8156 - loss: 0.4732 - val_accuracy: 0.8869 - val_loss: 0.4209\n",
      "Epoch 457/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.4896 - val_accuracy: 0.8905 - val_loss: 0.4198\n",
      "Epoch 458/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7807 - loss: 0.5221 - val_accuracy: 0.8763 - val_loss: 0.4190\n",
      "Epoch 459/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.5341 - val_accuracy: 0.8799 - val_loss: 0.4197\n",
      "Epoch 460/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.4828 - val_accuracy: 0.8763 - val_loss: 0.4200\n",
      "Epoch 461/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.5166 - val_accuracy: 0.8799 - val_loss: 0.4185\n",
      "Epoch 462/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8051 - loss: 0.4761 - val_accuracy: 0.8834 - val_loss: 0.4172\n",
      "Epoch 463/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.4636 - val_accuracy: 0.8763 - val_loss: 0.4187\n",
      "Epoch 464/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.5129 - val_accuracy: 0.8799 - val_loss: 0.4166\n",
      "Epoch 465/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4633 - val_accuracy: 0.8799 - val_loss: 0.4154\n",
      "Epoch 466/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.4583 - val_accuracy: 0.8799 - val_loss: 0.4152\n",
      "Epoch 467/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7935 - loss: 0.5438 - val_accuracy: 0.8834 - val_loss: 0.4152\n",
      "Epoch 468/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.5071 - val_accuracy: 0.8834 - val_loss: 0.4148\n",
      "Epoch 469/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4697 - val_accuracy: 0.8834 - val_loss: 0.4150\n",
      "Epoch 470/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.4419 - val_accuracy: 0.8799 - val_loss: 0.4140\n",
      "Epoch 471/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.4277 - val_accuracy: 0.8834 - val_loss: 0.4142\n",
      "Epoch 472/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8084 - loss: 0.4855 - val_accuracy: 0.8869 - val_loss: 0.4136\n",
      "Epoch 473/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.5037 - val_accuracy: 0.8834 - val_loss: 0.4142\n",
      "Epoch 474/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.4919 - val_accuracy: 0.8905 - val_loss: 0.4135\n",
      "Epoch 475/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.4862 - val_accuracy: 0.8834 - val_loss: 0.4149\n",
      "Epoch 476/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.4686 - val_accuracy: 0.8869 - val_loss: 0.4140\n",
      "Epoch 477/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.5512 - val_accuracy: 0.8905 - val_loss: 0.4139\n",
      "Epoch 478/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7978 - loss: 0.4689 - val_accuracy: 0.8869 - val_loss: 0.4147\n",
      "Epoch 479/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4553 - val_accuracy: 0.8869 - val_loss: 0.4137\n",
      "Epoch 480/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.4650 - val_accuracy: 0.8869 - val_loss: 0.4127\n",
      "Epoch 481/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7806 - loss: 0.5199 - val_accuracy: 0.8869 - val_loss: 0.4136\n",
      "Epoch 482/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.5149 - val_accuracy: 0.8869 - val_loss: 0.4123\n",
      "Epoch 483/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.4713 - val_accuracy: 0.8799 - val_loss: 0.4114\n",
      "Epoch 484/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4735 - val_accuracy: 0.8763 - val_loss: 0.4115\n",
      "Epoch 485/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.4826 - val_accuracy: 0.8799 - val_loss: 0.4119\n",
      "Epoch 486/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8104 - loss: 0.4574 - val_accuracy: 0.8869 - val_loss: 0.4112\n",
      "Epoch 487/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.4771 - val_accuracy: 0.8834 - val_loss: 0.4111\n",
      "Epoch 488/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7863 - loss: 0.5479 - val_accuracy: 0.8834 - val_loss: 0.4091\n",
      "Epoch 489/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.5013 - val_accuracy: 0.8834 - val_loss: 0.4088\n",
      "Epoch 490/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.5125 - val_accuracy: 0.8869 - val_loss: 0.4089\n",
      "Epoch 491/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.4621 - val_accuracy: 0.8834 - val_loss: 0.4092\n",
      "Epoch 492/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4982 - val_accuracy: 0.8799 - val_loss: 0.4103\n",
      "Epoch 493/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.4653 - val_accuracy: 0.8799 - val_loss: 0.4116\n",
      "Epoch 494/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4504 - val_accuracy: 0.8834 - val_loss: 0.4117\n",
      "Epoch 495/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4981 - val_accuracy: 0.8869 - val_loss: 0.4120\n",
      "Epoch 496/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.4618 - val_accuracy: 0.8693 - val_loss: 0.4107\n",
      "Epoch 497/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4960 - val_accuracy: 0.8799 - val_loss: 0.4105\n",
      "Epoch 498/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.4886 - val_accuracy: 0.8799 - val_loss: 0.4095\n",
      "Epoch 499/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.5154 - val_accuracy: 0.8799 - val_loss: 0.4092\n",
      "Epoch 500/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.4373 - val_accuracy: 0.8799 - val_loss: 0.4097\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(55, activation='relu'),\n",
    "    BatchNormalization(),  # Helps stabilize training\n",
    "    Dropout(0.3),\n",
    "    Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "   \n",
    "    Dense(label_count, activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(learning_rate=0.00008), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(model.summary())\n",
    "#implement early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_split=0.2,callbacks=early_stopping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "stringnames = [\"E\", \"A\", \"D\", \"G\", \"B\", \"h_E\"]\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=stringnames, yticklabels=stringnames)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "ERROR:tf2onnx.tfonnx:rewriter <function rewrite_constant_fold at 0x0000027D46C70550>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4)\n"
     ]
    }
   ],
   "source": [
    "model.save('stringDetectionML.h5')\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "model.output_names=['output']\n",
    "input_signature = [tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name='digit')]\n",
    "print(model.inputs[0].shape) \n",
    "# Convert the Keras model to ONNX format\n",
    "#onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, opset=13)\n",
    "\n",
    "\n",
    "(onnx_model_proto, storage) = tf2onnx.convert.from_keras(model,input_signature=input_signature, opset=13)\n",
    "\n",
    "dir = os.getcwd()\n",
    "dir = dir.split(\"/\")[0]\n",
    "while( path.basename(dir) != \"TabGenerator\"): # go to the TabGenerator directory\n",
    "    dir = os.path.dirname(dir)\n",
    "\n",
    "dir = os.path.join(dir, \"Assets\",\"MachineLearning\",\"MLModels\")\n",
    "onnxpath = os.path.join(dir, \"stringDetectionML_ONNX.onnx\")\n",
    "\n",
    "with open(onnxpath, \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
