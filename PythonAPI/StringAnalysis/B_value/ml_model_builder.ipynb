{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (708, 4)\n",
      "Training labels shape: (708, 6)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"b_values.json\") as f:\n",
    "#     b_values = json.load(f)\n",
    "    \n",
    "# with open(\"avg_amplitude_ratios.json\") as f:\n",
    "#     avg_amplitude_ratios = json.load(f)\n",
    "\n",
    "with open(\"results.csv\") as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "strings = [\"h_E\", \"B\", \"G\", \"D\", \"A\", \"E\"]\n",
    "labels = np.array([0,1,2,3,4,5])\n",
    "# strings = [\"1-2h_E\", \"1-2B\", \"1-2G\", \"1-2D\", \"1-2A\", \"1-2E\", \"2-2h_E\", \"2-2B\", \"2-2G\", \"2-2D\", \"2-2A\", \"2-2E\"]\n",
    "# labels = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "\n",
    "\n",
    "data = []\n",
    "label_list = []\n",
    "\n",
    "for i, line in enumerate(results):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    string,metric,amp_ra,deviation,f0 = line.split(\",\")\n",
    "    if string in strings:\n",
    "        metric = float(metric)\n",
    "        amp_ra = float(amp_ra)\n",
    "        deviation = float(deviation)\n",
    "        f0 = float(f0)\n",
    "        data.append([metric,amp_ra, deviation,f0])\n",
    "        label_list.append(labels[strings.index(string)])\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "label_count = 6\n",
    "labels_categorical = tf.keras.utils.to_categorical(label_list, num_classes=label_count)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert your data to numpy arrays if they are not already\n",
    "X = np.array(X_train)\n",
    "y = np.array(y_train)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "val_accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 2)\n",
    "print(f\"Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_64          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_65          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">336</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_106 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │           \u001b[38;5;34m275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_64          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_72 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_107 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │         \u001b[38;5;34m3,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_65          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_73 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_108 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m336\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,131</span> (16.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,131\u001b[0m (16.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,911</span> (15.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,911\u001b[0m (15.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> (880.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m220\u001b[0m (880.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.1146 - loss: 2.9702 - val_accuracy: 0.1754 - val_loss: 1.8303\n",
      "Epoch 2/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2485 - loss: 2.3725 - val_accuracy: 0.3246 - val_loss: 1.7749\n",
      "Epoch 3/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2419 - loss: 2.2203 - val_accuracy: 0.2982 - val_loss: 1.7337\n",
      "Epoch 4/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3824 - loss: 1.7525 - val_accuracy: 0.3333 - val_loss: 1.7065\n",
      "Epoch 5/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3984 - loss: 1.6988 - val_accuracy: 0.4035 - val_loss: 1.6677\n",
      "Epoch 6/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3915 - loss: 1.6511 - val_accuracy: 0.4561 - val_loss: 1.6241\n",
      "Epoch 7/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4208 - loss: 1.4842 - val_accuracy: 0.5088 - val_loss: 1.5752\n",
      "Epoch 8/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3753 - loss: 1.6361 - val_accuracy: 0.5263 - val_loss: 1.5309\n",
      "Epoch 9/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4225 - loss: 1.3449 - val_accuracy: 0.5702 - val_loss: 1.4761\n",
      "Epoch 10/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4176 - loss: 1.4359 - val_accuracy: 0.5614 - val_loss: 1.4526\n",
      "Epoch 11/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4290 - loss: 1.3917 - val_accuracy: 0.6228 - val_loss: 1.4327\n",
      "Epoch 12/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4362 - loss: 1.3610 - val_accuracy: 0.6491 - val_loss: 1.4018\n",
      "Epoch 13/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5107 - loss: 1.3459 - val_accuracy: 0.7105 - val_loss: 1.3846\n",
      "Epoch 14/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4844 - loss: 1.3568 - val_accuracy: 0.7281 - val_loss: 1.3721\n",
      "Epoch 15/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5317 - loss: 1.2531 - val_accuracy: 0.7105 - val_loss: 1.3461\n",
      "Epoch 16/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5115 - loss: 1.1766 - val_accuracy: 0.7368 - val_loss: 1.3241\n",
      "Epoch 17/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4927 - loss: 1.2696 - val_accuracy: 0.7368 - val_loss: 1.3032\n",
      "Epoch 18/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5228 - loss: 1.2499 - val_accuracy: 0.7193 - val_loss: 1.3034\n",
      "Epoch 19/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5331 - loss: 1.1979 - val_accuracy: 0.7193 - val_loss: 1.2694\n",
      "Epoch 20/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5230 - loss: 1.1758 - val_accuracy: 0.7193 - val_loss: 1.2632\n",
      "Epoch 21/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5184 - loss: 1.1476 - val_accuracy: 0.7281 - val_loss: 1.2467\n",
      "Epoch 22/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5362 - loss: 1.1481 - val_accuracy: 0.7368 - val_loss: 1.2586\n",
      "Epoch 23/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5497 - loss: 1.2255 - val_accuracy: 0.7281 - val_loss: 1.2860\n",
      "Epoch 24/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5972 - loss: 1.0917 - val_accuracy: 0.7281 - val_loss: 1.2832\n",
      "Epoch 25/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5882 - loss: 1.0229 - val_accuracy: 0.7281 - val_loss: 1.2972\n",
      "Epoch 26/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5558 - loss: 1.0849 - val_accuracy: 0.7368 - val_loss: 1.3072\n",
      "Epoch 27/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6025 - loss: 1.0718 - val_accuracy: 0.7281 - val_loss: 1.3101\n",
      "Epoch 28/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5654 - loss: 1.1350 - val_accuracy: 0.7368 - val_loss: 1.3216\n",
      "Epoch 29/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5704 - loss: 1.1331 - val_accuracy: 0.7281 - val_loss: 1.3140\n",
      "Epoch 30/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5870 - loss: 1.0547 - val_accuracy: 0.7281 - val_loss: 1.3290\n",
      "Epoch 31/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5859 - loss: 1.0039 - val_accuracy: 0.7281 - val_loss: 1.3349\n",
      "Epoch 32/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5906 - loss: 1.0335 - val_accuracy: 0.7281 - val_loss: 1.3411\n",
      "Epoch 33/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 1.1234 - val_accuracy: 0.7281 - val_loss: 1.3308\n",
      "Epoch 34/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5828 - loss: 1.0579 - val_accuracy: 0.7193 - val_loss: 1.3334\n",
      "Epoch 35/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5578 - loss: 1.0858 - val_accuracy: 0.7105 - val_loss: 1.3438\n",
      "Epoch 36/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5771 - loss: 1.0310 - val_accuracy: 0.7018 - val_loss: 1.3347\n",
      "Epoch 37/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5817 - loss: 1.0354 - val_accuracy: 0.7105 - val_loss: 1.3477\n",
      "Epoch 38/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5812 - loss: 0.9758 - val_accuracy: 0.7018 - val_loss: 1.3369\n",
      "Epoch 39/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 0.9322 - val_accuracy: 0.7105 - val_loss: 1.3222\n",
      "Epoch 40/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6063 - loss: 0.9561 - val_accuracy: 0.7368 - val_loss: 1.3480\n",
      "Epoch 41/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5582 - loss: 1.0450 - val_accuracy: 0.7368 - val_loss: 1.3506\n",
      "Epoch 42/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6282 - loss: 0.9548 - val_accuracy: 0.7456 - val_loss: 1.3255\n",
      "Epoch 43/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6007 - loss: 0.9604 - val_accuracy: 0.7544 - val_loss: 1.3447\n",
      "Epoch 44/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5628 - loss: 0.9999 - val_accuracy: 0.7193 - val_loss: 1.3718\n",
      "Epoch 45/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6264 - loss: 0.8839 - val_accuracy: 0.7281 - val_loss: 1.3918\n",
      "Epoch 46/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.9329 - val_accuracy: 0.7368 - val_loss: 1.3918\n",
      "Epoch 47/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6197 - loss: 0.9609 - val_accuracy: 0.7281 - val_loss: 1.4038\n",
      "Epoch 48/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6140 - loss: 0.9665 - val_accuracy: 0.7193 - val_loss: 1.4031\n",
      "Epoch 49/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5642 - loss: 0.9562 - val_accuracy: 0.7368 - val_loss: 1.4174\n",
      "Epoch 50/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5585 - loss: 0.9881 - val_accuracy: 0.7456 - val_loss: 1.4362\n",
      "Epoch 51/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6439 - loss: 0.9113 - val_accuracy: 0.7456 - val_loss: 1.4219\n",
      "Epoch 52/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.8620 - val_accuracy: 0.7456 - val_loss: 1.4351\n",
      "Epoch 53/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6120 - loss: 0.9213 - val_accuracy: 0.7281 - val_loss: 1.4351\n",
      "Epoch 54/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6296 - loss: 0.9872 - val_accuracy: 0.7105 - val_loss: 1.4065\n",
      "Epoch 55/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6453 - loss: 0.8980 - val_accuracy: 0.7456 - val_loss: 1.4323\n",
      "Epoch 56/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5959 - loss: 0.9722 - val_accuracy: 0.7368 - val_loss: 1.4405\n",
      "Epoch 57/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5822 - loss: 0.9964 - val_accuracy: 0.7368 - val_loss: 1.4787\n",
      "Epoch 58/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6059 - loss: 0.9461 - val_accuracy: 0.7105 - val_loss: 1.5225\n",
      "Epoch 59/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6464 - loss: 0.8576 - val_accuracy: 0.7281 - val_loss: 1.5302\n",
      "Epoch 60/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6632 - loss: 0.8612 - val_accuracy: 0.7193 - val_loss: 1.5383\n",
      "Epoch 61/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6309 - loss: 0.9466 - val_accuracy: 0.7368 - val_loss: 1.5548\n",
      "Epoch 62/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6193 - loss: 0.9256 - val_accuracy: 0.7281 - val_loss: 1.5471\n",
      "Epoch 63/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6783 - loss: 0.8476 - val_accuracy: 0.7193 - val_loss: 1.5609\n",
      "Epoch 64/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6489 - loss: 0.9238 - val_accuracy: 0.7193 - val_loss: 1.5340\n",
      "Epoch 65/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6331 - loss: 0.8884 - val_accuracy: 0.7193 - val_loss: 1.5572\n",
      "Epoch 66/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6633 - loss: 0.8524 - val_accuracy: 0.7193 - val_loss: 1.4885\n",
      "Epoch 67/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6385 - loss: 0.8470 - val_accuracy: 0.7193 - val_loss: 1.4694\n",
      "Epoch 68/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5958 - loss: 0.9292 - val_accuracy: 0.7456 - val_loss: 1.4311\n",
      "Epoch 69/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6316 - loss: 0.9551 - val_accuracy: 0.7281 - val_loss: 1.4551\n",
      "Epoch 70/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6369 - loss: 0.8789 - val_accuracy: 0.7368 - val_loss: 1.4583\n",
      "Epoch 71/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6363 - loss: 0.8974 - val_accuracy: 0.7281 - val_loss: 1.4500\n",
      "Epoch 72/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6248 - loss: 0.8503 - val_accuracy: 0.7281 - val_loss: 1.4844\n",
      "Epoch 73/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 0.8633 - val_accuracy: 0.7368 - val_loss: 1.5415\n",
      "Epoch 74/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6024 - loss: 0.9368 - val_accuracy: 0.7281 - val_loss: 1.5585\n",
      "Epoch 75/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6045 - loss: 0.9341 - val_accuracy: 0.7456 - val_loss: 1.5851\n",
      "Epoch 76/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6129 - loss: 0.8617 - val_accuracy: 0.7368 - val_loss: 1.5721\n",
      "Epoch 77/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 0.8293 - val_accuracy: 0.7105 - val_loss: 1.5698\n",
      "Epoch 78/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6560 - loss: 0.8995 - val_accuracy: 0.7105 - val_loss: 1.5457\n",
      "Epoch 79/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6608 - loss: 0.8917 - val_accuracy: 0.7193 - val_loss: 1.5432\n",
      "Epoch 80/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6233 - loss: 0.8961 - val_accuracy: 0.7368 - val_loss: 1.5241\n",
      "Epoch 81/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6663 - loss: 0.8332 - val_accuracy: 0.7456 - val_loss: 1.5181\n",
      "Epoch 82/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6905 - loss: 0.7828 - val_accuracy: 0.7281 - val_loss: 1.5036\n",
      "Epoch 83/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6387 - loss: 0.9180 - val_accuracy: 0.7281 - val_loss: 1.4918\n",
      "Epoch 84/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6772 - loss: 0.8345 - val_accuracy: 0.7368 - val_loss: 1.4954\n",
      "Epoch 85/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6969 - loss: 0.7827 - val_accuracy: 0.7281 - val_loss: 1.4950\n",
      "Epoch 86/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6718 - loss: 0.8185 - val_accuracy: 0.7368 - val_loss: 1.4859\n",
      "Epoch 87/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6457 - loss: 0.8169 - val_accuracy: 0.7281 - val_loss: 1.4380\n",
      "Epoch 88/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6745 - loss: 0.7833 - val_accuracy: 0.7281 - val_loss: 1.4305\n",
      "Epoch 89/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6719 - loss: 0.8115 - val_accuracy: 0.7193 - val_loss: 1.4670\n",
      "Epoch 90/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6660 - loss: 0.8154 - val_accuracy: 0.7193 - val_loss: 1.4703\n",
      "Epoch 91/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.8452 - val_accuracy: 0.7544 - val_loss: 1.4591\n",
      "Epoch 92/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6766 - loss: 0.7840 - val_accuracy: 0.7544 - val_loss: 1.4375\n",
      "Epoch 93/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6502 - loss: 0.7322 - val_accuracy: 0.7544 - val_loss: 1.4561\n",
      "Epoch 94/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6767 - loss: 0.8044 - val_accuracy: 0.7456 - val_loss: 1.5017\n",
      "Epoch 95/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6155 - loss: 0.8299 - val_accuracy: 0.7456 - val_loss: 1.5261\n",
      "Epoch 96/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6217 - loss: 0.9129 - val_accuracy: 0.7281 - val_loss: 1.5680\n",
      "Epoch 97/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6303 - loss: 0.8981 - val_accuracy: 0.7456 - val_loss: 1.4948\n",
      "Epoch 98/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6452 - loss: 0.8121 - val_accuracy: 0.7544 - val_loss: 1.4602\n",
      "Epoch 99/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 0.7601 - val_accuracy: 0.7368 - val_loss: 1.5260\n",
      "Epoch 100/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6543 - loss: 0.8423 - val_accuracy: 0.7281 - val_loss: 1.5181\n",
      "Epoch 101/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6277 - loss: 0.8265 - val_accuracy: 0.7368 - val_loss: 1.5269\n",
      "Epoch 102/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6957 - loss: 0.7695 - val_accuracy: 0.7105 - val_loss: 1.5407\n",
      "Epoch 103/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6441 - loss: 0.8458 - val_accuracy: 0.7456 - val_loss: 1.5481\n",
      "Epoch 104/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7210 - loss: 0.7581 - val_accuracy: 0.7456 - val_loss: 1.4808\n",
      "Epoch 105/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6554 - loss: 0.8494 - val_accuracy: 0.7632 - val_loss: 1.5019\n",
      "Epoch 106/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6286 - loss: 0.8334 - val_accuracy: 0.7544 - val_loss: 1.5423\n",
      "Epoch 107/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6958 - loss: 0.6993 - val_accuracy: 0.7632 - val_loss: 1.5892\n",
      "Epoch 108/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6881 - loss: 0.8142 - val_accuracy: 0.7719 - val_loss: 1.5621\n",
      "Epoch 109/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7203 - loss: 0.7049 - val_accuracy: 0.7632 - val_loss: 1.6193\n",
      "Epoch 110/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6819 - loss: 0.7509 - val_accuracy: 0.7719 - val_loss: 1.6663\n",
      "Epoch 111/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.7265 - val_accuracy: 0.7632 - val_loss: 1.7186\n",
      "Epoch 112/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6778 - loss: 0.7908 - val_accuracy: 0.7807 - val_loss: 1.6987\n",
      "Epoch 113/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6609 - loss: 0.8242 - val_accuracy: 0.7456 - val_loss: 1.7091\n",
      "Epoch 114/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6967 - loss: 0.7846 - val_accuracy: 0.7719 - val_loss: 1.7128\n",
      "Epoch 115/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6510 - loss: 0.8648 - val_accuracy: 0.8070 - val_loss: 1.7244\n",
      "Epoch 116/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7000 - loss: 0.7946 - val_accuracy: 0.7895 - val_loss: 1.7362\n",
      "Epoch 117/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6894 - loss: 0.7447 - val_accuracy: 0.7982 - val_loss: 1.7408\n",
      "Epoch 118/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7054 - loss: 0.7693 - val_accuracy: 0.8246 - val_loss: 1.6943\n",
      "Epoch 119/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6975 - loss: 0.7786 - val_accuracy: 0.8246 - val_loss: 1.6262\n",
      "Epoch 120/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7089 - loss: 0.7812 - val_accuracy: 0.8070 - val_loss: 1.5721\n",
      "Epoch 121/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.9039 - val_accuracy: 0.8158 - val_loss: 1.5963\n",
      "Epoch 122/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7378 - loss: 0.7189 - val_accuracy: 0.7632 - val_loss: 1.6390\n",
      "Epoch 123/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6678 - loss: 0.8374 - val_accuracy: 0.7982 - val_loss: 1.5993\n",
      "Epoch 124/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.8513 - val_accuracy: 0.8070 - val_loss: 1.5775\n",
      "Epoch 125/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6691 - loss: 0.8052 - val_accuracy: 0.8070 - val_loss: 1.6265\n",
      "Epoch 126/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6269 - loss: 0.7971 - val_accuracy: 0.8158 - val_loss: 1.6378\n",
      "Epoch 127/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6912 - loss: 0.7589 - val_accuracy: 0.7982 - val_loss: 1.6497\n",
      "Epoch 128/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6839 - loss: 0.7942 - val_accuracy: 0.8158 - val_loss: 1.6240\n",
      "Epoch 129/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6430 - loss: 0.8441 - val_accuracy: 0.8246 - val_loss: 1.6439\n",
      "Epoch 130/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7286 - loss: 0.6878 - val_accuracy: 0.8070 - val_loss: 1.6795\n",
      "Epoch 131/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7004 - loss: 0.8037 - val_accuracy: 0.7895 - val_loss: 1.6732\n",
      "Epoch 132/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7352 - loss: 0.6356 - val_accuracy: 0.7719 - val_loss: 1.6952\n",
      "Epoch 133/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7373 - loss: 0.7418 - val_accuracy: 0.7807 - val_loss: 1.6627\n",
      "Epoch 134/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6909 - loss: 0.7353 - val_accuracy: 0.7719 - val_loss: 1.6734\n",
      "Epoch 135/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7256 - loss: 0.7100 - val_accuracy: 0.7807 - val_loss: 1.6809\n",
      "Epoch 136/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6718 - loss: 0.8125 - val_accuracy: 0.7895 - val_loss: 1.6704\n",
      "Epoch 137/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6964 - loss: 0.7532 - val_accuracy: 0.7807 - val_loss: 1.6693\n",
      "Epoch 138/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6731 - loss: 0.7733 - val_accuracy: 0.7982 - val_loss: 1.6138\n",
      "Epoch 139/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6943 - loss: 0.7488 - val_accuracy: 0.7895 - val_loss: 1.5722\n",
      "Epoch 140/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6989 - loss: 0.7437 - val_accuracy: 0.7895 - val_loss: 1.6327\n",
      "Epoch 141/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6974 - loss: 0.7329 - val_accuracy: 0.7807 - val_loss: 1.6256\n",
      "Epoch 142/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6949 - loss: 0.7164 - val_accuracy: 0.7719 - val_loss: 1.5823\n",
      "Epoch 143/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7069 - loss: 0.7829 - val_accuracy: 0.7632 - val_loss: 1.5677\n",
      "Epoch 144/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7018 - loss: 0.7069 - val_accuracy: 0.7719 - val_loss: 1.6161\n",
      "Epoch 145/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.7446 - val_accuracy: 0.7807 - val_loss: 1.5642\n",
      "Epoch 146/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.6844 - val_accuracy: 0.7895 - val_loss: 1.5910\n",
      "Epoch 147/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7116 - loss: 0.6986 - val_accuracy: 0.7982 - val_loss: 1.6519\n",
      "Epoch 148/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.7197 - val_accuracy: 0.7719 - val_loss: 1.6182\n",
      "Epoch 149/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6961 - loss: 0.6870 - val_accuracy: 0.7807 - val_loss: 1.6444\n",
      "Epoch 150/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.7705 - val_accuracy: 0.7895 - val_loss: 1.6683\n",
      "Epoch 151/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.7079 - val_accuracy: 0.7895 - val_loss: 1.6354\n",
      "Epoch 152/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7196 - loss: 0.7230 - val_accuracy: 0.7807 - val_loss: 1.6844\n",
      "Epoch 153/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7102 - loss: 0.7234 - val_accuracy: 0.7807 - val_loss: 1.6905\n",
      "Epoch 154/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6940 - loss: 0.7216 - val_accuracy: 0.7807 - val_loss: 1.6626\n",
      "Epoch 155/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.7544 - val_accuracy: 0.7807 - val_loss: 1.6357\n",
      "Epoch 156/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7073 - loss: 0.7310 - val_accuracy: 0.7807 - val_loss: 1.6107\n",
      "Epoch 157/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.7495 - val_accuracy: 0.7982 - val_loss: 1.5814\n",
      "Epoch 158/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7082 - loss: 0.7298 - val_accuracy: 0.7632 - val_loss: 1.6335\n",
      "Epoch 159/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6936 - loss: 0.7044 - val_accuracy: 0.7895 - val_loss: 1.6655\n",
      "Epoch 160/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.7367 - val_accuracy: 0.7895 - val_loss: 1.6615\n",
      "Epoch 161/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6757 - loss: 0.7642 - val_accuracy: 0.7807 - val_loss: 1.6341\n",
      "Epoch 162/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6797 - loss: 0.7305 - val_accuracy: 0.7632 - val_loss: 1.6349\n",
      "Epoch 163/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6739 - loss: 0.7256 - val_accuracy: 0.7895 - val_loss: 1.5905\n",
      "Epoch 164/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.6368 - val_accuracy: 0.7719 - val_loss: 1.5796\n",
      "Epoch 165/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7221 - loss: 0.6826 - val_accuracy: 0.7544 - val_loss: 1.5607\n",
      "Epoch 166/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7089 - loss: 0.6551 - val_accuracy: 0.7544 - val_loss: 1.6083\n",
      "Epoch 167/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7030 - loss: 0.7023 - val_accuracy: 0.7719 - val_loss: 1.6413\n",
      "Epoch 168/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.7456 - val_accuracy: 0.7719 - val_loss: 1.6282\n",
      "Epoch 169/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.7063 - val_accuracy: 0.8158 - val_loss: 1.6304\n",
      "Epoch 170/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.6751 - val_accuracy: 0.7982 - val_loss: 1.6166\n",
      "Epoch 171/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.6921 - val_accuracy: 0.7895 - val_loss: 1.6691\n",
      "Epoch 172/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.7796 - val_accuracy: 0.8158 - val_loss: 1.6898\n",
      "Epoch 173/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7097 - loss: 0.6762 - val_accuracy: 0.7895 - val_loss: 1.7097\n",
      "Epoch 174/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7024 - loss: 0.6934 - val_accuracy: 0.7982 - val_loss: 1.7459\n",
      "Epoch 175/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6988 - loss: 0.7187 - val_accuracy: 0.7982 - val_loss: 1.7038\n",
      "Epoch 176/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7254 - loss: 0.6591 - val_accuracy: 0.8070 - val_loss: 1.7217\n",
      "Epoch 177/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6804 - loss: 0.7393 - val_accuracy: 0.7895 - val_loss: 1.7063\n",
      "Epoch 178/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.6687 - val_accuracy: 0.7719 - val_loss: 1.6744\n",
      "Epoch 179/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6914 - loss: 0.7392 - val_accuracy: 0.7895 - val_loss: 1.6410\n",
      "Epoch 180/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7017 - loss: 0.6954 - val_accuracy: 0.8070 - val_loss: 1.6493\n",
      "Epoch 181/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.7023 - val_accuracy: 0.7982 - val_loss: 1.5991\n",
      "Epoch 182/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7247 - loss: 0.6356 - val_accuracy: 0.7982 - val_loss: 1.5801\n",
      "Epoch 183/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 0.6691 - val_accuracy: 0.8158 - val_loss: 1.5846\n",
      "Epoch 184/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7398 - loss: 0.6683 - val_accuracy: 0.8070 - val_loss: 1.5819\n",
      "Epoch 185/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7547 - loss: 0.6687 - val_accuracy: 0.8070 - val_loss: 1.5223\n",
      "Epoch 186/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6560 - loss: 0.7489 - val_accuracy: 0.8158 - val_loss: 1.5927\n",
      "Epoch 187/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7544 - loss: 0.6313 - val_accuracy: 0.8509 - val_loss: 1.5920\n",
      "Epoch 188/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7619 - loss: 0.6447 - val_accuracy: 0.8158 - val_loss: 1.5925\n",
      "Epoch 189/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7046 - loss: 0.6953 - val_accuracy: 0.7807 - val_loss: 1.6066\n",
      "Epoch 190/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7368 - loss: 0.6483 - val_accuracy: 0.8070 - val_loss: 1.6386\n",
      "Epoch 191/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6858 - loss: 0.7667 - val_accuracy: 0.8070 - val_loss: 1.6354\n",
      "Epoch 192/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7235 - loss: 0.6530 - val_accuracy: 0.8070 - val_loss: 1.5881\n",
      "Epoch 193/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7228 - loss: 0.6502 - val_accuracy: 0.8421 - val_loss: 1.5824\n",
      "Epoch 194/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.6915 - val_accuracy: 0.8333 - val_loss: 1.4817\n",
      "Epoch 195/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.6728 - val_accuracy: 0.8333 - val_loss: 1.5207\n",
      "Epoch 196/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7071 - loss: 0.7129 - val_accuracy: 0.8421 - val_loss: 1.5483\n",
      "Epoch 197/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.6172 - val_accuracy: 0.7982 - val_loss: 1.5493\n",
      "Epoch 198/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6921 - loss: 0.6874 - val_accuracy: 0.8158 - val_loss: 1.5355\n",
      "Epoch 199/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7450 - loss: 0.6215 - val_accuracy: 0.8246 - val_loss: 1.5337\n",
      "Epoch 200/200\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7403 - loss: 0.7046 - val_accuracy: 0.8333 - val_loss: 1.4673\n",
      "Mean validation accuracy: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(55, activation='relu'),\n",
    "    BatchNormalization(),  # Helps stabilize training\n",
    "    Dropout(0.3),\n",
    "    Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "   \n",
    "    Dense(label_count, activation='softmax') \n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(learning_rate=0.00008), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(model.summary())\n",
    "#implement early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_split=0.2,callbacks=early_stopping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "stringnames = [\"E\", \"A\", \"D\", \"G\", \"B\", \"h_E\"]\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=stringnames, yticklabels=stringnames)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('B_value_model.h5')\n",
    "\n",
    "\n",
    "\n",
    "model.output_names=['output']\n",
    "input_signature = [tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name='digit')]\n",
    "\n",
    "# Convert the Keras model to ONNX format\n",
    "#onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=input_signature, opset=13)\n",
    "\n",
    "\n",
    "(onnx_model_proto, storage) = tf2onnx.convert.from_keras(model,input_signature=input_signature, opset=13)\n",
    "with open('modelData.onnx', \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
