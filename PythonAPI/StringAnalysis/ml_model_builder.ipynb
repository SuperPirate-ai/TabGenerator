{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization,Normalization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1415, 4)\n",
      "Training labels shape: (1415, 6)\n"
     ]
    }
   ],
   "source": [
    "with open(path.join(\"results\",\"results.csv\")) as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "strings = [\"h_E\", \"B\", \"G\", \"D\", \"A\", \"E\"]\n",
    "labels = np.array([0,1,2,3,4,5])\n",
    "\n",
    "data = []\n",
    "label_list = []\n",
    "\n",
    "for i, line in enumerate(results):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    string,metric,amp_ra,deviation,f0 = line.split(\",\")\n",
    "    if string in strings:\n",
    "        metric = float(metric)\n",
    "        amp_ra = float(amp_ra)\n",
    "        deviation = float(deviation)\n",
    "        f0 = float(f0)\n",
    "        data.append([metric,amp_ra, deviation,f0])\n",
    "        label_list.append(labels[strings.index(string)])\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=np.float32)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_count = 6\n",
    "labels_categorical = tf.keras.utils.to_categorical(label_list, num_classes=label_count)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")  # Should be (num_samples, 2)\n",
    "print(f\"Training labels shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#normalize data\n",
    "normalization_layer = Normalization(input_shape=(X_train.shape[1],))\n",
    "normalization_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">275</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization (\u001b[38;5;33mNormalization\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │           \u001b[38;5;34m275\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)             │         \u001b[38;5;34m3,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,574</span> (21.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,574\u001b[0m (21.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,455</span> (21.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,455\u001b[0m (21.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m119\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1896 - loss: 2.0793 - val_accuracy: 0.1767 - val_loss: 1.8071\n",
      "Epoch 2/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2400 - loss: 1.9213 - val_accuracy: 0.2014 - val_loss: 1.7931\n",
      "Epoch 3/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2251 - loss: 1.8289 - val_accuracy: 0.2014 - val_loss: 1.7737\n",
      "Epoch 4/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2336 - loss: 1.8085 - val_accuracy: 0.2049 - val_loss: 1.7488\n",
      "Epoch 5/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2619 - loss: 1.7055 - val_accuracy: 0.2509 - val_loss: 1.7171\n",
      "Epoch 6/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2993 - loss: 1.6604 - val_accuracy: 0.3145 - val_loss: 1.6800\n",
      "Epoch 7/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2776 - loss: 1.6241 - val_accuracy: 0.3463 - val_loss: 1.6376\n",
      "Epoch 8/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3658 - loss: 1.5400 - val_accuracy: 0.3604 - val_loss: 1.5913\n",
      "Epoch 9/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3604 - loss: 1.5127 - val_accuracy: 0.3887 - val_loss: 1.5407\n",
      "Epoch 10/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 1.4785 - val_accuracy: 0.4064 - val_loss: 1.4890\n",
      "Epoch 11/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4408 - loss: 1.4075 - val_accuracy: 0.4417 - val_loss: 1.4392\n",
      "Epoch 12/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4290 - loss: 1.3979 - val_accuracy: 0.4806 - val_loss: 1.3910\n",
      "Epoch 13/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4540 - loss: 1.3409 - val_accuracy: 0.5088 - val_loss: 1.3467\n",
      "Epoch 14/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4575 - loss: 1.3087 - val_accuracy: 0.5159 - val_loss: 1.3051\n",
      "Epoch 15/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4943 - loss: 1.2753 - val_accuracy: 0.5194 - val_loss: 1.2671\n",
      "Epoch 16/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4507 - loss: 1.2992 - val_accuracy: 0.5371 - val_loss: 1.2349\n",
      "Epoch 17/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4834 - loss: 1.2317 - val_accuracy: 0.5512 - val_loss: 1.2057\n",
      "Epoch 18/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5030 - loss: 1.2032 - val_accuracy: 0.5618 - val_loss: 1.1790\n",
      "Epoch 19/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5355 - loss: 1.1838 - val_accuracy: 0.5830 - val_loss: 1.1515\n",
      "Epoch 20/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5144 - loss: 1.1648 - val_accuracy: 0.5830 - val_loss: 1.1283\n",
      "Epoch 21/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5006 - loss: 1.1597 - val_accuracy: 0.5866 - val_loss: 1.1081\n",
      "Epoch 22/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5450 - loss: 1.1278 - val_accuracy: 0.5866 - val_loss: 1.0870\n",
      "Epoch 23/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5107 - loss: 1.1645 - val_accuracy: 0.6007 - val_loss: 1.0676\n",
      "Epoch 24/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5310 - loss: 1.1301 - val_accuracy: 0.6078 - val_loss: 1.0488\n",
      "Epoch 25/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5525 - loss: 1.0693 - val_accuracy: 0.6219 - val_loss: 1.0317\n",
      "Epoch 26/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5637 - loss: 1.0901 - val_accuracy: 0.6325 - val_loss: 1.0132\n",
      "Epoch 27/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5616 - loss: 1.0773 - val_accuracy: 0.6396 - val_loss: 0.9979\n",
      "Epoch 28/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5960 - loss: 1.0466 - val_accuracy: 0.6431 - val_loss: 0.9819\n",
      "Epoch 29/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5956 - loss: 1.0331 - val_accuracy: 0.6466 - val_loss: 0.9678\n",
      "Epoch 30/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5783 - loss: 1.0218 - val_accuracy: 0.6466 - val_loss: 0.9540\n",
      "Epoch 31/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5767 - loss: 1.0135 - val_accuracy: 0.6502 - val_loss: 0.9409\n",
      "Epoch 32/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5658 - loss: 1.0072 - val_accuracy: 0.6572 - val_loss: 0.9307\n",
      "Epoch 33/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6221 - loss: 0.9703 - val_accuracy: 0.6608 - val_loss: 0.9188\n",
      "Epoch 34/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6244 - loss: 0.9526 - val_accuracy: 0.6572 - val_loss: 0.9081\n",
      "Epoch 35/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5974 - loss: 0.9792 - val_accuracy: 0.6608 - val_loss: 0.8960\n",
      "Epoch 36/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6300 - loss: 0.9378 - val_accuracy: 0.6608 - val_loss: 0.8882\n",
      "Epoch 37/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6336 - loss: 0.9242 - val_accuracy: 0.6784 - val_loss: 0.8773\n",
      "Epoch 38/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 0.9398 - val_accuracy: 0.6890 - val_loss: 0.8690\n",
      "Epoch 39/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6120 - loss: 0.9533 - val_accuracy: 0.7032 - val_loss: 0.8609\n",
      "Epoch 40/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5862 - loss: 0.9923 - val_accuracy: 0.6996 - val_loss: 0.8513\n",
      "Epoch 41/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 0.9359 - val_accuracy: 0.7067 - val_loss: 0.8440\n",
      "Epoch 42/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6276 - loss: 0.8939 - val_accuracy: 0.7067 - val_loss: 0.8358\n",
      "Epoch 43/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6297 - loss: 0.8896 - val_accuracy: 0.7208 - val_loss: 0.8276\n",
      "Epoch 44/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6514 - loss: 0.8446 - val_accuracy: 0.7173 - val_loss: 0.8209\n",
      "Epoch 45/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6619 - loss: 0.8488 - val_accuracy: 0.7173 - val_loss: 0.8146\n",
      "Epoch 46/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.8398 - val_accuracy: 0.7208 - val_loss: 0.8077\n",
      "Epoch 47/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6505 - loss: 0.8866 - val_accuracy: 0.7279 - val_loss: 0.8003\n",
      "Epoch 48/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6578 - loss: 0.8496 - val_accuracy: 0.7279 - val_loss: 0.7967\n",
      "Epoch 49/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6403 - loss: 0.8875 - val_accuracy: 0.7385 - val_loss: 0.7892\n",
      "Epoch 50/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6367 - loss: 0.8854 - val_accuracy: 0.7420 - val_loss: 0.7829\n",
      "Epoch 51/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6230 - loss: 0.8825 - val_accuracy: 0.7385 - val_loss: 0.7777\n",
      "Epoch 52/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6455 - loss: 0.8840 - val_accuracy: 0.7491 - val_loss: 0.7711\n",
      "Epoch 53/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6656 - loss: 0.8334 - val_accuracy: 0.7527 - val_loss: 0.7651\n",
      "Epoch 54/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6399 - loss: 0.8510 - val_accuracy: 0.7456 - val_loss: 0.7605\n",
      "Epoch 55/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6450 - loss: 0.8782 - val_accuracy: 0.7527 - val_loss: 0.7545\n",
      "Epoch 56/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6892 - loss: 0.8200 - val_accuracy: 0.7456 - val_loss: 0.7497\n",
      "Epoch 57/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6599 - loss: 0.8364 - val_accuracy: 0.7562 - val_loss: 0.7458\n",
      "Epoch 58/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6720 - loss: 0.8118 - val_accuracy: 0.7562 - val_loss: 0.7436\n",
      "Epoch 59/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.7827 - val_accuracy: 0.7562 - val_loss: 0.7397\n",
      "Epoch 60/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6511 - loss: 0.7987 - val_accuracy: 0.7562 - val_loss: 0.7356\n",
      "Epoch 61/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6542 - loss: 0.8408 - val_accuracy: 0.7597 - val_loss: 0.7320\n",
      "Epoch 62/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6724 - loss: 0.7934 - val_accuracy: 0.7562 - val_loss: 0.7272\n",
      "Epoch 63/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6516 - loss: 0.8247 - val_accuracy: 0.7739 - val_loss: 0.7229\n",
      "Epoch 64/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6659 - loss: 0.7809 - val_accuracy: 0.7739 - val_loss: 0.7190\n",
      "Epoch 65/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6662 - loss: 0.7835 - val_accuracy: 0.7668 - val_loss: 0.7138\n",
      "Epoch 66/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6919 - loss: 0.7981 - val_accuracy: 0.7633 - val_loss: 0.7102\n",
      "Epoch 67/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6583 - loss: 0.7951 - val_accuracy: 0.7739 - val_loss: 0.7055\n",
      "Epoch 68/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6768 - loss: 0.7838 - val_accuracy: 0.7739 - val_loss: 0.7033\n",
      "Epoch 69/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6857 - loss: 0.7722 - val_accuracy: 0.7809 - val_loss: 0.6991\n",
      "Epoch 70/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6748 - loss: 0.7815 - val_accuracy: 0.7809 - val_loss: 0.6959\n",
      "Epoch 71/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6927 - loss: 0.7858 - val_accuracy: 0.7774 - val_loss: 0.6922\n",
      "Epoch 72/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6611 - loss: 0.7925 - val_accuracy: 0.7774 - val_loss: 0.6895\n",
      "Epoch 73/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.7445 - val_accuracy: 0.7739 - val_loss: 0.6859\n",
      "Epoch 74/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6698 - loss: 0.8001 - val_accuracy: 0.7809 - val_loss: 0.6831\n",
      "Epoch 75/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7023 - loss: 0.7659 - val_accuracy: 0.7739 - val_loss: 0.6801\n",
      "Epoch 76/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 0.7434 - val_accuracy: 0.7739 - val_loss: 0.6764\n",
      "Epoch 77/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.7603 - val_accuracy: 0.7845 - val_loss: 0.6722\n",
      "Epoch 78/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7156 - loss: 0.7372 - val_accuracy: 0.7809 - val_loss: 0.6684\n",
      "Epoch 79/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6685 - loss: 0.7795 - val_accuracy: 0.7809 - val_loss: 0.6661\n",
      "Epoch 80/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.7312 - val_accuracy: 0.7774 - val_loss: 0.6643\n",
      "Epoch 81/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6897 - loss: 0.7207 - val_accuracy: 0.7809 - val_loss: 0.6618\n",
      "Epoch 82/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6830 - loss: 0.7530 - val_accuracy: 0.7774 - val_loss: 0.6593\n",
      "Epoch 83/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6638 - loss: 0.7951 - val_accuracy: 0.7774 - val_loss: 0.6567\n",
      "Epoch 84/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6671 - loss: 0.7801 - val_accuracy: 0.7774 - val_loss: 0.6535\n",
      "Epoch 85/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6649 - loss: 0.7655 - val_accuracy: 0.7809 - val_loss: 0.6515\n",
      "Epoch 86/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.7663 - val_accuracy: 0.7809 - val_loss: 0.6503\n",
      "Epoch 87/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6956 - loss: 0.7805 - val_accuracy: 0.7809 - val_loss: 0.6490\n",
      "Epoch 88/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6818 - loss: 0.7559 - val_accuracy: 0.7845 - val_loss: 0.6448\n",
      "Epoch 89/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.7450 - val_accuracy: 0.7845 - val_loss: 0.6414\n",
      "Epoch 90/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.7730 - val_accuracy: 0.7845 - val_loss: 0.6398\n",
      "Epoch 91/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7072 - loss: 0.7222 - val_accuracy: 0.7809 - val_loss: 0.6380\n",
      "Epoch 92/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7006 - loss: 0.7074 - val_accuracy: 0.7880 - val_loss: 0.6367\n",
      "Epoch 93/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7070 - loss: 0.7127 - val_accuracy: 0.7880 - val_loss: 0.6339\n",
      "Epoch 94/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7068 - loss: 0.7097 - val_accuracy: 0.7915 - val_loss: 0.6309\n",
      "Epoch 95/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.7069 - val_accuracy: 0.7845 - val_loss: 0.6290\n",
      "Epoch 96/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7045 - loss: 0.6967 - val_accuracy: 0.7915 - val_loss: 0.6276\n",
      "Epoch 97/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.6855 - val_accuracy: 0.7951 - val_loss: 0.6252\n",
      "Epoch 98/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7182 - loss: 0.6962 - val_accuracy: 0.7915 - val_loss: 0.6232\n",
      "Epoch 99/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6839 - loss: 0.7399 - val_accuracy: 0.7951 - val_loss: 0.6224\n",
      "Epoch 100/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6801 - loss: 0.7502 - val_accuracy: 0.7915 - val_loss: 0.6184\n",
      "Epoch 101/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 0.7446 - val_accuracy: 0.7986 - val_loss: 0.6160\n",
      "Epoch 102/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7138 - loss: 0.7101 - val_accuracy: 0.8021 - val_loss: 0.6143\n",
      "Epoch 103/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7059 - loss: 0.6947 - val_accuracy: 0.8021 - val_loss: 0.6126\n",
      "Epoch 104/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.7220 - val_accuracy: 0.7986 - val_loss: 0.6085\n",
      "Epoch 105/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.6801 - val_accuracy: 0.7986 - val_loss: 0.6084\n",
      "Epoch 106/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6761 - loss: 0.7845 - val_accuracy: 0.8021 - val_loss: 0.6082\n",
      "Epoch 107/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.6687 - val_accuracy: 0.7986 - val_loss: 0.6062\n",
      "Epoch 108/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7157 - loss: 0.7343 - val_accuracy: 0.7915 - val_loss: 0.6036\n",
      "Epoch 109/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7171 - loss: 0.7013 - val_accuracy: 0.7880 - val_loss: 0.6021\n",
      "Epoch 110/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.7035 - val_accuracy: 0.8021 - val_loss: 0.5975\n",
      "Epoch 111/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.6882 - val_accuracy: 0.7951 - val_loss: 0.5968\n",
      "Epoch 112/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.7058 - val_accuracy: 0.7951 - val_loss: 0.5971\n",
      "Epoch 113/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7079 - loss: 0.6903 - val_accuracy: 0.7986 - val_loss: 0.5967\n",
      "Epoch 114/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7253 - loss: 0.7037 - val_accuracy: 0.7986 - val_loss: 0.5938\n",
      "Epoch 115/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.6504 - val_accuracy: 0.8021 - val_loss: 0.5901\n",
      "Epoch 116/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.6422 - val_accuracy: 0.8057 - val_loss: 0.5880\n",
      "Epoch 117/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7098 - loss: 0.6915 - val_accuracy: 0.7915 - val_loss: 0.5874\n",
      "Epoch 118/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7515 - loss: 0.6457 - val_accuracy: 0.8021 - val_loss: 0.5852\n",
      "Epoch 119/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.7239 - val_accuracy: 0.8057 - val_loss: 0.5841\n",
      "Epoch 120/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7080 - loss: 0.6841 - val_accuracy: 0.8092 - val_loss: 0.5808\n",
      "Epoch 121/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.6526 - val_accuracy: 0.8092 - val_loss: 0.5778\n",
      "Epoch 122/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6939 - loss: 0.7182 - val_accuracy: 0.8092 - val_loss: 0.5781\n",
      "Epoch 123/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.6839 - val_accuracy: 0.7986 - val_loss: 0.5771\n",
      "Epoch 124/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.6317 - val_accuracy: 0.8057 - val_loss: 0.5746\n",
      "Epoch 125/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6979 - loss: 0.6906 - val_accuracy: 0.8021 - val_loss: 0.5740\n",
      "Epoch 126/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.6687 - val_accuracy: 0.7986 - val_loss: 0.5722\n",
      "Epoch 127/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7481 - loss: 0.6511 - val_accuracy: 0.7986 - val_loss: 0.5706\n",
      "Epoch 128/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7478 - loss: 0.6392 - val_accuracy: 0.8127 - val_loss: 0.5690\n",
      "Epoch 129/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7255 - loss: 0.6733 - val_accuracy: 0.8163 - val_loss: 0.5660\n",
      "Epoch 130/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.7364 - val_accuracy: 0.8092 - val_loss: 0.5638\n",
      "Epoch 131/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.6776 - val_accuracy: 0.8092 - val_loss: 0.5637\n",
      "Epoch 132/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.6377 - val_accuracy: 0.8127 - val_loss: 0.5606\n",
      "Epoch 133/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.6334 - val_accuracy: 0.8092 - val_loss: 0.5584\n",
      "Epoch 134/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.7130 - val_accuracy: 0.8198 - val_loss: 0.5589\n",
      "Epoch 135/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.6723 - val_accuracy: 0.8127 - val_loss: 0.5555\n",
      "Epoch 136/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.6474 - val_accuracy: 0.8163 - val_loss: 0.5548\n",
      "Epoch 137/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7181 - loss: 0.6852 - val_accuracy: 0.8269 - val_loss: 0.5555\n",
      "Epoch 138/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7206 - loss: 0.6609 - val_accuracy: 0.8233 - val_loss: 0.5539\n",
      "Epoch 139/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7101 - loss: 0.6954 - val_accuracy: 0.8127 - val_loss: 0.5533\n",
      "Epoch 140/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.6509 - val_accuracy: 0.8163 - val_loss: 0.5528\n",
      "Epoch 141/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.6632 - val_accuracy: 0.8198 - val_loss: 0.5526\n",
      "Epoch 142/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.6717 - val_accuracy: 0.8198 - val_loss: 0.5491\n",
      "Epoch 143/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7450 - loss: 0.6742 - val_accuracy: 0.8198 - val_loss: 0.5468\n",
      "Epoch 144/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7504 - loss: 0.6512 - val_accuracy: 0.8198 - val_loss: 0.5482\n",
      "Epoch 145/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7602 - loss: 0.6164 - val_accuracy: 0.8198 - val_loss: 0.5449\n",
      "Epoch 146/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.6279 - val_accuracy: 0.8198 - val_loss: 0.5439\n",
      "Epoch 147/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7487 - loss: 0.6588 - val_accuracy: 0.8233 - val_loss: 0.5450\n",
      "Epoch 148/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.6549 - val_accuracy: 0.8233 - val_loss: 0.5425\n",
      "Epoch 149/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.6275 - val_accuracy: 0.8233 - val_loss: 0.5387\n",
      "Epoch 150/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7222 - loss: 0.6819 - val_accuracy: 0.8269 - val_loss: 0.5375\n",
      "Epoch 151/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.6842 - val_accuracy: 0.8269 - val_loss: 0.5377\n",
      "Epoch 152/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7467 - loss: 0.6362 - val_accuracy: 0.8233 - val_loss: 0.5357\n",
      "Epoch 153/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7611 - loss: 0.5933 - val_accuracy: 0.8198 - val_loss: 0.5352\n",
      "Epoch 154/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7482 - loss: 0.6387 - val_accuracy: 0.8269 - val_loss: 0.5339\n",
      "Epoch 155/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.6650 - val_accuracy: 0.8233 - val_loss: 0.5340\n",
      "Epoch 156/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.6016 - val_accuracy: 0.8198 - val_loss: 0.5322\n",
      "Epoch 157/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.5807 - val_accuracy: 0.8304 - val_loss: 0.5293\n",
      "Epoch 158/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7129 - loss: 0.6911 - val_accuracy: 0.8269 - val_loss: 0.5292\n",
      "Epoch 159/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.6907 - val_accuracy: 0.8269 - val_loss: 0.5303\n",
      "Epoch 160/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.6643 - val_accuracy: 0.8304 - val_loss: 0.5262\n",
      "Epoch 161/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.6090 - val_accuracy: 0.8304 - val_loss: 0.5259\n",
      "Epoch 162/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7001 - loss: 0.6989 - val_accuracy: 0.8269 - val_loss: 0.5273\n",
      "Epoch 163/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7576 - loss: 0.6066 - val_accuracy: 0.8198 - val_loss: 0.5258\n",
      "Epoch 164/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.6203 - val_accuracy: 0.8269 - val_loss: 0.5269\n",
      "Epoch 165/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7556 - loss: 0.6172 - val_accuracy: 0.8269 - val_loss: 0.5254\n",
      "Epoch 166/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7490 - loss: 0.5917 - val_accuracy: 0.8339 - val_loss: 0.5228\n",
      "Epoch 167/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7471 - loss: 0.6544 - val_accuracy: 0.8339 - val_loss: 0.5214\n",
      "Epoch 168/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7493 - loss: 0.6530 - val_accuracy: 0.8339 - val_loss: 0.5199\n",
      "Epoch 169/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 0.6076 - val_accuracy: 0.8375 - val_loss: 0.5184\n",
      "Epoch 170/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.6454 - val_accuracy: 0.8339 - val_loss: 0.5168\n",
      "Epoch 171/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7210 - loss: 0.6652 - val_accuracy: 0.8339 - val_loss: 0.5150\n",
      "Epoch 172/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.5626 - val_accuracy: 0.8269 - val_loss: 0.5147\n",
      "Epoch 173/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.6698 - val_accuracy: 0.8375 - val_loss: 0.5130\n",
      "Epoch 174/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7166 - loss: 0.7045 - val_accuracy: 0.8375 - val_loss: 0.5124\n",
      "Epoch 175/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 0.6727 - val_accuracy: 0.8375 - val_loss: 0.5126\n",
      "Epoch 176/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.5939 - val_accuracy: 0.8375 - val_loss: 0.5104\n",
      "Epoch 177/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7698 - loss: 0.5745 - val_accuracy: 0.8445 - val_loss: 0.5085\n",
      "Epoch 178/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.6133 - val_accuracy: 0.8375 - val_loss: 0.5074\n",
      "Epoch 179/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.6425 - val_accuracy: 0.8339 - val_loss: 0.5084\n",
      "Epoch 180/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7545 - loss: 0.6205 - val_accuracy: 0.8445 - val_loss: 0.5049\n",
      "Epoch 181/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.6299 - val_accuracy: 0.8410 - val_loss: 0.5045\n",
      "Epoch 182/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7474 - loss: 0.6219 - val_accuracy: 0.8481 - val_loss: 0.5032\n",
      "Epoch 183/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.5983 - val_accuracy: 0.8516 - val_loss: 0.5034\n",
      "Epoch 184/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.5970 - val_accuracy: 0.8481 - val_loss: 0.5022\n",
      "Epoch 185/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.5751 - val_accuracy: 0.8516 - val_loss: 0.5014\n",
      "Epoch 186/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.6293 - val_accuracy: 0.8445 - val_loss: 0.5005\n",
      "Epoch 187/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7621 - loss: 0.6172 - val_accuracy: 0.8516 - val_loss: 0.5003\n",
      "Epoch 188/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7476 - loss: 0.6145 - val_accuracy: 0.8516 - val_loss: 0.5014\n",
      "Epoch 189/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.6966 - val_accuracy: 0.8445 - val_loss: 0.5026\n",
      "Epoch 190/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7718 - loss: 0.5918 - val_accuracy: 0.8375 - val_loss: 0.5012\n",
      "Epoch 191/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.6152 - val_accuracy: 0.8445 - val_loss: 0.4998\n",
      "Epoch 192/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7593 - loss: 0.5960 - val_accuracy: 0.8445 - val_loss: 0.4973\n",
      "Epoch 193/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.6063 - val_accuracy: 0.8445 - val_loss: 0.4945\n",
      "Epoch 194/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.5975 - val_accuracy: 0.8445 - val_loss: 0.4948\n",
      "Epoch 195/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7755 - loss: 0.5578 - val_accuracy: 0.8410 - val_loss: 0.4942\n",
      "Epoch 196/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7511 - loss: 0.6151 - val_accuracy: 0.8445 - val_loss: 0.4940\n",
      "Epoch 197/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7595 - loss: 0.5928 - val_accuracy: 0.8410 - val_loss: 0.4934\n",
      "Epoch 198/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.6644 - val_accuracy: 0.8410 - val_loss: 0.4921\n",
      "Epoch 199/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.6446 - val_accuracy: 0.8339 - val_loss: 0.4904\n",
      "Epoch 200/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7713 - loss: 0.5713 - val_accuracy: 0.8445 - val_loss: 0.4891\n",
      "Epoch 201/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7860 - loss: 0.5822 - val_accuracy: 0.8445 - val_loss: 0.4887\n",
      "Epoch 202/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7550 - loss: 0.6029 - val_accuracy: 0.8481 - val_loss: 0.4882\n",
      "Epoch 203/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.5584 - val_accuracy: 0.8445 - val_loss: 0.4871\n",
      "Epoch 204/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7494 - loss: 0.6120 - val_accuracy: 0.8516 - val_loss: 0.4850\n",
      "Epoch 205/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.5733 - val_accuracy: 0.8516 - val_loss: 0.4854\n",
      "Epoch 206/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.5998 - val_accuracy: 0.8516 - val_loss: 0.4847\n",
      "Epoch 207/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.5963 - val_accuracy: 0.8481 - val_loss: 0.4824\n",
      "Epoch 208/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.5784 - val_accuracy: 0.8516 - val_loss: 0.4831\n",
      "Epoch 209/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7716 - loss: 0.5831 - val_accuracy: 0.8481 - val_loss: 0.4836\n",
      "Epoch 210/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 0.5699 - val_accuracy: 0.8516 - val_loss: 0.4818\n",
      "Epoch 211/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5427 - val_accuracy: 0.8481 - val_loss: 0.4812\n",
      "Epoch 212/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.6031 - val_accuracy: 0.8587 - val_loss: 0.4805\n",
      "Epoch 213/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.5626 - val_accuracy: 0.8516 - val_loss: 0.4785\n",
      "Epoch 214/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7806 - loss: 0.5908 - val_accuracy: 0.8551 - val_loss: 0.4792\n",
      "Epoch 215/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7612 - loss: 0.5783 - val_accuracy: 0.8551 - val_loss: 0.4789\n",
      "Epoch 216/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.5881 - val_accuracy: 0.8587 - val_loss: 0.4783\n",
      "Epoch 217/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7522 - loss: 0.6095 - val_accuracy: 0.8516 - val_loss: 0.4757\n",
      "Epoch 218/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.5774 - val_accuracy: 0.8587 - val_loss: 0.4770\n",
      "Epoch 219/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.5739 - val_accuracy: 0.8551 - val_loss: 0.4764\n",
      "Epoch 220/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.5918 - val_accuracy: 0.8516 - val_loss: 0.4750\n",
      "Epoch 221/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7674 - loss: 0.6009 - val_accuracy: 0.8516 - val_loss: 0.4753\n",
      "Epoch 222/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.6043 - val_accuracy: 0.8551 - val_loss: 0.4735\n",
      "Epoch 223/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5756 - val_accuracy: 0.8587 - val_loss: 0.4747\n",
      "Epoch 224/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.5963 - val_accuracy: 0.8587 - val_loss: 0.4738\n",
      "Epoch 225/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7971 - loss: 0.5278 - val_accuracy: 0.8587 - val_loss: 0.4724\n",
      "Epoch 226/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.5523 - val_accuracy: 0.8551 - val_loss: 0.4703\n",
      "Epoch 227/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7524 - loss: 0.5798 - val_accuracy: 0.8516 - val_loss: 0.4728\n",
      "Epoch 228/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.5568 - val_accuracy: 0.8516 - val_loss: 0.4720\n",
      "Epoch 229/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.5442 - val_accuracy: 0.8551 - val_loss: 0.4692\n",
      "Epoch 230/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7902 - loss: 0.5420 - val_accuracy: 0.8587 - val_loss: 0.4693\n",
      "Epoch 231/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.5782 - val_accuracy: 0.8587 - val_loss: 0.4712\n",
      "Epoch 232/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7898 - loss: 0.5627 - val_accuracy: 0.8622 - val_loss: 0.4688\n",
      "Epoch 233/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.5730 - val_accuracy: 0.8622 - val_loss: 0.4674\n",
      "Epoch 234/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.5429 - val_accuracy: 0.8622 - val_loss: 0.4678\n",
      "Epoch 235/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.5592 - val_accuracy: 0.8622 - val_loss: 0.4675\n",
      "Epoch 236/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7757 - loss: 0.5702 - val_accuracy: 0.8622 - val_loss: 0.4668\n",
      "Epoch 237/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7747 - loss: 0.5558 - val_accuracy: 0.8622 - val_loss: 0.4680\n",
      "Epoch 238/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.5535 - val_accuracy: 0.8587 - val_loss: 0.4649\n",
      "Epoch 239/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5764 - val_accuracy: 0.8657 - val_loss: 0.4633\n",
      "Epoch 240/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7582 - loss: 0.5996 - val_accuracy: 0.8657 - val_loss: 0.4628\n",
      "Epoch 241/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.5897 - val_accuracy: 0.8622 - val_loss: 0.4646\n",
      "Epoch 242/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.5804 - val_accuracy: 0.8622 - val_loss: 0.4636\n",
      "Epoch 243/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.5373 - val_accuracy: 0.8622 - val_loss: 0.4628\n",
      "Epoch 244/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.6305 - val_accuracy: 0.8693 - val_loss: 0.4627\n",
      "Epoch 245/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.5565 - val_accuracy: 0.8622 - val_loss: 0.4608\n",
      "Epoch 246/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.5245 - val_accuracy: 0.8551 - val_loss: 0.4613\n",
      "Epoch 247/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.5468 - val_accuracy: 0.8622 - val_loss: 0.4604\n",
      "Epoch 248/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7851 - loss: 0.5709 - val_accuracy: 0.8587 - val_loss: 0.4597\n",
      "Epoch 249/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.5820 - val_accuracy: 0.8587 - val_loss: 0.4575\n",
      "Epoch 250/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.5298 - val_accuracy: 0.8587 - val_loss: 0.4580\n",
      "Epoch 251/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.5395 - val_accuracy: 0.8622 - val_loss: 0.4589\n",
      "Epoch 252/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.5289 - val_accuracy: 0.8622 - val_loss: 0.4574\n",
      "Epoch 253/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.5456 - val_accuracy: 0.8587 - val_loss: 0.4554\n",
      "Epoch 254/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5600 - val_accuracy: 0.8657 - val_loss: 0.4543\n",
      "Epoch 255/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.5309 - val_accuracy: 0.8657 - val_loss: 0.4551\n",
      "Epoch 256/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.5065 - val_accuracy: 0.8657 - val_loss: 0.4531\n",
      "Epoch 257/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7704 - loss: 0.5855 - val_accuracy: 0.8657 - val_loss: 0.4518\n",
      "Epoch 258/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.5081 - val_accuracy: 0.8657 - val_loss: 0.4544\n",
      "Epoch 259/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7837 - loss: 0.5552 - val_accuracy: 0.8622 - val_loss: 0.4525\n",
      "Epoch 260/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.5411 - val_accuracy: 0.8657 - val_loss: 0.4503\n",
      "Epoch 261/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5567 - val_accuracy: 0.8587 - val_loss: 0.4507\n",
      "Epoch 262/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7661 - loss: 0.5469 - val_accuracy: 0.8587 - val_loss: 0.4488\n",
      "Epoch 263/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.5778 - val_accuracy: 0.8622 - val_loss: 0.4498\n",
      "Epoch 264/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7996 - loss: 0.4906 - val_accuracy: 0.8622 - val_loss: 0.4494\n",
      "Epoch 265/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7828 - loss: 0.5386 - val_accuracy: 0.8657 - val_loss: 0.4503\n",
      "Epoch 266/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7687 - loss: 0.5291 - val_accuracy: 0.8657 - val_loss: 0.4479\n",
      "Epoch 267/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.5166 - val_accuracy: 0.8587 - val_loss: 0.4474\n",
      "Epoch 268/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.5321 - val_accuracy: 0.8587 - val_loss: 0.4460\n",
      "Epoch 269/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8362 - loss: 0.4833 - val_accuracy: 0.8693 - val_loss: 0.4450\n",
      "Epoch 270/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5718 - val_accuracy: 0.8587 - val_loss: 0.4457\n",
      "Epoch 271/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.5274 - val_accuracy: 0.8551 - val_loss: 0.4483\n",
      "Epoch 272/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4944 - val_accuracy: 0.8622 - val_loss: 0.4457\n",
      "Epoch 273/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7557 - loss: 0.6130 - val_accuracy: 0.8622 - val_loss: 0.4444\n",
      "Epoch 274/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.5331 - val_accuracy: 0.8657 - val_loss: 0.4433\n",
      "Epoch 275/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.5331 - val_accuracy: 0.8657 - val_loss: 0.4444\n",
      "Epoch 276/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.5822 - val_accuracy: 0.8551 - val_loss: 0.4455\n",
      "Epoch 277/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.5225 - val_accuracy: 0.8551 - val_loss: 0.4457\n",
      "Epoch 278/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.5363 - val_accuracy: 0.8622 - val_loss: 0.4439\n",
      "Epoch 279/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.5209 - val_accuracy: 0.8622 - val_loss: 0.4431\n",
      "Epoch 280/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.5013 - val_accuracy: 0.8657 - val_loss: 0.4418\n",
      "Epoch 281/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.5638 - val_accuracy: 0.8657 - val_loss: 0.4405\n",
      "Epoch 282/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.5065 - val_accuracy: 0.8622 - val_loss: 0.4424\n",
      "Epoch 283/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7793 - loss: 0.5576 - val_accuracy: 0.8657 - val_loss: 0.4397\n",
      "Epoch 284/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7837 - loss: 0.5461 - val_accuracy: 0.8622 - val_loss: 0.4370\n",
      "Epoch 285/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7937 - loss: 0.5092 - val_accuracy: 0.8728 - val_loss: 0.4352\n",
      "Epoch 286/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.5005 - val_accuracy: 0.8693 - val_loss: 0.4355\n",
      "Epoch 287/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.5598 - val_accuracy: 0.8693 - val_loss: 0.4379\n",
      "Epoch 288/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.4937 - val_accuracy: 0.8728 - val_loss: 0.4362\n",
      "Epoch 289/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.5194 - val_accuracy: 0.8657 - val_loss: 0.4370\n",
      "Epoch 290/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.5337 - val_accuracy: 0.8587 - val_loss: 0.4397\n",
      "Epoch 291/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.4910 - val_accuracy: 0.8587 - val_loss: 0.4369\n",
      "Epoch 292/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.5096 - val_accuracy: 0.8622 - val_loss: 0.4358\n",
      "Epoch 293/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.5686 - val_accuracy: 0.8728 - val_loss: 0.4343\n",
      "Epoch 294/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7763 - loss: 0.5615 - val_accuracy: 0.8657 - val_loss: 0.4347\n",
      "Epoch 295/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.5214 - val_accuracy: 0.8693 - val_loss: 0.4321\n",
      "Epoch 296/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.5289 - val_accuracy: 0.8693 - val_loss: 0.4319\n",
      "Epoch 297/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7820 - loss: 0.5594 - val_accuracy: 0.8728 - val_loss: 0.4311\n",
      "Epoch 298/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.5277 - val_accuracy: 0.8657 - val_loss: 0.4310\n",
      "Epoch 299/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.5092 - val_accuracy: 0.8693 - val_loss: 0.4313\n",
      "Epoch 300/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.5833 - val_accuracy: 0.8693 - val_loss: 0.4303\n",
      "Epoch 301/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.5205 - val_accuracy: 0.8693 - val_loss: 0.4296\n",
      "Epoch 302/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5489 - val_accuracy: 0.8693 - val_loss: 0.4301\n",
      "Epoch 303/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.5118 - val_accuracy: 0.8728 - val_loss: 0.4271\n",
      "Epoch 304/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5102 - val_accuracy: 0.8693 - val_loss: 0.4267\n",
      "Epoch 305/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4904 - val_accuracy: 0.8693 - val_loss: 0.4265\n",
      "Epoch 306/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.5286 - val_accuracy: 0.8693 - val_loss: 0.4269\n",
      "Epoch 307/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.5320 - val_accuracy: 0.8693 - val_loss: 0.4251\n",
      "Epoch 308/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.5576 - val_accuracy: 0.8728 - val_loss: 0.4243\n",
      "Epoch 309/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8144 - loss: 0.5343 - val_accuracy: 0.8763 - val_loss: 0.4233\n",
      "Epoch 310/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.5206 - val_accuracy: 0.8728 - val_loss: 0.4243\n",
      "Epoch 311/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.4953 - val_accuracy: 0.8693 - val_loss: 0.4252\n",
      "Epoch 312/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.5066 - val_accuracy: 0.8693 - val_loss: 0.4243\n",
      "Epoch 313/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.5102 - val_accuracy: 0.8728 - val_loss: 0.4238\n",
      "Epoch 314/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.5488 - val_accuracy: 0.8728 - val_loss: 0.4238\n",
      "Epoch 315/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8096 - loss: 0.4666 - val_accuracy: 0.8693 - val_loss: 0.4246\n",
      "Epoch 316/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.4985 - val_accuracy: 0.8728 - val_loss: 0.4244\n",
      "Epoch 317/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.4947 - val_accuracy: 0.8693 - val_loss: 0.4227\n",
      "Epoch 318/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.5366 - val_accuracy: 0.8763 - val_loss: 0.4226\n",
      "Epoch 319/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7858 - loss: 0.5306 - val_accuracy: 0.8834 - val_loss: 0.4227\n",
      "Epoch 320/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.5134 - val_accuracy: 0.8763 - val_loss: 0.4241\n",
      "Epoch 321/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.4852 - val_accuracy: 0.8763 - val_loss: 0.4227\n",
      "Epoch 322/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7774 - loss: 0.5433 - val_accuracy: 0.8693 - val_loss: 0.4212\n",
      "Epoch 323/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.4927 - val_accuracy: 0.8799 - val_loss: 0.4205\n",
      "Epoch 324/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4948 - val_accuracy: 0.8763 - val_loss: 0.4208\n",
      "Epoch 325/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7762 - loss: 0.5299 - val_accuracy: 0.8799 - val_loss: 0.4198\n",
      "Epoch 326/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.5263 - val_accuracy: 0.8799 - val_loss: 0.4194\n",
      "Epoch 327/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.5301 - val_accuracy: 0.8763 - val_loss: 0.4179\n",
      "Epoch 328/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.5895 - val_accuracy: 0.8763 - val_loss: 0.4176\n",
      "Epoch 329/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.4718 - val_accuracy: 0.8799 - val_loss: 0.4159\n",
      "Epoch 330/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.5106 - val_accuracy: 0.8799 - val_loss: 0.4177\n",
      "Epoch 331/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7840 - loss: 0.5292 - val_accuracy: 0.8728 - val_loss: 0.4201\n",
      "Epoch 332/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7849 - loss: 0.5428 - val_accuracy: 0.8728 - val_loss: 0.4168\n",
      "Epoch 333/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.5844 - val_accuracy: 0.8799 - val_loss: 0.4158\n",
      "Epoch 334/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8006 - loss: 0.5322 - val_accuracy: 0.8763 - val_loss: 0.4149\n",
      "Epoch 335/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.5392 - val_accuracy: 0.8763 - val_loss: 0.4156\n",
      "Epoch 336/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.4901 - val_accuracy: 0.8728 - val_loss: 0.4163\n",
      "Epoch 337/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.5344 - val_accuracy: 0.8728 - val_loss: 0.4142\n",
      "Epoch 338/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.5332 - val_accuracy: 0.8728 - val_loss: 0.4152\n",
      "Epoch 339/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8150 - loss: 0.5418 - val_accuracy: 0.8728 - val_loss: 0.4135\n",
      "Epoch 340/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.4975 - val_accuracy: 0.8763 - val_loss: 0.4114\n",
      "Epoch 341/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.5019 - val_accuracy: 0.8763 - val_loss: 0.4109\n",
      "Epoch 342/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.5534 - val_accuracy: 0.8763 - val_loss: 0.4107\n",
      "Epoch 343/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8061 - loss: 0.4979 - val_accuracy: 0.8763 - val_loss: 0.4099\n",
      "Epoch 344/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.4873 - val_accuracy: 0.8763 - val_loss: 0.4106\n",
      "Epoch 345/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.4971 - val_accuracy: 0.8799 - val_loss: 0.4115\n",
      "Epoch 346/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4571 - val_accuracy: 0.8763 - val_loss: 0.4094\n",
      "Epoch 347/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7749 - loss: 0.5597 - val_accuracy: 0.8728 - val_loss: 0.4099\n",
      "Epoch 348/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7889 - loss: 0.5070 - val_accuracy: 0.8799 - val_loss: 0.4120\n",
      "Epoch 349/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5028 - val_accuracy: 0.8763 - val_loss: 0.4104\n",
      "Epoch 350/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4924 - val_accuracy: 0.8763 - val_loss: 0.4098\n",
      "Epoch 351/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.5098 - val_accuracy: 0.8763 - val_loss: 0.4112\n",
      "Epoch 352/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7839 - loss: 0.5146 - val_accuracy: 0.8728 - val_loss: 0.4115\n",
      "Epoch 353/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.4961 - val_accuracy: 0.8728 - val_loss: 0.4093\n",
      "Epoch 354/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.5173 - val_accuracy: 0.8693 - val_loss: 0.4100\n",
      "Epoch 355/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.5306 - val_accuracy: 0.8763 - val_loss: 0.4075\n",
      "Epoch 356/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.5072 - val_accuracy: 0.8834 - val_loss: 0.4066\n",
      "Epoch 357/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.5359 - val_accuracy: 0.8940 - val_loss: 0.4060\n",
      "Epoch 358/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.5024 - val_accuracy: 0.8905 - val_loss: 0.4060\n",
      "Epoch 359/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.4923 - val_accuracy: 0.8799 - val_loss: 0.4067\n",
      "Epoch 360/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7947 - loss: 0.4920 - val_accuracy: 0.8728 - val_loss: 0.4051\n",
      "Epoch 361/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.4898 - val_accuracy: 0.8728 - val_loss: 0.4059\n",
      "Epoch 362/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.4878 - val_accuracy: 0.8905 - val_loss: 0.4040\n",
      "Epoch 363/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.5356 - val_accuracy: 0.8834 - val_loss: 0.4035\n",
      "Epoch 364/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.4736 - val_accuracy: 0.8905 - val_loss: 0.4005\n",
      "Epoch 365/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.4793 - val_accuracy: 0.8799 - val_loss: 0.4018\n",
      "Epoch 366/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7746 - loss: 0.5220 - val_accuracy: 0.8763 - val_loss: 0.4022\n",
      "Epoch 367/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8275 - loss: 0.4599 - val_accuracy: 0.8799 - val_loss: 0.4017\n",
      "Epoch 368/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.4835 - val_accuracy: 0.8763 - val_loss: 0.4012\n",
      "Epoch 369/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.5152 - val_accuracy: 0.8905 - val_loss: 0.3995\n",
      "Epoch 370/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.4945 - val_accuracy: 0.8869 - val_loss: 0.4003\n",
      "Epoch 371/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4821 - val_accuracy: 0.8763 - val_loss: 0.4013\n",
      "Epoch 372/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4624 - val_accuracy: 0.8799 - val_loss: 0.4000\n",
      "Epoch 373/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.4935 - val_accuracy: 0.8799 - val_loss: 0.3995\n",
      "Epoch 374/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4985 - val_accuracy: 0.8905 - val_loss: 0.3974\n",
      "Epoch 375/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.4918 - val_accuracy: 0.8905 - val_loss: 0.3984\n",
      "Epoch 376/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4725 - val_accuracy: 0.8905 - val_loss: 0.3980\n",
      "Epoch 377/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.4959 - val_accuracy: 0.8834 - val_loss: 0.3975\n",
      "Epoch 378/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7971 - loss: 0.5205 - val_accuracy: 0.8799 - val_loss: 0.3964\n",
      "Epoch 379/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.4687 - val_accuracy: 0.8799 - val_loss: 0.3959\n",
      "Epoch 380/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.4978 - val_accuracy: 0.8799 - val_loss: 0.3952\n",
      "Epoch 381/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4592 - val_accuracy: 0.8834 - val_loss: 0.3957\n",
      "Epoch 382/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4978 - val_accuracy: 0.8799 - val_loss: 0.3957\n",
      "Epoch 383/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.4975 - val_accuracy: 0.8799 - val_loss: 0.3958\n",
      "Epoch 384/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.4939 - val_accuracy: 0.8834 - val_loss: 0.3948\n",
      "Epoch 385/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.4894 - val_accuracy: 0.8834 - val_loss: 0.3952\n",
      "Epoch 386/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.4880 - val_accuracy: 0.8905 - val_loss: 0.3937\n",
      "Epoch 387/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.4853 - val_accuracy: 0.8905 - val_loss: 0.3912\n",
      "Epoch 388/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8009 - loss: 0.4978 - val_accuracy: 0.8869 - val_loss: 0.3905\n",
      "Epoch 389/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.4738 - val_accuracy: 0.8905 - val_loss: 0.3924\n",
      "Epoch 390/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8087 - loss: 0.4812 - val_accuracy: 0.8905 - val_loss: 0.3936\n",
      "Epoch 391/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.4770 - val_accuracy: 0.8869 - val_loss: 0.3910\n",
      "Epoch 392/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.4789 - val_accuracy: 0.8834 - val_loss: 0.3896\n",
      "Epoch 393/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.4630 - val_accuracy: 0.8905 - val_loss: 0.3890\n",
      "Epoch 394/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.5184 - val_accuracy: 0.8869 - val_loss: 0.3897\n",
      "Epoch 395/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.4985 - val_accuracy: 0.8905 - val_loss: 0.3925\n",
      "Epoch 396/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.5046 - val_accuracy: 0.8869 - val_loss: 0.3895\n",
      "Epoch 397/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.5418 - val_accuracy: 0.8834 - val_loss: 0.3900\n",
      "Epoch 398/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.4750 - val_accuracy: 0.8834 - val_loss: 0.3880\n",
      "Epoch 399/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.4971 - val_accuracy: 0.8834 - val_loss: 0.3886\n",
      "Epoch 400/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.4697 - val_accuracy: 0.8834 - val_loss: 0.3900\n",
      "Epoch 401/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.4637 - val_accuracy: 0.8799 - val_loss: 0.3890\n",
      "Epoch 402/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4750 - val_accuracy: 0.8869 - val_loss: 0.3898\n",
      "Epoch 403/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.4662 - val_accuracy: 0.8869 - val_loss: 0.3889\n",
      "Epoch 404/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4745 - val_accuracy: 0.8834 - val_loss: 0.3876\n",
      "Epoch 405/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.4811 - val_accuracy: 0.8905 - val_loss: 0.3860\n",
      "Epoch 406/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4929 - val_accuracy: 0.8940 - val_loss: 0.3836\n",
      "Epoch 407/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5013 - val_accuracy: 0.8975 - val_loss: 0.3868\n",
      "Epoch 408/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8294 - loss: 0.4691 - val_accuracy: 0.8869 - val_loss: 0.3864\n",
      "Epoch 409/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7864 - loss: 0.5207 - val_accuracy: 0.8799 - val_loss: 0.3853\n",
      "Epoch 410/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.4922 - val_accuracy: 0.8869 - val_loss: 0.3857\n",
      "Epoch 411/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.4606 - val_accuracy: 0.8834 - val_loss: 0.3837\n",
      "Epoch 412/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.4488 - val_accuracy: 0.8940 - val_loss: 0.3847\n",
      "Epoch 413/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.4890 - val_accuracy: 0.8940 - val_loss: 0.3841\n",
      "Epoch 414/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.4655 - val_accuracy: 0.8905 - val_loss: 0.3821\n",
      "Epoch 415/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.4730 - val_accuracy: 0.8869 - val_loss: 0.3823\n",
      "Epoch 416/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7979 - loss: 0.4697 - val_accuracy: 0.8869 - val_loss: 0.3833\n",
      "Epoch 417/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4981 - val_accuracy: 0.8869 - val_loss: 0.3814\n",
      "Epoch 418/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.4105 - val_accuracy: 0.8869 - val_loss: 0.3808\n",
      "Epoch 419/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4954 - val_accuracy: 0.8869 - val_loss: 0.3810\n",
      "Epoch 420/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.5200 - val_accuracy: 0.8905 - val_loss: 0.3811\n",
      "Epoch 421/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.4977 - val_accuracy: 0.8975 - val_loss: 0.3811\n",
      "Epoch 422/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4675 - val_accuracy: 0.8940 - val_loss: 0.3800\n",
      "Epoch 423/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8260 - loss: 0.4677 - val_accuracy: 0.8975 - val_loss: 0.3807\n",
      "Epoch 424/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.4641 - val_accuracy: 0.8975 - val_loss: 0.3807\n",
      "Epoch 425/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.4995 - val_accuracy: 0.8869 - val_loss: 0.3778\n",
      "Epoch 426/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.4463 - val_accuracy: 0.8869 - val_loss: 0.3770\n",
      "Epoch 427/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4819 - val_accuracy: 0.8869 - val_loss: 0.3762\n",
      "Epoch 428/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8380 - loss: 0.4334 - val_accuracy: 0.8834 - val_loss: 0.3750\n",
      "Epoch 429/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8149 - loss: 0.4583 - val_accuracy: 0.8834 - val_loss: 0.3770\n",
      "Epoch 430/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8087 - loss: 0.4572 - val_accuracy: 0.8869 - val_loss: 0.3759\n",
      "Epoch 431/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.4361 - val_accuracy: 0.8940 - val_loss: 0.3770\n",
      "Epoch 432/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8003 - loss: 0.4978 - val_accuracy: 0.8905 - val_loss: 0.3762\n",
      "Epoch 433/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7720 - loss: 0.5373 - val_accuracy: 0.8905 - val_loss: 0.3769\n",
      "Epoch 434/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.4494 - val_accuracy: 0.8940 - val_loss: 0.3774\n",
      "Epoch 435/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.4407 - val_accuracy: 0.8940 - val_loss: 0.3764\n",
      "Epoch 436/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.4451 - val_accuracy: 0.8975 - val_loss: 0.3755\n",
      "Epoch 437/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.4526 - val_accuracy: 0.8940 - val_loss: 0.3756\n",
      "Epoch 438/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8097 - loss: 0.5144 - val_accuracy: 0.8905 - val_loss: 0.3749\n",
      "Epoch 439/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.4751 - val_accuracy: 0.8905 - val_loss: 0.3751\n",
      "Epoch 440/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.4940 - val_accuracy: 0.8905 - val_loss: 0.3754\n",
      "Epoch 441/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8155 - loss: 0.4538 - val_accuracy: 0.8975 - val_loss: 0.3752\n",
      "Epoch 442/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8225 - loss: 0.4595 - val_accuracy: 0.8869 - val_loss: 0.3729\n",
      "Epoch 443/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7817 - loss: 0.5050 - val_accuracy: 0.8905 - val_loss: 0.3722\n",
      "Epoch 444/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8015 - loss: 0.5010 - val_accuracy: 0.8799 - val_loss: 0.3724\n",
      "Epoch 445/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.4158 - val_accuracy: 0.8869 - val_loss: 0.3739\n",
      "Epoch 446/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.5022 - val_accuracy: 0.8905 - val_loss: 0.3724\n",
      "Epoch 447/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.4450 - val_accuracy: 0.8834 - val_loss: 0.3728\n",
      "Epoch 448/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4398 - val_accuracy: 0.8940 - val_loss: 0.3719\n",
      "Epoch 449/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8395 - loss: 0.4279 - val_accuracy: 0.8905 - val_loss: 0.3713\n",
      "Epoch 450/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.4314 - val_accuracy: 0.8975 - val_loss: 0.3717\n",
      "Epoch 451/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.5008 - val_accuracy: 0.8869 - val_loss: 0.3708\n",
      "Epoch 452/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.4230 - val_accuracy: 0.8975 - val_loss: 0.3702\n",
      "Epoch 453/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8511 - loss: 0.4269 - val_accuracy: 0.8975 - val_loss: 0.3698\n",
      "Epoch 454/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.4113 - val_accuracy: 0.8975 - val_loss: 0.3684\n",
      "Epoch 455/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.4585 - val_accuracy: 0.8869 - val_loss: 0.3682\n",
      "Epoch 456/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.4616 - val_accuracy: 0.8975 - val_loss: 0.3681\n",
      "Epoch 457/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8164 - loss: 0.4763 - val_accuracy: 0.8975 - val_loss: 0.3679\n",
      "Epoch 458/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.4758 - val_accuracy: 0.8869 - val_loss: 0.3686\n",
      "Epoch 459/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4838 - val_accuracy: 0.8940 - val_loss: 0.3690\n",
      "Epoch 460/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.5248 - val_accuracy: 0.8940 - val_loss: 0.3675\n",
      "Epoch 461/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4585 - val_accuracy: 0.8834 - val_loss: 0.3665\n",
      "Epoch 462/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8154 - loss: 0.4552 - val_accuracy: 0.8834 - val_loss: 0.3678\n",
      "Epoch 463/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.4041 - val_accuracy: 0.8869 - val_loss: 0.3654\n",
      "Epoch 464/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.4587 - val_accuracy: 0.8940 - val_loss: 0.3668\n",
      "Epoch 465/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.5190 - val_accuracy: 0.8905 - val_loss: 0.3655\n",
      "Epoch 466/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.4645 - val_accuracy: 0.8905 - val_loss: 0.3654\n",
      "Epoch 467/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.4541 - val_accuracy: 0.8940 - val_loss: 0.3656\n",
      "Epoch 468/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.4497 - val_accuracy: 0.8905 - val_loss: 0.3663\n",
      "Epoch 469/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.4776 - val_accuracy: 0.8940 - val_loss: 0.3679\n",
      "Epoch 470/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8196 - loss: 0.4736 - val_accuracy: 0.8905 - val_loss: 0.3658\n",
      "Epoch 471/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.4831 - val_accuracy: 0.8905 - val_loss: 0.3656\n",
      "Epoch 472/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.4562 - val_accuracy: 0.8940 - val_loss: 0.3663\n",
      "Epoch 473/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8227 - loss: 0.4574 - val_accuracy: 0.8905 - val_loss: 0.3685\n",
      "Epoch 474/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.4198 - val_accuracy: 0.8975 - val_loss: 0.3666\n",
      "Epoch 475/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4418 - val_accuracy: 0.9011 - val_loss: 0.3654\n",
      "Epoch 476/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.4670 - val_accuracy: 0.8905 - val_loss: 0.3643\n",
      "Epoch 477/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.4947 - val_accuracy: 0.9011 - val_loss: 0.3660\n",
      "Epoch 478/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.5037 - val_accuracy: 0.8940 - val_loss: 0.3652\n",
      "Epoch 479/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.4356 - val_accuracy: 0.8940 - val_loss: 0.3632\n",
      "Epoch 480/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.4535 - val_accuracy: 0.8975 - val_loss: 0.3649\n",
      "Epoch 481/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.4150 - val_accuracy: 0.8975 - val_loss: 0.3679\n",
      "Epoch 482/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.4067 - val_accuracy: 0.8975 - val_loss: 0.3649\n",
      "Epoch 483/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4803 - val_accuracy: 0.8975 - val_loss: 0.3642\n",
      "Epoch 484/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.4096 - val_accuracy: 0.8940 - val_loss: 0.3637\n",
      "Epoch 485/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8090 - loss: 0.5004 - val_accuracy: 0.8940 - val_loss: 0.3645\n",
      "Epoch 486/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.4821 - val_accuracy: 0.8940 - val_loss: 0.3645\n",
      "Epoch 487/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4649 - val_accuracy: 0.8975 - val_loss: 0.3654\n",
      "Epoch 488/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.5181 - val_accuracy: 0.9046 - val_loss: 0.3653\n",
      "Epoch 489/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.5038 - val_accuracy: 0.8940 - val_loss: 0.3641\n",
      "Epoch 490/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4621 - val_accuracy: 0.8940 - val_loss: 0.3641\n",
      "Epoch 491/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.4434 - val_accuracy: 0.8940 - val_loss: 0.3636\n",
      "Epoch 492/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.4520 - val_accuracy: 0.8975 - val_loss: 0.3637\n",
      "Epoch 493/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.4444 - val_accuracy: 0.9011 - val_loss: 0.3639\n",
      "Epoch 494/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.4185 - val_accuracy: 0.9011 - val_loss: 0.3594\n",
      "Epoch 495/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.4477 - val_accuracy: 0.9011 - val_loss: 0.3597\n",
      "Epoch 496/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8107 - loss: 0.4885 - val_accuracy: 0.8975 - val_loss: 0.3605\n",
      "Epoch 497/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8458 - loss: 0.4308 - val_accuracy: 0.9011 - val_loss: 0.3594\n",
      "Epoch 498/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8087 - loss: 0.4824 - val_accuracy: 0.9011 - val_loss: 0.3585\n",
      "Epoch 499/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4389 - val_accuracy: 0.8940 - val_loss: 0.3582\n",
      "Epoch 500/500\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.4265 - val_accuracy: 0.8940 - val_loss: 0.3590\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    normalization_layer,\n",
    "    Dense(55, activation='relu'),\n",
    "    BatchNormalization(),  # Helps stabilize training\n",
    "    Dropout(0.3),\n",
    "    Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    #Dense(55, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "   \n",
    "    Dense(label_count, activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Nadam(learning_rate=0.00008), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#implement early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(X_train, y_train, epochs=500, batch_size=30, validation_split=0.2,callbacks=early_stopping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "stringnames = [\"E\", \"A\", \"D\", \"G\", \"B\", \"h_E\"]\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=stringnames, yticklabels=stringnames)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tf2onnx.tfonnx:rewriter <function rewrite_constant_fold at 0x000002518A5AAD40>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "model.save('stringDetectionML.h5')\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "model.output_names=['output']\n",
    "input_signature = [tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype, name='digit')]\n",
    "print(model.inputs[0].shape) \n",
    "\n",
    "(onnx_model_proto, storage) = tf2onnx.convert.from_keras(model,input_signature=input_signature, opset=13)\n",
    "\n",
    "dir = os.getcwd()\n",
    "dir = dir.split(\"/\")[0]\n",
    "while( path.basename(dir) != \"TabGenerator\"): # go to the TabGenerator directory\n",
    "    dir = os.path.dirname(dir)\n",
    "\n",
    "dir = os.path.join(dir, \"Assets\",\"MachineLearning\",\"MLModels\")\n",
    "onnxpath_asset_folder = os.path.join(dir, \"stringDetectionML_ONNX.onnx\")\n",
    "\n",
    "with open(onnxpath_asset_folder, \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())\n",
    "\n",
    "\n",
    "#export the model to local folder\n",
    "onnx_path = os.path.join(\"models\", \"stringDetectionML_ONNX.onnx\")\n",
    "with open(onnx_path, \"wb\") as f:\n",
    "    f.write(onnx_model_proto.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
